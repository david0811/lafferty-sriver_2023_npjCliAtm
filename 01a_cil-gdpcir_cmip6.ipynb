{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e6a91-5f45-445a-8e78-53fa1dbfa401",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "### FOR USE ON MICROSOFT PLANETARY COMPUTER ###\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8b0cb3-6059-43c0-87ee-cb343c13e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import planetary_computer\n",
    "import pystac_client\n",
    "import pystac\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "import fsspec\n",
    "import requests\n",
    "\n",
    "import getpass\n",
    "import azure.storage.blob\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230b7c1-1a5c-44ef-be0b-92a672666307",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9e1ed9-efe8-4743-b2f5-7e56b75fcca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Azure blob storage\n",
    "######################\n",
    "# connection string (from azure web login, select your storage account, then \"Access keys\")\n",
    "connection_string = getpass.getpass()\n",
    "\n",
    "    \n",
    "# format storage\n",
    "container_client = azure.storage.blob.ContainerClient.from_connection_string(\n",
    "    connection_string, container_name=\"mpctransfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16c220d-323f-4b12-954f-acfe608b96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Models\n",
    "###################\n",
    "\n",
    "# nex models with all SSPs and variables (tas, pr)\n",
    "complete_nex_models = ['ACCESS-CM2', 'ACCESS-ESM1-5', 'CanESM5', 'CMCC-ESM2', \n",
    "                       'CNRM-CM6-1', 'CNRM-ESM2-1', 'EC-Earth3',\n",
    "                       'EC-Earth3-Veg-LR', 'FGOALS-g3', 'GFDL-CM4', 'GFDL-ESM4', \n",
    "                       'GISS-E2-1-G', 'INM-CM4-8', 'INM-CM5-0',\n",
    "                       'IPSL-CM6A-LR', 'KACE-1-0-G', 'MIROC-ES2L', 'MIROC6',\n",
    "                       'MPI-ESM1-2-HR', 'MPI-ESM1-2-LR', 'MRI-ESM2-0', 'NorESM2-LM',\n",
    "                       'NorESM2-MM', 'TaiESM1', 'UKESM1-0-LL']\n",
    "\n",
    "# cil models with all SSPs and variables\n",
    "complete_cil_models = [\"INM-CM4-8\", \"INM-CM5-0\", \"BCC-CSM2-MR\", \"CMCC-CM2-SR5\",\n",
    "              \"CMCC-ESM2\", \"MIROC-ES2L\", \"MIROC6\", \"UKESM1-0-LL\", \"MPI-ESM1-2-LR\",\n",
    "              \"NorESM2-LM\", \"NorESM2-MM\", \"GFDL-ESM4\", \"EC-Earth3\", \n",
    "              \"EC-Earth3-Veg-LR\", \"EC-Earth3-Veg\", \"CanESM5\"]\n",
    "\n",
    "# intersection of models\n",
    "models = np.intersect1d(complete_cil_models, complete_nex_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d39ec5-6d6d-409d-bc19-db42a353b5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CMCC-ESM2', 'CanESM5', 'EC-Earth3', 'EC-Earth3-Veg-LR',\n",
       "       'GFDL-ESM4', 'INM-CM4-8', 'INM-CM5-0', 'MIROC-ES2L', 'MIROC6',\n",
       "       'MPI-ESM1-2-LR', 'NorESM2-LM', 'NorESM2-MM', 'UKESM1-0-LL'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27086cd8-9a0c-49bd-871c-8150e4831f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Data access\n",
    "#################\n",
    "\n",
    "# Complete catalog\n",
    "catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "# function to grab variables and SSPs for singe model\n",
    "def grab_model(model_id, include_temp, include_prcp):\n",
    "    # Search across all licences in CIL-GDPCIR\n",
    "    search = catalog.search(\n",
    "        collections=[\"cil-gdpcir-cc0\", \"cil-gdpcir-cc-by\", \"cil-gdpcir-cc-by-sa\"],\n",
    "        query={\"cmip6:source_id\" : {\"eq\": model_id},\n",
    "               \"cmip6:experiment_id\": {\"neq\": \"historical\"}} # omit historical\n",
    "    )\n",
    "    ensemble = search.get_all_items()\n",
    "    \n",
    "    # grab all into one dataset\n",
    "    ds_ssp = []\n",
    "    \n",
    "    # define vars to grab\n",
    "    vars_to_grab = include_temp * ['tasmin', 'tasmax'] + include_prcp * ['pr']\n",
    "\n",
    "    for item in ensemble:\n",
    "        signed = planetary_computer.sign(item)\n",
    "        ds_vars = []\n",
    "        for variable_id in vars_to_grab:\n",
    "            asset = signed.assets[variable_id]\n",
    "            ds_tmp = xr.open_dataset(asset.href, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "            ds_tmp = ds_tmp.assign_coords(ssp = ds_tmp.attrs['experiment_id'])\n",
    "            ds_vars.append(ds_tmp)\n",
    "        ds_ssp.append(xr.merge(ds_vars))\n",
    "\n",
    "    ds_out = xr.concat(ds_ssp, dim='ssp')\n",
    "    \n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e5f78d-502d-4d43-bd80-01802ed831c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.b66642175a9e4725b8a36c5bfdfeeb28/status\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# Dask\n",
    "#########\n",
    "import dask_gateway\n",
    "gateway = dask_gateway.Gateway()\n",
    "\n",
    "# cluster options\n",
    "cluster_options = gateway.cluster_options()\n",
    "cluster_options[\"worker_memory\"] = 16\n",
    "cluster_options[\"worker_cores\"] = 1\n",
    "\n",
    "# start cluster\n",
    "cluster = gateway.new_cluster(cluster_options)\n",
    "client = cluster.get_client()\n",
    "cluster.scale(40)\n",
    "\n",
    "# dashboard link\n",
    "print(cluster.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0a62c-d15c-490c-ba23-1f2ac34842a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805de98-8992-446f-ad3c-aa2ea3102244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # load data (lazy)\n",
    "    ds = grab_model(model, True, True)\n",
    "    \n",
    "    # storage options\n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds.data_vars} \n",
    "    \n",
    "    azure_prefix = 'cil-gdpcir/annual_avgs/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "    \n",
    "    # compute and store\n",
    "    ds['tasavg'] = (ds['tasmax'] + ds['tasmin']) / 2.\n",
    "    ds_final = ds.resample(time='1Y').mean()\n",
    "\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb97d939-4949-4517-bb29-e3577dd27ff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annual maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8579e6-6721-4267-bd37-844331af59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through models: RUNTIME IS AROUND 12 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # load data (lazy)\n",
    "    ds = grab_model(model, True, True)\n",
    "\n",
    "    # storage options\n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds.data_vars} \n",
    "    \n",
    "    azure_prefix = 'cil-gdpcir/annual_maxs/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "    \n",
    "    # compute and store\n",
    "    ds_final = ds.resample(time='1Y').max()\n",
    "\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba4412-37b7-4317-8d85-1e3d7a3851ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annual minima (temperature only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ea9a1-5654-48bb-b92d-7032e8f9faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through models: RUNTIME IS AROUND 8 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # load data (lazy)\n",
    "    ds = grab_model(model, True, False)\n",
    "\n",
    "    # storage options\n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds.data_vars} \n",
    "    \n",
    "    azure_prefix = 'cil-gdpcir/annual_mins/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "    \n",
    "    # compute and store\n",
    "    ds_final = ds.resample(time='1Y').min()\n",
    "\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fef3c-105b-4e9e-903b-9c0c90fceca3",
   "metadata": {},
   "source": [
    "## Precipitation indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb5a99-ed6e-46a0-a13d-41bdeb4bac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through models: RUNTIME IS AROUND 8 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # load data (lazy)\n",
    "    ds = grab_model(model, False, True)\n",
    "\n",
    "    # storage options  \n",
    "    azure_prefix = 'cil-gdpcir/precip_inds/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "    \n",
    "    # compute and store\n",
    "    prcp_sdii = ds.where(ds.pr >= 1.).resample(time='1Y').mean()\n",
    "    prcp_r20mm = ds.where(ds.pr >= 20.).resample(time='1Y').count()\n",
    "    \n",
    "    ds_final = xr.combine_by_coords([prcp_sdii.rename({'pr': 'SDII'}),\n",
    "                                     prcp_r20mm.rename({'pr': 'R20mm'})])\n",
    "\n",
    "    # storage options\n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars} \n",
    "    \n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36a222-c73f-43c6-ad49-49106a68d045",
   "metadata": {},
   "source": [
    "## re-chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4a3c0-8e43-4b9b-99e0-2f449bd2cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-chunk for easier access - should have thought about this the first time around!\n",
    "for model in models:\n",
    "    print(model)\n",
    "    for metric in ['annual_avgs', 'annual_maxs', 'annual_mins', 'precip_inds']:\n",
    "        # read\n",
    "        azure_prefix = 'cil-gdpcir/' + metric + '/' + model\n",
    "        store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "        ds_cil = xr.open_zarr(store=store)\n",
    "        \n",
    "        # rechunk and write\n",
    "        azure_prefix = 'cil-gdpcir_rechunked/' + metric + '/' + model\n",
    "        store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "        \n",
    "        ds_cil = ds_cil.chunk({'ssp':1, 'time':10, 'lat':720, 'lon':1440})\n",
    "        \n",
    "        compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "        encoding = {vname: {'compressor': compressor} for vname in ds_cil.data_vars} \n",
    "\n",
    "        ds_cil.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dd233-73e6-4ac3-8a13-a9bf3a5b4e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7407f8-65d4-4e40-8b2b-a39f3800d906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f78c9ef4-fbeb-4fbf-ad88-fd2429d3faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# OLD: all SSPs and variables\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b601f01-23c2-45de-8e84-04a7e7756694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grab_ssp_var(ssp_id, variable_id):\n",
    "#     # Search across all licences in CIL-GDPCIR\n",
    "#     search = catalog.search(\n",
    "#         collections=[\"cil-gdpcir-cc0\", \"cil-gdpcir-cc-by\", \"cil-gdpcir-cc-by-sa\"],\n",
    "#         query={\"cmip6:experiment_id\": {\"eq\": ssp_id}},\n",
    "#     )\n",
    "#     # How many models?\n",
    "#     ensemble = search.get_all_items()\n",
    "    \n",
    "#     # grab all into one dataset\n",
    "#     datasets_by_model = []\n",
    "\n",
    "#     for item in tqdm(ensemble[:2]):\n",
    "#         try:\n",
    "#             signed = planetary_computer.sign(item)\n",
    "#             asset = signed.assets[variable_id]\n",
    "#             datasets_by_model.append(\n",
    "#                 xr.open_dataset(asset.href, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "#             )\n",
    "#         except: \n",
    "#             print(variable_id + ' error for ' + item.id)\n",
    "\n",
    "#     all_datasets = xr.concat(\n",
    "#         datasets_by_model,\n",
    "#         dim=pd.Index([ds.attrs[\"source_id\"] for ds in datasets_by_model], name=\"model\"),\n",
    "#         combine_attrs=\"drop_conflicts\",\n",
    "#     )\n",
    "    \n",
    "#     return all_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf884f53-e332-4768-8384-c276ab6319cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssp_id = 'ssp126'\n",
    "\n",
    "# # tmin, tmax, prcp\n",
    "# tmax_ssp126 = grab_ssp_var(ssp_id, 'tasmax')\n",
    "# tmin_ssp126 = grab_ssp_var(ssp_id, 'tasmin')\n",
    "# prcp_ssp126 = grab_ssp_var(ssp_id, 'pr')\n",
    "\n",
    "# # merge and assign ssp coordinate\n",
    "# ssp126_all = xr.merge([tmax_ssp126, tmin_ssp126, prcp_ssp126])\n",
    "# ssp126_all = ssp126_all.assign_coords(ssp=ssp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0c1e0-5924-4317-bf31-8bd7462399fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
