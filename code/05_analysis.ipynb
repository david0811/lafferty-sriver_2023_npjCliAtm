{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57743a7e-8b68-4544-8378-ac3e453f96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f3946-bb89-4535-a1e8-ae9b6ccaed61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662dfbf5-61c7-48f6-884d-ce058d6a7512",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Set paths\n",
    "# UPDATE THIS FOR REPRODUCTION\n",
    "###############################\n",
    "nex_in = \"/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/nex-gddp/\"  # location of NEX-GDDP metrics\n",
    "cil_in = \"/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/cil-gdpcir/\"  # location of CIL-GDPCIR metrics\n",
    "isi_in = \"/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/isimip3b/regridded/conservative/\"  # location of *regridded* ISIMIP metrics\n",
    "cbp_in = \"/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/carbonplan/\"  # location of carbonplan metrics\n",
    "\n",
    "out_path = \"/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/results/\"  # where to store UC results\n",
    "poly_path = \"/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/forced_response/\"  # where to store extracted forced responses\n",
    "iav_path = \"/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/interannual_variability/\"  # where to store rolling IAV estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c50de8a-ea1e-4a9d-ad37-c522111ff76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Models\n",
    "###################\n",
    "from utils import cil_ssp_dict, deepsdbc_dict, gardsv_ssp_dict, gardsv_var_dict, isimip_ssp_dict, nex_ssp_dict\n",
    "\n",
    "nex_models = list(nex_ssp_dict.keys())\n",
    "cil_models = list(cil_ssp_dict.keys())\n",
    "isi_models = list(isimip_ssp_dict.keys())\n",
    "cbp_gard_models = list(gardsv_ssp_dict.keys())\n",
    "cbp_gard_precip_models = [model for model in cbp_gard_models if \"pr\" in gardsv_var_dict[model]]\n",
    "cbp_deep_models = list(deepsdbc_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad43d2c-5706-40fa-a2b4-9e1f24782a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Land mask (from NEX)\n",
    "#######################\n",
    "land_mask = xr.open_dataset(nex_in + \"avg/CanESM5.nc\")\n",
    "land_mask = land_mask.isel(ssp=0, time=0).tas.isnull()\n",
    "land_mask[\"lon\"] = np.where(land_mask[\"lon\"] > 180, land_mask[\"lon\"] - 360, land_mask[\"lon\"])\n",
    "land_mask = land_mask.sortby(\"lon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a1c47d5-5fb5-4648-aac2-a86cbb62fdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-3462a89e-c047-11ed-94f6-74e6e2708ca4</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">8ae7e12a</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-d6f7ee86-1895-48a8-a7af-e76e16d6deb3</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.102.201.224:42639\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.102.201.224:42639' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Dask\n",
    "############\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "cluster = PBSCluster(\n",
    "    cores=1,\n",
    "    memory=\"40GB\",\n",
    "    resource_spec=\"pmem=40GB\",\n",
    "    # account='open',\n",
    "    worker_extra_args=[\"#PBS -l feature=rhel7\"],\n",
    "    walltime=\"06:00:00\",\n",
    ")\n",
    "\n",
    "cluster.scale(jobs=40)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f20699-35c7-4dbf-a8ad-ad73115785df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Total uncertainty: gridded metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099faaa-43cd-4e3b-a541-8cf3dfb66379",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c6626-3157-4eee-9847-5df9e74f459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Total uncertainty: variance across all models, scenarios, ensembles\n",
    "#######################################################################\n",
    "def uc_total(\n",
    "    nex_in,\n",
    "    nex_models,\n",
    "    cil_in,\n",
    "    cil_models,\n",
    "    isi_in,\n",
    "    isi_models,\n",
    "    cbp_in,\n",
    "    cbp_gard_models,\n",
    "    cbp_deep_models,\n",
    "    land_mask,\n",
    "    metric,\n",
    "    submetric,\n",
    "    year,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads in all models, ssps, and calculates the total uncertainty (variance across\n",
    "    all model, ssp, ensemble dimensions) for a given year (and possibly DataArray).\n",
    "    For metrics like 'hot' where there are several sub-metrics based on different\n",
    "    thresholds and/or observational data, we need to select a specific DataArray\n",
    "    to keep the memory manageable.\n",
    "    \"\"\"\n",
    "\n",
    "    # Subfunction for general preprocessing of each model/ensemble\n",
    "    def read_and_process(ensemble, path_in, model, year, metric, submetric):\n",
    "        # Read netcdf or zarr\n",
    "        if ensemble in [\"NEX\", \"ISIMIP\", \"GARD-SV\"]:\n",
    "            ds = xr.open_dataset(path_in + metric + \"/\" + model + \".nc\")\n",
    "        elif ensemble in [\"CIL\", \"DeepSD-BC\"]:\n",
    "            ds = xr.open_dataset(path_in + metric + \"/\" + model, engine=\"zarr\")\n",
    "\n",
    "        # Select submetric if chosen\n",
    "        if submetric:\n",
    "            ds = ds[submetric]\n",
    "\n",
    "        # Common preprocessing\n",
    "        ds[\"time\"] = ds.indexes[\"time\"].year\n",
    "        ds = ds.sel(time=year)\n",
    "        ds = ds.sortby(\"ssp\")\n",
    "        ds = ds.assign_coords(ensemble=ensemble)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "\n",
    "        # Add model dimension\n",
    "        if model[-6:] in [\"tasmin\", \"tasmax\"]:\n",
    "            model_str = model[:-7]\n",
    "        else:\n",
    "            model_str = model\n",
    "        ds = ds.assign_coords(model=model_str)\n",
    "\n",
    "        # Fix lon to [-180,180]\n",
    "        if ds.lon.max() > 180:\n",
    "            ds[\"lon\"] = np.where(ds[\"lon\"] > 180, ds[\"lon\"] - 360, ds[\"lon\"])\n",
    "            ds = ds.sortby(\"lon\")\n",
    "\n",
    "        # Some models/methods are missing precip so fill with NaNs\n",
    "        if (metric in [\"max\", \"avg\"]) and (\"pr\" not in ds.data_vars):\n",
    "            ds[\"pr\"] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "        if (metric == \"max5d\") and (\"RX5day\" not in ds.data_vars):\n",
    "            ds[\"RX5day\"] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "\n",
    "        # Drop member_id\n",
    "        if \"member_id\" in list(ds.coords):\n",
    "            ds = ds.isel(member_id=0).drop(\"member_id\")\n",
    "\n",
    "        # Return\n",
    "        return ds\n",
    "\n",
    "    ######################\n",
    "    # Read all ensembles\n",
    "    ######################\n",
    "    # NEX-GDDP\n",
    "    ds_out = []\n",
    "    for model in nex_models:\n",
    "        ds_out.append(read_and_process(\"NEX\", nex_in, model, year, metric, submetric))\n",
    "    ds_nex = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # CIL-GDPCIR\n",
    "    ds_out = []\n",
    "    for model in cil_models:\n",
    "        ds_out.append(read_and_process(\"CIL\", cil_in, model, year, metric, submetric))\n",
    "    ds_cil = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # ISIMIP\n",
    "    ds_out = []\n",
    "    for model in isi_models:\n",
    "        ds_out.append(read_and_process(\"ISIMIP\", isi_in, model, year, metric, submetric))\n",
    "    ds_isi = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # carbonplan: GARD-SV\n",
    "    ds_out = []\n",
    "    for model in cbp_gard_models:\n",
    "        ds_out.append(\n",
    "            read_and_process(\n",
    "                \"GARD-SV\",\n",
    "                cbp_in + \"/regridded/conservative/GARD-SV/\",\n",
    "                model,\n",
    "                year,\n",
    "                metric,\n",
    "                submetric,\n",
    "            )\n",
    "        )\n",
    "    ds_cbp_gard = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # carbonplan: DeepSD-BC\n",
    "    ds_out = []\n",
    "    for model in cbp_deep_models:\n",
    "        ds_out.append(\n",
    "            read_and_process(\n",
    "                \"DeepSD-BC\",\n",
    "                cbp_in + \"native_grid/DeepSD-BC/\",\n",
    "                model,\n",
    "                year,\n",
    "                metric,\n",
    "                submetric,\n",
    "            )\n",
    "        )\n",
    "    ds_cbp_deep = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    ###########################\n",
    "    # Merge all and mask ocean\n",
    "    ###########################\n",
    "    ds = xr.concat(\n",
    "        [ds_nex, ds_cil, ds_isi, ds_cbp_gard, ds_cbp_deep],\n",
    "        dim=\"ensemble\",\n",
    "        fill_value=np.nan,\n",
    "    )\n",
    "\n",
    "    # Mask out ocean points\n",
    "    ds = xr.where(land_mask, np.nan, ds)\n",
    "\n",
    "    ##########################\n",
    "    # Uncertainty calculation\n",
    "    ##########################\n",
    "    ## Total uncertainty\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        U_total_true = ds.var(dim=[\"ensemble\", \"ssp\", \"model\"], skipna=True)  # throws warning when all NaNs\n",
    "\n",
    "    U_total_true = U_total_true.assign_coords(uncertainty=\"total_true\")\n",
    "\n",
    "    return U_total_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ab2c4-937d-4182-bbb9-28cce3d0db86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fb9a5cf-fef0-4b13-a893-c3abb8f8869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 6s, sys: 19.6 s, total: 7min 25s\n",
      "Wall time: 53min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"avg\"\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "\n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim=\"time\")\n",
    "ds_out.to_netcdf(out_path + \"total_uncertainty/\" + metric + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a42be14-76c5-45c6-af3e-b3c3ac35d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 15s, sys: 26.9 s, total: 10min 42s\n",
      "Wall time: 1h 19min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"max\"\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "\n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim=\"time\")\n",
    "ds_out.to_netcdf(out_path + \"total_uncertainty/\" + metric + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3fad6-da49-4d22-8683-e48f26f2b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"max5d\"\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "\n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim=\"time\")\n",
    "ds_out.to_netcdf(out_path + \"total_uncertainty/\" + metric + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39d8af44-d0b6-4149-9fae-54bde897d272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 10.3 s, total: 3min 32s\n",
      "Wall time: 26min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"dry\"\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_precip_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        year,\n",
    "    )\n",
    "\n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "\n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim=\"time\")\n",
    "ds_out.to_netcdf(out_path + \"total_uncertainty/\" + metric + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dcf8a90-fa74-49a4-972a-2fd9e395645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.5 s, sys: 9.57 s, total: 1min 3s\n",
      "Wall time: 10min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hot + dry days\n",
    "metric = \"hotdry\"\n",
    "for thresh in [\"q99\", \"rp10\"]:\n",
    "    for obs in [\"gmfd\", \"era5\"]:\n",
    "        submetric_str = thresh + obs\n",
    "        submetric = [\n",
    "            \"hotdry_\" + submetric_str + \"_count\",\n",
    "            \"hotdry_\" + submetric_str + \"_streak\",\n",
    "        ]\n",
    "\n",
    "        # Dask delayed over years\n",
    "        delayed_res = []\n",
    "        for year in range(2015, 2100):\n",
    "            # Read all ensembles and compute total uncertainty\n",
    "            tmp_res = dask.delayed(uc_total)(\n",
    "                nex_in,\n",
    "                nex_models,\n",
    "                cil_in,\n",
    "                cil_models,\n",
    "                isi_in,\n",
    "                isi_models,\n",
    "                cbp_in,\n",
    "                cbp_gard_precip_models,\n",
    "                cbp_deep_models,\n",
    "                land_mask,\n",
    "                metric,\n",
    "                submetric,\n",
    "                year,\n",
    "            )\n",
    "\n",
    "            # Append\n",
    "            delayed_res.append(tmp_res)\n",
    "\n",
    "        # Compute\n",
    "        res = dask.compute(*delayed_res)\n",
    "\n",
    "        # Merge and store\n",
    "        ds_out = xr.concat(res, dim=\"time\")\n",
    "        ds_out.to_netcdf(out_path + \"total_uncertainty/\" + metric + \"_\" + submetric_str + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0095b6b-8090-4cff-88f9-3e7e8f44587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58 s, sys: 9.06 s, total: 1min 7s\n",
      "Wall time: 11min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wet days\n",
    "metric = \"wet\"\n",
    "for thresh in [\"q99\", \"rp10\"]:\n",
    "    for obs in [\"gmfd\", \"era5\"]:\n",
    "        submetric_str = thresh + obs\n",
    "        submetric = [\n",
    "            \"pr_\" + submetric_str + \"_count\",\n",
    "            \"pr_\" + submetric_str + \"_streak\",\n",
    "        ]\n",
    "\n",
    "        # Dask delayed over years\n",
    "        delayed_res = []\n",
    "        for year in range(2015, 2100):\n",
    "            # Read all ensembles and compute total uncertainty\n",
    "            tmp_res = dask.delayed(uc_total)(\n",
    "                nex_in,\n",
    "                nex_models,\n",
    "                cil_in,\n",
    "                cil_models,\n",
    "                isi_in,\n",
    "                isi_models,\n",
    "                cbp_in,\n",
    "                cbp_gard_precip_models,\n",
    "                cbp_deep_models,\n",
    "                land_mask,\n",
    "                metric,\n",
    "                submetric,\n",
    "                year,\n",
    "            )\n",
    "\n",
    "            # Append\n",
    "            delayed_res.append(tmp_res)\n",
    "\n",
    "        # Compute\n",
    "        res = dask.compute(*delayed_res)\n",
    "\n",
    "        # Merge and store\n",
    "        ds_out = xr.concat(res, dim=\"time\")\n",
    "        ds_out.to_netcdf(out_path + \"total_uncertainty/\" + metric + \"_\" + submetric_str + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6258a0e0-a464-4630-8f81-b527e24aacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 42s, sys: 33.1 s, total: 8min 15s\n",
      "Wall time: 58min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hot days\n",
    "metric = \"hot\"\n",
    "for thresh in [\"q99\", \"rp10\"]:\n",
    "    for obs in [\"gmfd\", \"era5\"]:\n",
    "        for submetric_var in [\"tas\", \"tasmin\", \"tasmax\"]:\n",
    "            submetric_str = submetric_var + \"_\" + thresh + obs\n",
    "            submetric = [submetric_str + \"_count\", submetric_str + \"_streak\"]\n",
    "\n",
    "            # Dask delayed over years\n",
    "            delayed_res = []\n",
    "            for year in range(2015, 2100):\n",
    "                # Read all ensembles and compute total uncertainty\n",
    "                tmp_res = dask.delayed(uc_total)(\n",
    "                    nex_in,\n",
    "                    [model + \"_\" + submetric_var for model in nex_models],\n",
    "                    cil_in,\n",
    "                    cil_models,\n",
    "                    isi_in,\n",
    "                    [model + \"_\" + submetric_var for model in isi_models],\n",
    "                    cbp_in,\n",
    "                    [model + \"_\" + submetric_var for model in cbp_gard_models],\n",
    "                    cbp_deep_models,\n",
    "                    land_mask,\n",
    "                    metric,\n",
    "                    submetric,\n",
    "                    year,\n",
    "                )\n",
    "\n",
    "                # Append\n",
    "                delayed_res.append(tmp_res)\n",
    "\n",
    "            # Compute\n",
    "            res = dask.compute(*delayed_res)\n",
    "\n",
    "            # Merge and store\n",
    "            ds_out = xr.concat(res, dim=\"time\")\n",
    "            ds_out.to_netcdf(out_path + \"total_uncertainty/\" + metric + \"_\" + submetric_str + \".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846d2ef-2b66-4b48-8f15-7cd721208f46",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Uncertainty partitioning: gridded metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd1c9fa-de1b-4b88-a734-dcefddb4be0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting the forced response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af24ede7-0f8b-4172-b9e8-7d0c8a137385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forced_poly(\n",
    "    nex_in,\n",
    "    nex_models,\n",
    "    cil_in,\n",
    "    cil_models,\n",
    "    isi_in,\n",
    "    isi_models,\n",
    "    cbp_in,\n",
    "    cbp_gard_models,\n",
    "    cbp_deep_models,\n",
    "    land_mask,\n",
    "    metric,\n",
    "    submetric,\n",
    "    submetric_var,\n",
    "    poly_path,\n",
    "    deg,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads in all models, ssps, and calculates the 'forced response' as a deg-th order\n",
    "    polynomial.\n",
    "    For metrics like 'hot' where there are several sub-metrics based on different\n",
    "    thresholds and/or observational data, we need to select a specific DataArray\n",
    "    to keep the memory manageable.\n",
    "    \"\"\"\n",
    "\n",
    "    # Subfunction to get polynomial for each model/ensemble\n",
    "    def get_poly_coeffs(ensemble, path_in, model, metric, submetric, submetric_var, deg):\n",
    "        # Read netcdf or zarr\n",
    "        if ensemble in [\"NEX\", \"ISIMIP\", \"GARD-SV\"]:\n",
    "            if submetric_var:\n",
    "                ds = xr.open_dataset(path_in + metric + \"/\" + model + \"_\" + submetric_var + \".nc\")\n",
    "            else:\n",
    "                ds = xr.open_dataset(path_in + metric + \"/\" + model + \".nc\")\n",
    "        elif ensemble in [\"CIL\", \"DeepSD-BC\"]:\n",
    "            ds = xr.open_dataset(path_in + metric + \"/\" + model, engine=\"zarr\")\n",
    "\n",
    "        # Select submetric if chosen\n",
    "        if submetric:\n",
    "            ds = ds[submetric]\n",
    "\n",
    "        # Common preprocessing\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "        ds = ds.sortby(\"ssp\")\n",
    "        if ds.lon.max() > 180:\n",
    "            ds[\"lon\"] = np.where(ds[\"lon\"] > 180, ds[\"lon\"] - 360, ds[\"lon\"])\n",
    "            ds = ds.sortby(\"lon\")\n",
    "\n",
    "        # Forced response via polynomial\n",
    "        ds = xr.polyval(coord=ds[\"time\"], coeffs=ds.polyfit(dim=\"time\", deg=deg))\n",
    "        ds = ds.rename({name: name.replace(\"_polyfit_coefficients\", \"\") for name in list(ds.data_vars)})\n",
    "\n",
    "        # Construct output name: assumes submetrics are of the form ['X_count', 'X_streak']\n",
    "        out_str = poly_path + metric + \"/\"\n",
    "\n",
    "        if submetric:\n",
    "            submetric_str = submetric[0].replace(\"_count\", \"\").replace(\"_streak\", \"\")\n",
    "            out_str = out_str + submetric_str + \"_\"\n",
    "\n",
    "        # Drop member_id\n",
    "        if \"member_id\" in list(ds.coords):\n",
    "            ds = ds.isel(member_id=0).drop(\"member_id\")\n",
    "\n",
    "        ds.to_netcdf(out_str + ensemble + \"_\" + model + \"_deg\" + str(deg) + \".nc\")\n",
    "\n",
    "    # For checking if file exists\n",
    "    def construct_out_str(poly_path, ensemble, model, metric, submetric, submetric_var, deg):\n",
    "        # Construct output name: assumes submetrics are of the form ['X_count', 'X_streak']\n",
    "        out_str = poly_path + metric + \"/\"\n",
    "\n",
    "        if submetric:\n",
    "            submetric_str = submetric[0].replace(\"_count\", \"\").replace(\"_streak\", \"\")\n",
    "            out_str = out_str + submetric_str + \"_\"\n",
    "\n",
    "        return out_str + ensemble + \"_\" + model + \"_deg\" + str(deg) + \".nc\"\n",
    "\n",
    "    #######################\n",
    "    # Apply to all ensembles\n",
    "    #######################\n",
    "    # Dask delayed\n",
    "    res = []\n",
    "\n",
    "    # NEX-GDDP\n",
    "    for model in nex_models:\n",
    "        if not os.path.isfile(construct_out_str(poly_path, \"NEX\", model, metric, submetric, submetric_var, deg)):\n",
    "            res.append(dask.delayed(get_poly_coeffs)(\"NEX\", nex_in, model, metric, submetric, submetric_var, deg))\n",
    "\n",
    "    # CIL-GDPCIR\n",
    "    for model in cil_models:\n",
    "        if not os.path.isfile(construct_out_str(poly_path, \"CIL\", model, metric, submetric, submetric_var, deg)):\n",
    "            res.append(dask.delayed(get_poly_coeffs)(\"CIL\", cil_in, model, metric, submetric, submetric_var, deg))\n",
    "\n",
    "    # ISIMIP\n",
    "    for model in isi_models:\n",
    "        if not os.path.isfile(construct_out_str(poly_path, \"ISIMIP\", model, metric, submetric, submetric_var, deg)):\n",
    "            res.append(dask.delayed(get_poly_coeffs)(\"ISIMIP\", isi_in, model, metric, submetric, submetric_var, deg))\n",
    "\n",
    "    # carbonplan: GARD-SV\n",
    "    for model in cbp_gard_models:\n",
    "        if not os.path.isfile(construct_out_str(poly_path, \"GARD-SV\", model, metric, submetric, submetric_var, deg)):\n",
    "            res.append(\n",
    "                dask.delayed(get_poly_coeffs)(\n",
    "                    \"GARD-SV\",\n",
    "                    cbp_in + \"/regridded/conservative/GARD-SV/\",\n",
    "                    model,\n",
    "                    metric,\n",
    "                    submetric,\n",
    "                    submetric_var,\n",
    "                    deg,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # carbonplan: DeepSD-BC\n",
    "    for model in cbp_deep_models:\n",
    "        if not os.path.isfile(construct_out_str(poly_path, \"DeepSD-BC\", model, metric, submetric, submetric_var, deg)):\n",
    "            res.append(\n",
    "                dask.delayed(get_poly_coeffs)(\n",
    "                    \"DeepSD-BC\",\n",
    "                    cbp_in + \"native_grid/DeepSD-BC/\",\n",
    "                    model,\n",
    "                    metric,\n",
    "                    submetric,\n",
    "                    submetric_var,\n",
    "                    deg,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Compute\n",
    "    if len(res) > 0:\n",
    "        dask.compute(*res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc653be-cb3f-4a81-9965-c701734e1c10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Uncertainty characterization of forced response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2451366-7734-4d83-bb2c-c16d11a91062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uc_forced(\n",
    "    nex_in,\n",
    "    nex_models,\n",
    "    cil_in,\n",
    "    cil_models,\n",
    "    isi_in,\n",
    "    isi_models,\n",
    "    cbp_in,\n",
    "    cbp_gard_models,\n",
    "    cbp_deep_models,\n",
    "    land_mask,\n",
    "    metric,\n",
    "    submetric,\n",
    "    submetric_var,\n",
    "    year,\n",
    "    poly_path,\n",
    "    deg,\n",
    "    weighted,\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads in all models, ssps, and calculates the uncertainty in the 'forced response'\n",
    "    along each dimension (ssp, model, ens) for a given year (and possibly DataArray).\n",
    "    For metrics like 'hot' where there are several sub-metrics based on different\n",
    "    thresholds and/or observational data, we need to select a specific DataArray\n",
    "    to keep the memory manageable.\n",
    "    \"\"\"\n",
    "\n",
    "    # Subfunction for general preprocessing of each model/ensemble\n",
    "    def read_and_process(ensemble, path_in, model, year, metric, submetric, submetric_var, deg):\n",
    "        # Polynomial responses should have already been calculated\n",
    "        poly_str = poly_path + metric + \"/\"\n",
    "        if submetric:\n",
    "            submetric_str = submetric[0].replace(\"_count\", \"\").replace(\"_streak\", \"\")\n",
    "            poly_str = poly_str + submetric_str + \"_\"\n",
    "        ds = xr.open_dataset(poly_str + ensemble + \"_\" + model + \"_deg\" + str(deg) + \".nc\")\n",
    "        ds[\"time\"] = ds.indexes[\"time\"].year\n",
    "        ds = ds.sel(time=year)\n",
    "\n",
    "        # Select submetric if chosen\n",
    "        if submetric:\n",
    "            ds = ds[submetric]\n",
    "\n",
    "        # Common preprocessing\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "        ds = ds.sortby(\"ssp\")\n",
    "        ds = ds.assign_coords(ensemble=ensemble)\n",
    "        ds = ds.assign_coords(model=model)\n",
    "\n",
    "        # Fix lon to [-180,180]\n",
    "        if ds.lon.max() > 180:\n",
    "            ds[\"lon\"] = np.where(ds[\"lon\"] > 180, ds[\"lon\"] - 360, ds[\"lon\"])\n",
    "            ds = ds.sortby(\"lon\")\n",
    "\n",
    "        # Some models/methods are missing precip so fill with NaNs\n",
    "        if (metric in [\"max\", \"avg\"]) and (\"pr\" not in ds.data_vars):\n",
    "            ds[\"pr\"] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "        if (metric == \"max5d\") and (\"RX5day\" not in ds.data_vars):\n",
    "            ds[\"RX5day\"] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "\n",
    "        # Drop member_id\n",
    "        if \"member_id\" in list(ds.coords):\n",
    "            ds = ds.isel(member_id=0).drop(\"member_id\")\n",
    "\n",
    "        # Forced response should always be >= 0\n",
    "        if metric in [\"hot\", \"wet\", \"dry\", \"hotdry\"]:\n",
    "            ds = xr.where(ds >= 0, ds, 0)\n",
    "\n",
    "        # Return\n",
    "        return ds\n",
    "\n",
    "    ######################\n",
    "    # Read all ensembles\n",
    "    ######################\n",
    "    # NEX-GDDP\n",
    "    ds_out = []\n",
    "    for model in nex_models:\n",
    "        ds_out.append(read_and_process(\"NEX\", nex_in, model, year, metric, submetric, submetric_var, deg))\n",
    "    ds_nex = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # CIL-GDPCIR\n",
    "    ds_out = []\n",
    "    for model in cil_models:\n",
    "        ds_out.append(read_and_process(\"CIL\", cil_in, model, year, metric, submetric, submetric_var, deg))\n",
    "    ds_cil = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # ISIMIP\n",
    "    ds_out = []\n",
    "    for model in isi_models:\n",
    "        ds_out.append(read_and_process(\"ISIMIP\", isi_in, model, year, metric, submetric, submetric_var, deg))\n",
    "    ds_isi = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # carbonplan: GARD-SV\n",
    "    ds_out = []\n",
    "    for model in cbp_gard_models:\n",
    "        ds_out.append(\n",
    "            read_and_process(\n",
    "                \"GARD-SV\",\n",
    "                cbp_in + \"/regridded/conservative/GARD-SV/\",\n",
    "                model,\n",
    "                year,\n",
    "                metric,\n",
    "                submetric,\n",
    "                submetric_var,\n",
    "                deg,\n",
    "            )\n",
    "        )\n",
    "    ds_cbp_gard = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    # carbonplan: DeepSD-BC\n",
    "    ds_out = []\n",
    "    for model in cbp_deep_models:\n",
    "        ds_out.append(\n",
    "            read_and_process(\n",
    "                \"DeepSD-BC\",\n",
    "                cbp_in + \"native_grid/DeepSD-BC/\",\n",
    "                model,\n",
    "                year,\n",
    "                metric,\n",
    "                submetric,\n",
    "                submetric_var,\n",
    "                deg,\n",
    "            )\n",
    "        )\n",
    "    ds_cbp_deep = xr.concat(ds_out, dim=\"model\", fill_value=np.nan)\n",
    "\n",
    "    ###########################\n",
    "    # Merge all and mask ocean\n",
    "    ###########################\n",
    "    ds = xr.concat(\n",
    "        [ds_nex, ds_cil, ds_isi, ds_cbp_gard, ds_cbp_deep],\n",
    "        dim=\"ensemble\",\n",
    "        fill_value=np.nan,\n",
    "    )\n",
    "    ds = xr.where(land_mask, np.nan, ds)\n",
    "\n",
    "    ##########################\n",
    "    # Uncertainty calculation\n",
    "    ##########################\n",
    "\n",
    "    ## Scenario uncertainty\n",
    "    # HS09 approach: variance across multi-model means\n",
    "    U_scen_hs09 = ds.mean(dim=[\"model\", \"ensemble\"]).var(dim=\"ssp\")\n",
    "    # BB13 approach: variance across scenarios, averaged over models and ensembles (no weighting)\n",
    "    U_scen_bb13 = ds.var(dim=\"ssp\").mean(dim=[\"model\", \"ensemble\"])\n",
    "\n",
    "    ##  Model uncertainty\n",
    "    # Variance across models, averaged over scenarios and ensembles\n",
    "    U_model = ds.var(dim=\"model\")\n",
    "\n",
    "    if weighted:\n",
    "        weights = (\n",
    "            ds.isel(lat=300, lon=800)[list(ds.data_vars)[0]].count(dim=\"model\").rename(\"weights\")\n",
    "        )  # weights (choose point over land)\n",
    "        weights = xr.where(weights == 1, 0, weights)  # remove combinations where variance was calculated over 1 entry\n",
    "        U_model = U_model.weighted(weights).mean(dim=[\"ssp\", \"ensemble\"])  # weighted average\n",
    "    else:\n",
    "        U_model = U_model.mean(dim=[\"ssp\", \"ensemble\"])  # simple average\n",
    "\n",
    "    ## Downscaling uncertainy\n",
    "    # Variance across ensembles, averaged over models and scenarios\n",
    "    U_ens = ds.var(dim=\"ensemble\")\n",
    "\n",
    "    if weighted:\n",
    "        weights = (\n",
    "            ds.isel(lat=300, lon=800)[list(ds.data_vars)[0]].count(dim=\"ensemble\").rename(\"weights\")\n",
    "        )  # weights (choose point over land)\n",
    "        weights = xr.where(weights == 1, 0, weights)  # remove combinations where variance was calculated over 1 entry\n",
    "        U_ens = U_ens.weighted(weights).mean(dim=[\"ssp\", \"model\"])  # weighted average\n",
    "    else:\n",
    "        U_ens = U_ens.mean(dim=[\"ssp\", \"model\"])  # simple average\n",
    "\n",
    "    ## Merge and return\n",
    "    U_model = U_model.assign_coords(uncertainty=\"model\")\n",
    "    U_ens = U_ens.assign_coords(uncertainty=\"ensemble\")\n",
    "    U_scen_hs09 = U_scen_hs09.assign_coords(uncertainty=\"scenario_hs09\")\n",
    "    U_scen_bb13 = U_scen_bb13.assign_coords(uncertainty=\"scenario_bb13\")\n",
    "\n",
    "    U_out = xr.concat([U_scen_hs09, U_scen_bb13, U_model, U_ens], dim=\"uncertainty\")\n",
    "\n",
    "    U_out = U_out.assign_coords(time=year)\n",
    "\n",
    "    return U_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be05b1c7-1d46-4c73-aa33-0213ed4e80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forced_uc(metric, submetric, submetric_var, poly_path, deg, weighted, save_str):\n",
    "    \"\"\"\n",
    "    Calculate the uncertainty paritition of the forced response\n",
    "    for a given selection of parameters/settings\n",
    "    \"\"\"\n",
    "    if os.path.isfile(out_path + \"uncertainty_partitioning/\" + metric + \"_\" + save_str + \".nc\"):\n",
    "        return None\n",
    "\n",
    "    delayed_res = []\n",
    "\n",
    "    # carbonplan GARD-SV precip models\n",
    "    if metric in [\"wet\", \"dry\", \"hotdry\"]:\n",
    "        cbp_gard_models_in = cbp_gard_precip_models\n",
    "    else:\n",
    "        cbp_gard_models_in = cbp_gard_models\n",
    "\n",
    "    for year in range(2015, 2100):\n",
    "        # Read all ensembles and compute UC\n",
    "        tmp_res = dask.delayed(uc_forced)(\n",
    "            nex_in,\n",
    "            nex_models,\n",
    "            cil_in,\n",
    "            cil_models,\n",
    "            isi_in,\n",
    "            isi_models,\n",
    "            cbp_in,\n",
    "            cbp_gard_models_in,\n",
    "            cbp_deep_models,\n",
    "            land_mask,\n",
    "            metric,\n",
    "            submetric,\n",
    "            submetric_var,\n",
    "            year,\n",
    "            poly_path,\n",
    "            deg,\n",
    "            weighted,\n",
    "        )\n",
    "\n",
    "        # Append\n",
    "        delayed_res.append(tmp_res)\n",
    "\n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Merge and store\n",
    "    ds_out = xr.concat(res, dim=\"time\")\n",
    "    ds_out.to_netcdf(out_path + \"uncertainty_partitioning/\" + metric + \"_\" + save_str + \".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3d2b7-b917-4378-a8a2-f0fd337868c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Measure of interannual variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aecba2ce-53f7-43c1-a490-f590f5043ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iav(\n",
    "    path_in,\n",
    "    ensemble,\n",
    "    model,\n",
    "    land_mask,\n",
    "    metric,\n",
    "    submetric,\n",
    "    submetric_var,\n",
    "    poly_path,\n",
    "    deg,\n",
    "    const_iav,\n",
    "    iav_path,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the internal variability (variance over all years\n",
    "    of residuals from forced response) for a given model-ssp-ensemble\n",
    "    \"\"\"\n",
    "\n",
    "    # Subfunction for general preprocessing of each model/ensemble\n",
    "    def read_and_process(ensemble, path_in, model, metric, submetric, submetric_var):\n",
    "        # Read netcdf or zarr\n",
    "        if ensemble in [\"NEX\", \"ISIMIP\", \"GARD-SV\"]:\n",
    "            if submetric_var:\n",
    "                ds = xr.open_dataset(path_in + metric + \"/\" + model + \"_\" + submetric_var + \".nc\")\n",
    "            else:\n",
    "                ds = xr.open_dataset(path_in + metric + \"/\" + model + \".nc\")\n",
    "        elif ensemble in [\"CIL\", \"DeepSD-BC\"]:\n",
    "            ds = xr.open_dataset(path_in + metric + \"/\" + model, engine=\"zarr\")\n",
    "\n",
    "        # Some models/methods are missing precip so fill with NaNs\n",
    "        if (metric in [\"max\", \"avg\"]) and (\"pr\" not in ds.data_vars):\n",
    "            ds[\"pr\"] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "        if (metric == \"max5d\") and (\"RX5day\" not in ds.data_vars):\n",
    "            ds[\"RX5day\"] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "\n",
    "        # Select submetric if chosen\n",
    "        if submetric:\n",
    "            ds = ds[submetric]\n",
    "\n",
    "        # Common preprocessing\n",
    "        ds[\"time\"] = ds.indexes[\"time\"].year\n",
    "        ds = ds.sortby(\"ssp\")\n",
    "        ds = ds.assign_coords(ensmod=ensemble + \"__\" + model)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "\n",
    "        # Fix lon to [-180,180]\n",
    "        if ds.lon.max() > 180:\n",
    "            ds[\"lon\"] = np.where(ds[\"lon\"] > 180, ds[\"lon\"] - 360, ds[\"lon\"])\n",
    "            ds = ds.sortby(\"lon\")\n",
    "\n",
    "        # Drop member_id\n",
    "        if \"member_id\" in list(ds.coords):\n",
    "            ds = ds.isel(member_id=0).drop(\"member_id\")\n",
    "\n",
    "        # Return\n",
    "        return ds\n",
    "\n",
    "    #########################\n",
    "    # Check if already done\n",
    "    # for non-const case\n",
    "    #########################\n",
    "    if not const_iav:\n",
    "        out_str = iav_path + metric + \"/\"\n",
    "\n",
    "        if submetric:\n",
    "            submetric_str = submetric[0].replace(\"_count\", \"\").replace(\"_streak\", \"\")\n",
    "            out_str = out_str + submetric_str + \"_\"\n",
    "\n",
    "        if os.path.isfile(out_str + ensemble + \"_\" + model + \"_deg\" + str(deg) + \".nc\"):\n",
    "            return None\n",
    "\n",
    "    ###################\n",
    "    # Read raw outputs\n",
    "    ###################\n",
    "    ds = read_and_process(ensemble, path_in, model, metric, submetric, submetric_var)\n",
    "    # Mask out ocean points\n",
    "    ds = xr.where(land_mask, np.nan, ds)\n",
    "\n",
    "    ########################\n",
    "    # Read forced response\n",
    "    ########################\n",
    "    poly_str = poly_path + metric + \"/\"\n",
    "    if submetric:\n",
    "        submetric_str = submetric[0].replace(\"_count\", \"\").replace(\"_streak\", \"\")\n",
    "        poly_str = poly_str + submetric_str + \"_\"\n",
    "\n",
    "    ds_forced = xr.open_dataset(poly_str + ensemble + \"_\" + model + \"_deg\" + str(deg) + \".nc\")\n",
    "    ds_forced[\"time\"] = ds_forced.indexes[\"time\"].year\n",
    "\n",
    "    # Forced response should always be >= 0\n",
    "    if metric in [\"hot\", \"wet\", \"dry\", \"hotdry\"]:\n",
    "        ds_forced = xr.where(ds_forced >= 0, ds_forced, 0)\n",
    "\n",
    "    # Some models/methods are missing precip so fill with NaNs\n",
    "    if (metric in [\"max\", \"avg\"]) and (\"pr\" not in ds_forced.data_vars):\n",
    "        ds_forced[\"pr\"] = xr.full_like(ds_forced[list(ds_forced.data_vars)[0]], np.nan)\n",
    "    if (metric == \"max5d\") and (\"RX5day\" not in ds_forced.data_vars):\n",
    "        ds_forced[\"RX5day\"] = xr.full_like(ds_forced[list(ds_forced.data_vars)[0]], np.nan)\n",
    "\n",
    "    ################################\n",
    "    # Get IAV estimate\n",
    "    # Variance of residuals\n",
    "    ################################\n",
    "    # IAV can be constant value or rolling\n",
    "    if const_iav:\n",
    "        iav = (ds - ds_forced).var(dim=\"time\")\n",
    "        return iav\n",
    "    else:\n",
    "        iav = (ds - ds_forced).rolling(time=11, center=True).var()\n",
    "\n",
    "        iav.to_netcdf(out_str + ensemble + \"_\" + model + \"_deg\" + str(deg) + \".nc\")\n",
    "\n",
    "        # #### NOTE: these time slices need to be the same as for the UC map plot!\n",
    "        # iav_early = (ds - ds_forced).sel(time=slice(2020,2039)).var(dim='time').assign_coords(time = 'early')\n",
    "        # iav_mid = (ds - ds_forced).sel(time=slice(2050,2069)).var(dim='time').assign_coords(time = 'mid')\n",
    "        # iav_late = (ds - ds_forced).sel(time=slice(2080,2099)).var(dim='time').assign_coords(time = 'late')\n",
    "        # iav = xr.concat([iav_early, iav_mid, iav_late], dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc00adc-483b-446c-be5d-6ac0914f745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_delayed_list_iav(metric, submetric, submetric_var, poly_path, deg, const_iav, iav_path):\n",
    "    \"\"\"\n",
    "    Make a delayed list with IAV of all models-ssps-ensembles which\n",
    "    can then be combined into one dataset and averaged for best estimate.\n",
    "    \"\"\"\n",
    "    # Parallelize with dask over models\n",
    "    delayed_res = []\n",
    "\n",
    "    # NEX\n",
    "    for model in nex_models:\n",
    "        tmp_res = dask.delayed(calculate_iav)(\n",
    "            nex_in,\n",
    "            \"NEX\",\n",
    "            model,\n",
    "            land_mask,\n",
    "            metric,\n",
    "            submetric,\n",
    "            submetric_var,\n",
    "            poly_path,\n",
    "            deg,\n",
    "            const_iav,\n",
    "            iav_path,\n",
    "        )\n",
    "        delayed_res.append(tmp_res)\n",
    "\n",
    "    # CIL\n",
    "    for model in cil_models:\n",
    "        tmp_res = dask.delayed(calculate_iav)(\n",
    "            cil_in,\n",
    "            \"CIL\",\n",
    "            model,\n",
    "            land_mask,\n",
    "            metric,\n",
    "            submetric,\n",
    "            submetric_var,\n",
    "            poly_path,\n",
    "            deg,\n",
    "            const_iav,\n",
    "            iav_path,\n",
    "        )\n",
    "        delayed_res.append(tmp_res)\n",
    "\n",
    "    # ISIMIP\n",
    "    for model in isi_models:\n",
    "        tmp_res = dask.delayed(calculate_iav)(\n",
    "            isi_in,\n",
    "            \"ISIMIP\",\n",
    "            model,\n",
    "            land_mask,\n",
    "            metric,\n",
    "            submetric,\n",
    "            submetric_var,\n",
    "            poly_path,\n",
    "            deg,\n",
    "            const_iav,\n",
    "            iav_path,\n",
    "        )\n",
    "        delayed_res.append(tmp_res)\n",
    "\n",
    "    # carbonplan GARD-SV\n",
    "    if metric in [\"wet\", \"dry\", \"hotdry\"]:\n",
    "        models = cbp_gard_precip_models\n",
    "    else:\n",
    "        models = cbp_gard_models\n",
    "    for model in models:\n",
    "        tmp_res = dask.delayed(calculate_iav)(\n",
    "            cbp_in + \"/regridded/conservative/GARD-SV/\",\n",
    "            \"GARD-SV\",\n",
    "            model,\n",
    "            land_mask,\n",
    "            metric,\n",
    "            submetric,\n",
    "            submetric_var,\n",
    "            poly_path,\n",
    "            deg,\n",
    "            const_iav,\n",
    "            iav_path,\n",
    "        )\n",
    "        delayed_res.append(tmp_res)\n",
    "\n",
    "    # carbonplan DeepSD-BC\n",
    "    for model in cbp_deep_models:\n",
    "        tmp_res = dask.delayed(calculate_iav)(\n",
    "            cbp_in + \"native_grid/DeepSD-BC/\",\n",
    "            \"DeepSD-BC\",\n",
    "            model,\n",
    "            land_mask,\n",
    "            metric,\n",
    "            submetric,\n",
    "            submetric_var,\n",
    "            poly_path,\n",
    "            deg,\n",
    "            const_iav,\n",
    "            iav_path,\n",
    "        )\n",
    "        delayed_res.append(tmp_res)\n",
    "\n",
    "    # return\n",
    "    return delayed_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0408c55b-f1b3-4839-8974-78be95a15924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_iav(metric, submetric, submetric_var, poly_path, deg, const_iav, iav_path, save_str):\n",
    "    \"\"\"\n",
    "    Calculate the internal variability uncertainty\n",
    "    for a given selection of parameters/settings\n",
    "    \"\"\"\n",
    "    # Check if already done\n",
    "    if os.path.isfile(out_path + \"uncertainty_partitioning/\" + metric + \"_\" + save_str + \".nc\"):\n",
    "        return None\n",
    "\n",
    "    # Make delayed list\n",
    "    delayed_res = make_delayed_list_iav(\n",
    "        metric=metric,\n",
    "        submetric=submetric,\n",
    "        submetric_var=submetric_var,\n",
    "        poly_path=poly_path,\n",
    "        deg=deg,\n",
    "        const_iav=const_iav,\n",
    "        iav_path=iav_path,\n",
    "    )\n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    if const_iav:\n",
    "        # Merge and average over ensemble + model (ensmod) and ssp\n",
    "        ds_out = xr.concat(res, dim=\"ensmod\").mean(dim=[\"ensmod\", \"ssp\"])\n",
    "        ds_out.to_netcdf(out_path + \"uncertainty_partitioning/\" + metric + \"_\" + save_str + \".nc\")\n",
    "    else:\n",
    "        # If rolling IAV, each ensmod was saved individually so now read with dask\n",
    "        # and calculate average (otherwise would run out of memory)\n",
    "        out_str = iav_path + metric + \"/\"\n",
    "\n",
    "        if submetric:\n",
    "            submetric_str = submetric[0].replace(\"_count\", \"\").replace(\"_streak\", \"\")\n",
    "            out_str = out_str + submetric_str + \"_\"\n",
    "\n",
    "        with dask.config.set(**{\"array.slicing.split_large_chunks\": False}):\n",
    "            ds_out = xr.open_mfdataset(\n",
    "                out_str + \"*_deg\" + str(deg) + \".nc\",\n",
    "                combine=\"nested\",\n",
    "                concat_dim=\"ensmod\",\n",
    "                parallel=True,\n",
    "            )\n",
    "\n",
    "        ds_out = ds_out.mean(dim=[\"ensmod\", \"ssp\"])\n",
    "        ds_out.to_netcdf(out_path + \"uncertainty_partitioning/\" + metric + \"_\" + save_str + \".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c897ff-ddc7-44df-aa4d-13f65dee67f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69ab4c-263f-4ed8-ac43-c61a0ba02312",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"avg\"\n",
    "\n",
    "##############################\n",
    "# Get the forced response\n",
    "##############################\n",
    "for deg in [2, 4]:\n",
    "    get_forced_poly(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        False,\n",
    "        poly_path,\n",
    "        deg,\n",
    "    )\n",
    "\n",
    "##############################\n",
    "# Interannual variability\n",
    "##############################\n",
    "for deg in [2, 4]:\n",
    "    for const_iav in [True, False]:\n",
    "        calculate_all_iav(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            const_iav=const_iav,\n",
    "            iav_path=iav_path,\n",
    "            save_str=\"deg\" + str(deg) + \"_\" + (\"non\" * (not const_iav)) + \"const_iav\",\n",
    "        )\n",
    "\n",
    "#############################\n",
    "# UC on forced response\n",
    "#############################\n",
    "for deg in [2, 4]:\n",
    "    for weighted in [True, False]:\n",
    "        calculate_forced_uc(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            weighted=weighted,\n",
    "            save_str=\"deg\" + str(2) + \"_nonWeighted\" * (not weighted),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e6809-7610-45c9-9dbe-b8f73379da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"max\"\n",
    "\n",
    "#######################################\n",
    "# Get the forced response (polynomial)\n",
    "#######################################\n",
    "for deg in [2, 4]:\n",
    "    get_forced_poly(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        False,\n",
    "        poly_path,\n",
    "        deg,\n",
    "    )\n",
    "\n",
    "####################################\n",
    "# Interannual variability\n",
    "####################################\n",
    "for deg in [2, 4]:\n",
    "    for const_iav in [True, False]:\n",
    "        calculate_all_iav(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            const_iav=const_iav,\n",
    "            iav_path=iav_path,\n",
    "            save_str=\"deg\" + str(deg) + \"_\" + (\"non\" * (not const_iav)) + \"const_iav\",\n",
    "        )\n",
    "\n",
    "#############################\n",
    "# UC on forced response\n",
    "#############################\n",
    "for deg in [2, 4]:\n",
    "    for weighted in [True, False]:\n",
    "        calculate_forced_uc(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            weighted=weighted,\n",
    "            save_str=\"deg\" + str(2) + \"_nonWeighted\" * (not weighted),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cb11e-5caf-4227-aa34-8a0eab66b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"max5d\"\n",
    "\n",
    "#######################################\n",
    "# Get the forced response (polynomial)\n",
    "#######################################\n",
    "for deg in [2, 4]:\n",
    "    get_forced_poly(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        False,\n",
    "        poly_path,\n",
    "        deg,\n",
    "    )\n",
    "\n",
    "####################################\n",
    "# Interannual variability\n",
    "####################################\n",
    "for deg in [2, 4]:\n",
    "    for const_iav in [True, False]:\n",
    "        calculate_all_iav(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            const_iav=const_iav,\n",
    "            iav_path=iav_path,\n",
    "            save_str=\"deg\" + str(deg) + \"_\" + (\"non\" * (not const_iav)) + \"const_iav\",\n",
    "        )\n",
    "\n",
    "#############################\n",
    "# UC on forced response\n",
    "#############################\n",
    "for deg in [2, 4]:\n",
    "    for weighted in [True, False]:\n",
    "        calculate_forced_uc(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            weighted=weighted,\n",
    "            save_str=\"deg\" + str(2) + \"_nonWeighted\" * (not weighted),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8cfcf8-68dd-4a28-999d-83bf65aeea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "metric = \"dry\"\n",
    "\n",
    "#######################################\n",
    "# Get the forced response (polynomial)\n",
    "#######################################\n",
    "for deg in [2, 4]:\n",
    "    get_forced_poly(\n",
    "        nex_in,\n",
    "        nex_models,\n",
    "        cil_in,\n",
    "        cil_models,\n",
    "        isi_in,\n",
    "        isi_models,\n",
    "        cbp_in,\n",
    "        cbp_gard_precip_models,\n",
    "        cbp_deep_models,\n",
    "        land_mask,\n",
    "        metric,\n",
    "        False,\n",
    "        False,\n",
    "        poly_path,\n",
    "        deg,\n",
    "    )\n",
    "\n",
    "####################################\n",
    "# Interannual variability\n",
    "####################################\n",
    "for deg in [2, 4]:\n",
    "    for const_iav in [True, False]:\n",
    "        calculate_all_iav(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            const_iav=const_iav,\n",
    "            iav_path=iav_path,\n",
    "            save_str=\"deg\" + str(deg) + \"_\" + (\"non\" * (not const_iav)) + \"const_iav\",\n",
    "        )\n",
    "\n",
    "#############################\n",
    "# UC on forced response\n",
    "#############################\n",
    "for deg in [2, 4]:\n",
    "    for weighted in [True, False]:\n",
    "        calculate_forced_uc(\n",
    "            metric=metric,\n",
    "            submetric=False,\n",
    "            submetric_var=False,\n",
    "            poly_path=poly_path,\n",
    "            deg=deg,\n",
    "            weighted=weighted,\n",
    "            save_str=\"deg\" + str(2) + \"_nonWeighted\" * (not weighted),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6d358-4c11-4d48-b85b-283f73aed10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wet days\n",
    "metric = \"wet\"\n",
    "\n",
    "for thresh in [\"q99\", \"rp10\"]:\n",
    "    for obs in [\"gmfd\", \"era5\"]:\n",
    "        submetric_str = thresh + obs\n",
    "        submetric = [\n",
    "            \"pr_\" + submetric_str + \"_count\",\n",
    "            \"pr_\" + submetric_str + \"_streak\",\n",
    "        ]\n",
    "\n",
    "        #######################################\n",
    "        # Get the forced response (polynomial)\n",
    "        #######################################\n",
    "        for deg in [2, 4]:\n",
    "            get_forced_poly(\n",
    "                nex_in,\n",
    "                nex_models,\n",
    "                cil_in,\n",
    "                cil_models,\n",
    "                isi_in,\n",
    "                isi_models,\n",
    "                cbp_in,\n",
    "                cbp_gard_precip_models,\n",
    "                cbp_deep_models,\n",
    "                land_mask,\n",
    "                metric,\n",
    "                submetric,\n",
    "                False,\n",
    "                poly_path,\n",
    "                deg,\n",
    "            )\n",
    "\n",
    "        ####################################\n",
    "        # Interannual variability\n",
    "        ####################################\n",
    "        for deg in [2, 4]:\n",
    "            for const_iav in [True, False]:\n",
    "                calculate_all_iav(\n",
    "                    metric=metric,\n",
    "                    submetric=submetric,\n",
    "                    submetric_var=False,\n",
    "                    poly_path=poly_path,\n",
    "                    deg=deg,\n",
    "                    const_iav=const_iav,\n",
    "                    iav_path=iav_path,\n",
    "                    save_str=submetric_str + \"_deg\" + str(deg) + \"_\" + (\"non\" * (not const_iav)) + \"const_iav\",\n",
    "                )\n",
    "\n",
    "        ################################\n",
    "        # UC on forced response\n",
    "        ################################\n",
    "        for deg in [2, 4]:\n",
    "            for weighted in [True, False]:\n",
    "                calculate_forced_uc(\n",
    "                    metric=metric,\n",
    "                    submetric=submetric,\n",
    "                    submetric_var=False,\n",
    "                    poly_path=poly_path,\n",
    "                    deg=deg,\n",
    "                    weighted=weighted,\n",
    "                    save_str=\"deg\" + str(2) + \"_nonWeighted\" * (not weighted),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6718e-9c58-4d40-b842-a95c075f6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hot days\n",
    "metric = \"hot\"\n",
    "\n",
    "# Subselection of submetrics to analyze\n",
    "submetric_strs = [\n",
    "    \"tas_q99gmfd\",\n",
    "    \"tasmax_q99gmfd\",\n",
    "    \"tasmin_q99gmfd\",\n",
    "    \"tas_q99era5\",\n",
    "    \"tasmax_q99era5\",\n",
    "    \"tasmin_q99era5\",\n",
    "    \"tas_rp10gmfd\",\n",
    "    \"tasmax_rp10gmfd\",\n",
    "    \"tasmin_rp10gmfd\",\n",
    "]\n",
    "\n",
    "# for thresh in ['q99', 'rp10']:\n",
    "#     for obs in ['gmfd', 'era5']:\n",
    "#         for submetric_var in ['tas', 'tasmin', 'tasmax']:\n",
    "\n",
    "for submetric_str in submetric_strs:\n",
    "    if True:\n",
    "        if True:\n",
    "            # submetric_str = submetric_var + '_' + thresh + obs\n",
    "            submetric_var = submetric_str.split(\"_\")[0]\n",
    "            submetric = [submetric_str + \"_count\", submetric_str + \"_streak\"]\n",
    "\n",
    "            #######################################\n",
    "            # Get the forced response (polynomial)\n",
    "            #######################################\n",
    "            for deg in [2, 4]:\n",
    "                get_forced_poly(\n",
    "                    nex_in,\n",
    "                    nex_models,\n",
    "                    cil_in,\n",
    "                    cil_models,\n",
    "                    isi_in,\n",
    "                    isi_models,\n",
    "                    cbp_in,\n",
    "                    cbp_gard_models,\n",
    "                    cbp_deep_models,\n",
    "                    land_mask,\n",
    "                    metric,\n",
    "                    submetric,\n",
    "                    submetric_var,\n",
    "                    poly_path,\n",
    "                    deg,\n",
    "                )\n",
    "\n",
    "            ####################################\n",
    "            # Interannual variability\n",
    "            ####################################\n",
    "            for deg in [2, 4]:\n",
    "                for const_iav in [True, False]:\n",
    "                    calculate_all_iav(\n",
    "                        metric=metric,\n",
    "                        submetric=submetric,\n",
    "                        submetric_var=submetric_var,\n",
    "                        poly_path=poly_path,\n",
    "                        deg=deg,\n",
    "                        const_iav=const_iav,\n",
    "                        iav_path=iav_path,\n",
    "                        save_str=submetric_str + \"_deg\" + str(deg) + \"_\" + (\"non\" * (not const_iav)) + \"const_iav\",\n",
    "                    )\n",
    "\n",
    "            ################################\n",
    "            # UC on forced response\n",
    "            ################################\n",
    "            for deg in [2, 4]:\n",
    "                for weighted in [True, False]:\n",
    "                    calculate_forced_uc(\n",
    "                        metric=metric,\n",
    "                        submetric=submetric,\n",
    "                        submetric_var=submetric_var,\n",
    "                        poly_path=poly_path,\n",
    "                        deg=deg,\n",
    "                        weighted=weighted,\n",
    "                        save_str=\"deg\" + str(2) + \"_nonWeighted\" * (not weighted),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141ef95-11f8-4cee-af38-ff90cba490e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hot + dry days\n",
    "metric = \"hotdry\"\n",
    "\n",
    "for thresh in [\"q99\", \"rp10\"]:\n",
    "    for obs in [\"gmfd\", \"era5\"]:\n",
    "        submetric_str = thresh + obs\n",
    "        submetric = [\n",
    "            \"hotdry_\" + submetric_str + \"_count\",\n",
    "            \"hotdry_\" + submetric_str + \"_streak\",\n",
    "        ]\n",
    "\n",
    "        #######################################\n",
    "        # Get the forced response (polynomial)\n",
    "        #######################################\n",
    "        for deg in [2, 4]:\n",
    "            get_forced_poly(\n",
    "                nex_in,\n",
    "                nex_models,\n",
    "                cil_in,\n",
    "                cil_models,\n",
    "                isi_in,\n",
    "                isi_models,\n",
    "                cbp_in,\n",
    "                cbp_gard_precip_models,\n",
    "                cbp_deep_models,\n",
    "                land_mask,\n",
    "                metric,\n",
    "                submetric,\n",
    "                False,\n",
    "                poly_path,\n",
    "                deg,\n",
    "            )\n",
    "\n",
    "        ####################################\n",
    "        # Interannual variability\n",
    "        ####################################\n",
    "        for deg in [2, 4]:\n",
    "            for const_iav in [True, False]:\n",
    "                calculate_all_iav(\n",
    "                    metric=metric,\n",
    "                    submetric=submetric,\n",
    "                    submetric_var=False,\n",
    "                    poly_path=poly_path,\n",
    "                    deg=deg,\n",
    "                    const_iav=const_iav,\n",
    "                    iav_path=iav_path,\n",
    "                    save_str=submetric_str + \"_deg\" + str(deg) + \"_\" + (\"non\" * (not const_iav)) + \"const_iav\",\n",
    "                )\n",
    "\n",
    "        ################################\n",
    "        # UC on forced response\n",
    "        ################################\n",
    "        for deg in [2, 4]:\n",
    "            for weighted in [True, False]:\n",
    "                calculate_forced_uc(\n",
    "                    metric=metric,\n",
    "                    submetric=submetric,\n",
    "                    submetric_var=False,\n",
    "                    poly_path=poly_path,\n",
    "                    deg=deg,\n",
    "                    weighted=weighted,\n",
    "                    save_str=\"deg\" + str(2) + \"_nonWeighted\" * (not weighted),\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
