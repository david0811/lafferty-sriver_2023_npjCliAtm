{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57743a7e-8b68-4544-8378-ac3e453f96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f3946-bb89-4535-a1e8-ae9b6ccaed61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662dfbf5-61c7-48f6-884d-ce058d6a7512",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Set paths\n",
    "# UPDATE THIS FOR REPRODUCTION\n",
    "###############################\n",
    "nex_in = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/nex-gddp/'\n",
    "cil_in = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/cil-gdpcir/'\n",
    "isi_in = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/isimip3b/regridded/conservative/'\n",
    "cbp_in = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/carbonplan/'\n",
    "\n",
    "out_path = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/uc_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c50de8a-ea1e-4a9d-ad37-c522111ff76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Models\n",
    "###################\n",
    "from utils import nex_ssp_dict, cil_ssp_dict, isimip_ssp_dict, gardsv_ssp_dict, gardsv_var_dict, deepsdbc_dict\n",
    "\n",
    "nex_models = list(nex_ssp_dict.keys())\n",
    "cil_models = list(cil_ssp_dict.keys())\n",
    "isi_models = list(isimip_ssp_dict.keys())\n",
    "cbp_gard_models = list(gardsv_ssp_dict.keys())\n",
    "cbp_gard_precip_models = [model for model in cbp_gard_models if 'pr' in gardsv_var_dict[model]]\n",
    "cbp_deep_models = list(deepsdbc_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad43d2c-5706-40fa-a2b4-9e1f24782a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Land mask (from NEX)\n",
    "#######################\n",
    "land_mask = xr.open_dataset('/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/nex-gddp/avg/CanESM5.nc')\n",
    "land_mask = land_mask.isel(ssp=0, time=0).tas.isnull()\n",
    "land_mask['lon'] = np.where(land_mask['lon'] > 180, land_mask['lon'] - 360, land_mask['lon'])\n",
    "land_mask = land_mask.sortby('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1c47d5-5fb5-4648-aac2-a86cbb62fdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-7fe478af-65d0-11ed-92f4-34e6d79eac84</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">a58a1713</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-f7daf3b7-3d93-4f6e-bb8a-19b5b945b933</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.102.201.240:36293\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.102.201.240:36293' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Dask\n",
    "############\n",
    "from dask_jobqueue import PBSCluster\n",
    "\n",
    "cluster = PBSCluster(cores=1, memory='50GB', resource_spec='pmem=50GB',\n",
    "                     # account='open',\n",
    "                     worker_extra_args=['#PBS -l feature=rhel7'], \n",
    "                     walltime='00:10:00')\n",
    "\n",
    "cluster.scale(jobs=30)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f20699-35c7-4dbf-a8ad-ad73115785df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Total uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099faaa-43cd-4e3b-a541-8cf3dfb66379",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2c6626-3157-4eee-9847-5df9e74f459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Total uncertainty: variance across all models, scenarios, ensembles \n",
    "#######################################################################\n",
    "def uc_total(nex_in, nex_models, \n",
    "             cil_in, cil_models, \n",
    "             isi_in, isi_models, \n",
    "             cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "             land_mask,\n",
    "             metric, submetric,\n",
    "             year):\n",
    "    \"\"\"\n",
    "    Reads in all models, ssps, and calculates the total uncertainty (variance across\n",
    "    all model, ssp, ensemble dimensions) for a given year (and possibly DataArray).\n",
    "    For metrics like 'hot' where there are several sub-metrics based on different \n",
    "    thresholds and/or observational data, we need to select a specific DataArray\n",
    "    to keep the memory manageable.\n",
    "    \"\"\"\n",
    "    # Subfunction for general preprocessing of each model/ensemble\n",
    "    def read_and_process(ensemble, path_in, model, year, metric, submetric):\n",
    "        # Read netcdf or zarr\n",
    "        if ensemble in ['NEX', 'ISIMIP', 'GARD-SV']:\n",
    "            ds = xr.open_dataset(path_in + metric + '/' + model + '.nc')\n",
    "        elif ensemble in ['CIL', 'DeepSD-BC']:\n",
    "            ds = xr.open_dataset(path_in + metric + '/' + model, engine='zarr')\n",
    "            \n",
    "        \n",
    "        # Select submetric if chosen\n",
    "        if submetric:\n",
    "            ds = ds[submetric]\n",
    "    \n",
    "        # Common preprocessing\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sel(time=year)\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(ensemble = ensemble)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "        \n",
    "        # Add model dimension\n",
    "        if model[-6:] in ['tasmin', 'tasmax']:\n",
    "            model_str = model[:-7]\n",
    "        else:\n",
    "            model_str = model\n",
    "        ds = ds.assign_coords(model = model_str)\n",
    "        \n",
    "        # Fix lon to [-180,180]\n",
    "        if ds.lon.max() > 180:\n",
    "            ds['lon'] = np.where(ds['lon'] > 180, ds['lon'] - 360, ds['lon'])\n",
    "            ds = ds.sortby('lon')\n",
    "    \n",
    "        # Some models/methods are missing precip so fill with NaNs\n",
    "        if (metric in ['max', 'avg']) and ('pr' not in ds.data_vars):\n",
    "            ds['pr'] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "    \n",
    "        # Return\n",
    "        return ds\n",
    "\n",
    "    ######################\n",
    "    # Read all ensembles\n",
    "    ######################\n",
    "    # NEX-GDDP \n",
    "    ds_out = []\n",
    "    for model in nex_models:\n",
    "        ds_out.append(read_and_process('NEX', nex_in, model, year, metric, submetric))\n",
    "    ds_nex = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    # CIL-GDPCIR\n",
    "    ds_out = []\n",
    "    for model in cil_models:\n",
    "        ds_out.append(read_and_process('CIL', cil_in, model, year, metric, submetric))\n",
    "    ds_cil = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    # ISIMIP\n",
    "    ds_out = []\n",
    "    for model in isi_models:\n",
    "        ds_out.append(read_and_process('ISIMIP', isi_in, model, year, metric, submetric))\n",
    "    ds_isi = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    # carbonplan: GARD-SV\n",
    "    ds_out = []\n",
    "    for model in cbp_gard_models:\n",
    "        ds_out.append(read_and_process('GARD-SV', cbp_in + '/regridded/conservative/GARD-SV/', model, year, metric, submetric))\n",
    "    ds_cbp_gard = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "    \n",
    "    # carbonplan: DeepSD-BC\n",
    "    ds_out = []\n",
    "    for model in cbp_deep_models:\n",
    "        ds_out.append(read_and_process('DeepSD-BC', cbp_in + 'native_grid/DeepSD-BC/', model, year, metric, submetric))\n",
    "    ds_cbp_deep = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    ###########################\n",
    "    # Merge all and mask ocean\n",
    "    ###########################\n",
    "    ds = xr.concat([ds_nex, ds_cil, ds_isi, ds_cbp_gard, ds_cbp_deep],\n",
    "                       dim='ensemble', fill_value=np.nan)\n",
    "\n",
    "    # Mask out ocean points\n",
    "    ds = xr.where(land_mask, np.nan, ds)\n",
    "    \n",
    "    ##########################\n",
    "    # Uncertainty calculation\n",
    "    ##########################\n",
    "    ## Total uncertainty\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        U_total_true = ds.var(dim=['ensemble', 'ssp', 'model']) # throws warning when all NaNs\n",
    "\n",
    "    U_total_true = U_total_true.assign_coords(uncertainty = 'total_true')\n",
    "    \n",
    "    return U_total_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5b42a-fc3e-49d4-8763-7a7eb1840181",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb9a5cf-fef0-4b13-a893-c3abb8f8869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 7.45 s, total: 2min 4s\n",
      "Wall time: 11min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metric = 'avg'\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(nex_in, nex_models, \n",
    "                                     cil_in, cil_models, \n",
    "                                     isi_in, isi_models, \n",
    "                                     cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                     land_mask,\n",
    "                                     metric, False,\n",
    "                                     year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'total_uncertainty/' + metric + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e3cdc-5cc0-4784-8f7e-afd5f64d8f3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1-day maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a42be14-76c5-45c6-af3e-b3c3ac35d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 6.9 s, total: 1min 54s\n",
      "Wall time: 10min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metric = 'max'\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(nex_in, nex_models, \n",
    "                                     cil_in, cil_models, \n",
    "                                     isi_in, isi_models, \n",
    "                                     cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                     land_mask,\n",
    "                                     metric, False,\n",
    "                                     year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'total_uncertainty/' + metric +'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7da7f-ff91-4d97-8875-993a10c9a51e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5-day max (pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e3fad6-da49-4d22-8683-e48f26f2b166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.6 s, sys: 3.15 s, total: 58.7 s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metric = 'max5d'\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(nex_in, nex_models, \n",
    "                                     cil_in, cil_models, \n",
    "                                     isi_in, isi_models, \n",
    "                                     cbp_in, cbp_gard_precip_models, cbp_deep_models,\n",
    "                                     land_mask,\n",
    "                                     metric, False,\n",
    "                                     year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'total_uncertainty/' + metric +'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6a732-375d-4abd-aefe-810b447ab92c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d8af44-d0b6-4149-9fae-54bde897d272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 8.53 s, total: 1min 37s\n",
      "Wall time: 10min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metric = 'dry'\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(nex_in, nex_models, \n",
    "                                     cil_in, cil_models, \n",
    "                                     isi_in, isi_models, \n",
    "                                     cbp_in, cbp_gard_precip_models, cbp_deep_models,\n",
    "                                     land_mask,\n",
    "                                     metric, False,\n",
    "                                     year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'total_uncertainty/' + metric +'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4014b48-519c-4546-be70-9f01b3401784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2abd3c6-a8e8-42d4-9570-d731da1df337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 3.51 s, total: 33.6 s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wet days: 5yr RP\n",
    "metric = 'wet'\n",
    "submetric = ['pr_rp5gmfd_count', 'pr_rp5gmfd_streak']\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(nex_in, nex_models, \n",
    "                                     cil_in, cil_models, \n",
    "                                     isi_in, isi_models, \n",
    "                                     cbp_in, cbp_gard_precip_models, cbp_deep_models,\n",
    "                                     land_mask,\n",
    "                                     metric, submetric,\n",
    "                                     year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'total_uncertainty/' + metric + '_rp5gmfd.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909cad3-30ab-440c-b89a-9ea138eae528",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa52c48-19f3-466d-ab61-9b0b47f5691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.6 s, sys: 3.48 s, total: 51.1 s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hot days: 5yr RP GMFD tasmin\n",
    "metric = 'hot'\n",
    "submetric = ['tasmin_rp5gmfd_count', 'tasmin_rp5gmfd_streak']\n",
    "submetric_var = 'tasmin'\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(nex_in, [model + '_' + submetric_var for model in nex_models], \n",
    "                                     cil_in, cil_models, \n",
    "                                     isi_in, [model + '_' + submetric_var for model in isi_models], \n",
    "                                     cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                     land_mask,\n",
    "                                     metric, submetric, \n",
    "                                     year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'total_uncertainty/' + metric + '_' + submetric_var + '_rp5gmfd.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e731cea0-36b1-4a66-9061-6a9a9c4e2023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.8 s, sys: 2.8 s, total: 47.6 s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hot days: tasmax 5yr GMFD RP\n",
    "metric = 'hot'\n",
    "submetric = ['tasmax_rp5gmfd_count', 'tasmax_rp5gmfd_streak']\n",
    "submetric_var = 'tasmax'\n",
    "\n",
    "# Dask delayed over years\n",
    "delayed_res = []\n",
    "for year in range(2015, 2100):\n",
    "    # Read all ensembles and compute total uncertainty\n",
    "    tmp_res = dask.delayed(uc_total)(nex_in, [model + '_' + submetric_var for model in nex_models], \n",
    "                                     cil_in, cil_models, \n",
    "                                     isi_in, [model + '_' + submetric_var for model in isi_models], \n",
    "                                     cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                     land_mask,\n",
    "                                     metric, submetric, \n",
    "                                     year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'total_uncertainty/' + metric + '_' + submetric_var + '_rp5gmfd.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb443a5-6422-4597-b3b7-3d83e4e857a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# UC without interannual variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830e1b1a-ee79-417b-b048-a08c0cc43ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# Uncertainty characterization following Hawkins & Sutton 2009 \n",
    "# No consideration of internal variability!\n",
    "################################################################\n",
    "def uc_hs09(nex_in, nex_models, \n",
    "            cil_in, cil_models, \n",
    "            isi_in, isi_models, \n",
    "            cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "            metric, year):\n",
    "    ##################################\n",
    "    # Read and format all ensembles\n",
    "    ##################################\n",
    "    # NEX-GDDP \n",
    "    ds_out = []\n",
    "    for model in nex_models:\n",
    "        ds = xr.open_dataset(nex_in + metric + '/' + model + '.nc')\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sel(time=year)\n",
    "        ds['lon'] = np.where(ds['lon'] > 180, ds['lon'] - 360, ds['lon'])\n",
    "        ds = ds.sortby('lon')\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(ensemble = 'NEX')\n",
    "        ds = ds.assign_coords(model = ds.encoding['source'].replace(nex_in, '').split('/')[-1][:-3])\n",
    "        ds_out.append(ds)\n",
    "    ds_nex = xr.concat(ds_out, dim='model', compat='identical')\n",
    "\n",
    "    # CIL-GDPCIR\n",
    "    ds_out = []\n",
    "    for model in cil_models:\n",
    "        ds = xr.open_dataset(cil_in + metric + '/' + model, engine='zarr')\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sel(time=year)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "        ds = ds.assign_coords(ensemble = 'CIL')\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(model = ds.encoding['source'].replace(cil_in, '').split('/')[-1])\n",
    "        ds_out.append(ds)\n",
    "    ds_cil = xr.concat(ds_out, dim='model', compat='identical')\n",
    "\n",
    "    # ISIMIP\n",
    "    ds_out = []\n",
    "    for model in isi_models:\n",
    "        ds = xr.open_dataset(isi_in + metric + '/' + model + '.nc')\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sel(time=year)\n",
    "        ds['lon'] = np.where(ds['lon'] > 180, ds['lon'] - 360, ds['lon'])\n",
    "        ds = ds.sortby('lon')\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(ensemble = 'ISIMIP')\n",
    "        ds = ds.assign_coords(model = ds.encoding['source'].replace(isi_in, '').split('/')[-1][:-3])\n",
    "        ds_out.append(ds)\n",
    "    ds_isi = xr.concat(ds_out, dim='model', compat='identical')\n",
    "\n",
    "    # carbonplan: GARD-SV\n",
    "    ds_out = []\n",
    "    for model in cbp_gard_models:\n",
    "        ds = xr.open_dataset(cbp_in + 'GARD-SV/' + metric + '/' + model + '.nc')\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sel(time=year)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(ensemble = 'GARD-SV')\n",
    "        ds = ds.assign_coords(model = ds.encoding['source'].replace(cbp_in, '').split('/')[-1][:-3])\n",
    "        # for some models/methods we are missing \n",
    "        # precip so need to fill with NaNs\n",
    "        if 'pr' not in ds.data_vars:\n",
    "            ds['pr'] = xr.full_like(ds['tas'], np.NaN)\n",
    "        ds_out.append(ds)\n",
    "    ds_cbp_gard = xr.concat(ds_out, dim='model', compat='identical')\n",
    "    \n",
    "    # carbonplan: DeepSD-BC\n",
    "    ds_out = []\n",
    "    for model in cbp_deep_models:\n",
    "        ds = xr.open_dataset(cbp_in + 'DeepSD-BC/' + metric + '/' + model + '.nc')\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sel(time=year)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(ensemble = 'DeepSD-BC')\n",
    "        ds = ds.assign_coords(model = ds.encoding['source'].replace(cbp_in, '').split('/')[-1][:-3])\n",
    "        # for some models/methods we are missing \n",
    "        # precip so need to fill with NaNs\n",
    "        if 'pr' not in ds.data_vars:\n",
    "            ds['pr'] = xr.full_like(ds['tas'], np.NaN)\n",
    "        ds_out.append(ds)\n",
    "    ds_cbp_deep = xr.concat(ds_out, dim='model', compat='identical')\n",
    "\n",
    "    ###########################\n",
    "    # Merge all and mask ocean\n",
    "    ###########################\n",
    "    ds = xr.concat([ds_nex, ds_cil, ds_isi, ds_cbp_gard, ds_cbp_deep],\n",
    "                       dim='ensemble', fill_value=np.nan)\n",
    "    \n",
    "    # mask out ocean points (NEX is only available over land)\n",
    "    ds_mask = ds.sel(ensemble='NEX').isel(ssp=0, model=0)[list(ds.keys())[0]].isnull()\n",
    "    ds = xr.where(ds_mask, np.nan, ds)\n",
    "    \n",
    "    ##########################\n",
    "    # Uncertainty calculation\n",
    "    ##########################\n",
    "    ##  Model uncertainty\n",
    "    # Variance across models, averaged over scenarios and ensembles\n",
    "    U_model = ds.var(dim='model')\n",
    "    weights = ds.isel(lat=300, lon=800)[list(ds.data_vars)[0]].count(dim='model').rename('weights')     # weights (choose point over land)\n",
    "    weights = xr.where(weights == 1, 0, weights) # remove combinations where variance was calculated over 1 entry\n",
    "    U_model = U_model.weighted(weights).mean(dim=['ssp', 'ensemble']) # weighted average\n",
    "\n",
    "    ## Scenario uncertainty\n",
    "    # Variance across multi-model means (HS09 approach)\n",
    "    U_scen = ds.mean(dim=['model', 'ensemble']).var(dim='ssp')\n",
    "\n",
    "    ## Downscaling uncertainy\n",
    "    # Variance across ensembles, averaged over models and scenarios\n",
    "    U_ens = ds.var(dim='ensemble')\n",
    "    weights = ds.isel(lat=300, lon=800)[list(ds.data_vars)[0]].count(dim='ensemble').rename('weights') # weights\n",
    "    weights = xr.where(weights == 1, 0, weights) # remove combinations where variance was calculated over 1 entry\n",
    "    U_ens = U_ens.weighted(weights).mean(dim=['ssp', 'model'])\n",
    "\n",
    "    ## Total uncertainty    \n",
    "    # Our 'simulated' total uncertainty\n",
    "    # This will in general not equal true total\n",
    "    U_total = U_model + U_scen + U_ens\n",
    "\n",
    "    ## Merge and return\n",
    "    U_model = U_model.assign_coords(uncertainty = 'model')\n",
    "    U_scen = U_scen.assign_coords(uncertainty = 'scenario')\n",
    "    U_ens = U_ens.assign_coords(uncertainty = 'ensemble')\n",
    "    U_total = U_total_sim.assign_coords(uncertainty = 'total')\n",
    "    \n",
    "    return xr.concat([U_model, U_scen, U_ens, U_total, U_total], dim='uncertainty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b61a306-665b-40c4-8024-57c20a3364ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbeead59-5a74-4f7b-89c3-f0e819715d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'avg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84b78327-13ae-472f-93a7-4b2c28ec4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on raw outputs (no iav)\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2015, 2101):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09)(nex_in, nex_models, \n",
    "                                    cil_in, cil_models, \n",
    "                                    isi_in, isi_models, \n",
    "                                    cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                    metric, year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_no_iav/' + metric +'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25831023-fd72-43ee-b37e-004bcf01683f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annual maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c04bef-2ae7-480f-abcd-b82482b2d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0ebc7a-482d-482f-8ff4-fbd96058a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 9.44 s, total: 24.8 s\n",
      "Wall time: 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on raw outputs (no iav)\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2015, 2101):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09)(nex_in, nex_models, \n",
    "                                    cil_in, cil_models, \n",
    "                                    isi_in, isi_models, \n",
    "                                    cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                    metric, year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_no_iav/' + metric +'.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791ed2a-a415-44a6-ba57-6ec6589e454c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# UC with interannual variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f835b0-9cf4-46f0-8167-189063ca1d97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f612e0f3-8e82-4d6d-847b-19eae4bac017",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# Uncertainty characterization following Hawkins & Sutton 2009 \n",
    "# 'Forced response' = 10 year rolling mean\n",
    "################################################################\n",
    "def uc_hs09_forced(nex_in, nex_models, \n",
    "                   cil_in, cil_models, \n",
    "                   isi_in, isi_models, \n",
    "                   cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                   land_mask,\n",
    "                   metric, submetric, \n",
    "                   year):\n",
    "    \"\"\"\n",
    "    Reads in all models, ssps, and calculates the uncertainty in the 'forced response'\n",
    "    (10 year rolling mean) along each dimension for a given year (and possibly DataArray).\n",
    "    For metrics like 'hot' where there are several sub-metrics based on different \n",
    "    thresholds and/or observational data, we need to select a specific DataArray\n",
    "    to keep the memory manageable.\n",
    "    \"\"\"\n",
    "    # Subfunction for general preprocessing of each model/ensemble\n",
    "    def read_and_process(ensemble, path_in, model, year, metric, submetric):\n",
    "        # Read netcdf or zarr\n",
    "        if ensemble in ['NEX', 'ISIMIP', 'GARD-SV']:\n",
    "            ds = xr.open_dataset(path_in + metric + '/' + model + '.nc')\n",
    "        elif ensemble in ['CIL', 'DeepSD-BC']:\n",
    "            ds = xr.open_dataset(path_in + metric + '/' + model, engine='zarr')\n",
    "            \n",
    "        \n",
    "        # Select submetric if chosen\n",
    "        if submetric:\n",
    "            ds = ds[submetric]\n",
    "    \n",
    "        # Common preprocessing\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sel(time=slice(year-5, year+5)) # faster rolling mean\n",
    "        ds = ds.rolling(time=11, center=True).mean().sel(time=year)\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(ensemble = ensemble)\n",
    "        ds = ds.assign_coords(model = model)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "    \n",
    "        # Fix lon to [-180,180]\n",
    "        if ds.lon.max() > 180:\n",
    "            ds['lon'] = np.where(ds['lon'] > 180, ds['lon'] - 360, ds['lon'])\n",
    "            ds = ds.sortby('lon')\n",
    "    \n",
    "        # Some models/methods are missing precip so fill with NaNs\n",
    "        if (metric in ['max', 'avg']) and ('pr' not in ds.data_vars):\n",
    "            ds['pr'] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "    \n",
    "        # Return\n",
    "        return ds\n",
    "\n",
    "    ######################\n",
    "    # Read all ensembles\n",
    "    ######################\n",
    "    # NEX-GDDP \n",
    "    ds_out = []\n",
    "    for model in nex_models:\n",
    "        ds_out.append(read_and_process('NEX', nex_in, model, year, metric, submetric))\n",
    "    ds_nex = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    # CIL-GDPCIR\n",
    "    ds_out = []\n",
    "    for model in cil_models:\n",
    "        ds_out.append(read_and_process('CIL', cil_in, model, year, metric, submetric))\n",
    "    ds_cil = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    # ISIMIP\n",
    "    ds_out = []\n",
    "    for model in isi_models:\n",
    "        ds_out.append(read_and_process('ISIMIP', isi_in, model, year, metric, submetric))\n",
    "    ds_isi = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    # carbonplan: GARD-SV\n",
    "    ds_out = []\n",
    "    for model in cbp_gard_models:\n",
    "        ds_out.append(read_and_process('GARD-SV', cbp_in + '/regridded/conservative/GARD-SV/', model, year, metric, submetric))\n",
    "    ds_cbp_gard = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "    \n",
    "    # carbonplan: DeepSD-BC\n",
    "    ds_out = []\n",
    "    for model in cbp_deep_models:\n",
    "        ds_out.append(read_and_process('DeepSD-BC', cbp_in + 'native_grid/DeepSD-BC/', model, year, metric, submetric))\n",
    "    ds_cbp_deep = xr.concat(ds_out, dim='model', fill_value=np.nan)\n",
    "\n",
    "    ###########################\n",
    "    # Merge all and mask ocean\n",
    "    ###########################\n",
    "    ds = xr.concat([ds_nex, ds_cil, ds_isi, ds_cbp_gard, ds_cbp_deep],\n",
    "                       dim='ensemble', fill_value=np.nan)\n",
    "    ds = xr.where(land_mask, np.nan, ds)\n",
    "    \n",
    "    ##########################\n",
    "    # Uncertainty calculation\n",
    "    ##########################\n",
    "    ##  Model uncertainty\n",
    "    # Variance across models, averaged over scenarios and ensembles\n",
    "    U_model = ds.var(dim='model')\n",
    "    weights = ds.isel(lat=300, lon=800)[list(ds.data_vars)[0]].count(dim='model').rename('weights') # weights (choose point over land)\n",
    "    weights = xr.where(weights == 1, 0, weights) # remove combinations where variance was calculated over 1 entry\n",
    "    U_model = U_model.weighted(weights).mean(dim=['ssp', 'ensemble']) # weighted average\n",
    "\n",
    "    ## Scenario uncertainty\n",
    "    # Variance across multi-model means (HS09 approach)\n",
    "    U_scen = ds.mean(dim=['model', 'ensemble']).var(dim='ssp')\n",
    "\n",
    "    ## Downscaling uncertainy\n",
    "    # Variance across ensembles, averaged over models and scenarios\n",
    "    U_ens = ds.var(dim='ensemble')\n",
    "    weights = ds.isel(lat=300, lon=800)[list(ds.data_vars)[0]].count(dim='ensemble').rename('weights') # weights\n",
    "    weights = xr.where(weights == 1, 0, weights) # remove combinations where variance was calculated over 1 entry\n",
    "    U_ens = U_ens.weighted(weights).mean(dim=['ssp', 'model'])\n",
    "\n",
    "    ## Merge and return\n",
    "    U_model = U_model.assign_coords(uncertainty = 'model')\n",
    "    U_scen = U_scen.assign_coords(uncertainty = 'scenario')\n",
    "    U_ens = U_ens.assign_coords(uncertainty = 'ensemble')\n",
    "    \n",
    "    return xr.concat([U_model, U_scen, U_ens], dim='uncertainty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b210d705-e5cf-4ff4-9a47-fcc171bc699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# Uncertainty characterization following Hawkins & Sutton 2009 \n",
    "# Interannual variability (single value for all years)\n",
    "################################################################\n",
    "def uc_hs09_iav(path_in, ensemble, model, land_mask, metric, submetric):\n",
    "    \"\"\"\n",
    "    Calculates the internal variability (variance over all years\n",
    "    of residuals from rolling mean) for a given model-ssp-ensemble\n",
    "    \"\"\"\n",
    "    # Subfunction for general preprocessing of each model/ensemble\n",
    "    def read_and_process(ensemble, path_in, model, metric, submetric):\n",
    "        # Read netcdf or zarr\n",
    "        if ensemble in ['NEX', 'ISIMIP', 'GARD-SV']:\n",
    "            ds = xr.open_dataset(path_in + metric + '/' + model + '.nc')\n",
    "        elif ensemble in ['CIL', 'DeepSD-BC']:\n",
    "            ds = xr.open_dataset(path_in + metric + '/' + model, engine='zarr')\n",
    "            \n",
    "        # Select submetric if chosen\n",
    "        if submetric:\n",
    "            ds = ds[submetric]\n",
    "    \n",
    "        # Common preprocessing\n",
    "        ds['time'] = ds.indexes['time'].year\n",
    "        ds = ds.sortby('ssp')\n",
    "        ds = ds.assign_coords(ensmod = ensemble + '__' + model)\n",
    "        ds = ds.sel(lat=slice(-60, 90))\n",
    "    \n",
    "        # Fix lon to [-180,180]\n",
    "        if ds.lon.max() > 180:\n",
    "            ds['lon'] = np.where(ds['lon'] > 180, ds['lon'] - 360, ds['lon'])\n",
    "            ds = ds.sortby('lon')\n",
    "    \n",
    "        # Some models/methods are missing precip so fill with NaNs\n",
    "        if (metric in ['max', 'avg']) and ('pr' not in ds.data_vars):\n",
    "            ds['pr'] = xr.full_like(ds[list(ds.data_vars)[0]], np.nan)\n",
    "    \n",
    "        # Return\n",
    "        return ds\n",
    "\n",
    "    ###############\n",
    "    # Read model\n",
    "    ###############\n",
    "    ds = read_and_process(ensemble, path_in, model, metric, submetric)\n",
    "    # Mask out ocean points\n",
    "    ds = xr.where(land_mask, np.nan, ds)\n",
    "            \n",
    "    #####################################\n",
    "    # Get IAV estimate\n",
    "    # Variance of rolling mean residuals\n",
    "    #####################################\n",
    "    ds_rolling = ds.rolling(time=11, center=True).mean().sel(time=slice(2020,2094))\n",
    "    return (ds - ds_rolling).var(dim='time')\n",
    "\n",
    "\n",
    "def make_delayed_list_iav(metric, submetric, submetric_var):\n",
    "    \"\"\"\n",
    "    Make a delayed list with IAV of all models-ssps-ensembles which \n",
    "    can then be combined into one dataset and averaged for best estimate.\n",
    "    \"\"\"\n",
    "    # Parallelize with dask over models\n",
    "    delayed_res = []\n",
    "    \n",
    "    # NEX\n",
    "    if submetric_var:\n",
    "        models = [model + '_' + submetric_var for model in nex_models]\n",
    "    else:\n",
    "        models = nex_models\n",
    "    for model in models:\n",
    "        tmp_res = dask.delayed(uc_hs09_iav)(nex_in, 'NEX', model, land_mask, metric, submetric)\n",
    "        delayed_res.append(tmp_res)\n",
    "        \n",
    "    # CIL\n",
    "    for model in cil_models:\n",
    "        tmp_res = dask.delayed(uc_hs09_iav)(cil_in, 'CIL', model, land_mask, metric, submetric)\n",
    "        delayed_res.append(tmp_res)\n",
    "        \n",
    "    # ISIMIP\n",
    "    if submetric_var:\n",
    "        models = [model + '_' + submetric_var for model in isi_models]\n",
    "    else:\n",
    "        models = isi_models\n",
    "    for model in models:\n",
    "        tmp_res = dask.delayed(uc_hs09_iav)(isi_in, 'ISIMIP', model, land_mask, metric, submetric)\n",
    "        delayed_res.append(tmp_res)\n",
    "        \n",
    "    # carbonplan GARD-SV\n",
    "    if metric in ['wet', 'dry', 'max5d']:\n",
    "        models = cbp_gard_precip_models\n",
    "    else:\n",
    "        models = cbp_gard_models\n",
    "        \n",
    "    for model in models:\n",
    "        tmp_res = dask.delayed(uc_hs09_iav)(cbp_in + '/regridded/conservative/GARD-SV/', 'GARD-SV', model, land_mask, metric, submetric)\n",
    "        delayed_res.append(tmp_res)\n",
    "        \n",
    "    # carbonplan DeepSD-BC\n",
    "    for model in cbp_deep_models:\n",
    "        tmp_res = dask.delayed(uc_hs09_iav)(cbp_in + 'native_grid/DeepSD-BC/', 'DeepSD-BC', model, land_mask, metric, submetric)\n",
    "        delayed_res.append(tmp_res)\n",
    "        \n",
    "    # return\n",
    "    return delayed_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a15c7-7b8c-4005-8855-a771f4649fc3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c75f14-322b-4e1d-b642-e429e7fbdaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'avg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d39e8e9-7b05-40ad-b5eb-56e945cffd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.9 s, sys: 15 s, total: 1min 14s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# Interannual variability\n",
    "################################\n",
    "delayed_res = make_delayed_list_iav(metric, False, False)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and average over ensemble + model (ensmod) and ssp\n",
    "ds_out = xr.concat(res, dim='ensmod').mean(dim=['ensmod', 'ssp'])\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_iav.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750aae98-913c-48e6-9868-201d7bd01b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 25 s, total: 2min 58s\n",
      "Wall time: 13min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on forced response\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2020, 2095):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09_forced)(nex_in, nex_models, \n",
    "                                           cil_in, cil_models, \n",
    "                                           isi_in, isi_models, \n",
    "                                           cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                           land_mask,\n",
    "                                           metric, False,\n",
    "                                           year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dd321-2169-466e-8cef-ed20d0ede997",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a260c81-0ea8-4510-84cc-8fd7f0490d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c78b45-049e-4665-becf-f294c8a96bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.7 s, sys: 12.3 s, total: 1min 4s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# Interannual variability\n",
    "################################\n",
    "delayed_res = make_delayed_list_iav(metric, False, False)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and average over ensemble + model (ensmod) and ssp\n",
    "ds_out = xr.concat(res, dim='ensmod').mean(dim=['ensmod', 'ssp'])\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_iav.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "702d89a9-23cd-4d42-84e8-fd039d6e2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 37s, sys: 24 s, total: 3min 1s\n",
      "Wall time: 13min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on forced response\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2020, 2095):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09_forced)(nex_in, nex_models, \n",
    "                                           cil_in, cil_models, \n",
    "                                           isi_in, isi_models, \n",
    "                                           cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                           land_mask,\n",
    "                                           metric, False,\n",
    "                                           year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a0e9b-be46-4700-a3c0-24b38ff7e175",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5-day max (pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2868edaf-e40d-4faf-bebf-0c0160bbea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'max5d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36a17e97-d3c5-420c-b549-99f534b8ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.1 s, sys: 4.77 s, total: 50.9 s\n",
      "Wall time: 3min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# Interannual variability\n",
    "################################\n",
    "delayed_res = make_delayed_list_iav(metric, False, False)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and average over ensemble + model (ensmod) and ssp\n",
    "ds_out = xr.concat(res, dim='ensmod').mean(dim=['ensmod', 'ssp'])\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_iav.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb1e6ae8-40b2-45e5-a82a-922af43fbeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.6 s, sys: 4.87 s, total: 1min\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on forced response\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2020, 2095):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09_forced)(nex_in, nex_models, \n",
    "                                           cil_in, cil_models, \n",
    "                                           isi_in, isi_models, \n",
    "                                           cbp_in, cbp_gard_precip_models, cbp_deep_models,\n",
    "                                           land_mask,\n",
    "                                           metric, False,\n",
    "                                           year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a85a3-825c-4964-87e4-9387da6ed0c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef59571a-64f4-4247-b3ae-1219c9d0fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'dry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e465261-aebd-4acf-b82f-055180485061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 22.5 s, total: 1min 27s\n",
      "Wall time: 7min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# Interannual variability\n",
    "################################\n",
    "delayed_res = make_delayed_list_iav(metric, False, False)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and average over ensemble + model (ensmod) and ssp\n",
    "ds_out = xr.concat(res, dim='ensmod').mean(dim=['ensmod', 'ssp'])\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_iav.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1bfb575-dbdd-4611-8778-1aed2a926d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 37s, sys: 32.6 s, total: 6min 9s\n",
      "Wall time: 34min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on forced response\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2020, 2095):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09_forced)(nex_in, nex_models, \n",
    "                                           cil_in, cil_models, \n",
    "                                           isi_in, isi_models, \n",
    "                                           cbp_in, cbp_gard_precip_models, cbp_deep_models,\n",
    "                                           land_mask,\n",
    "                                           metric, False,\n",
    "                                           year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1eb7e-3dd8-4019-93ab-fbbef41522d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3dadb1-6a27-4a75-b420-4726aac8c505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba6563d-4723-4751-af57-6a48abd93502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa032df-170e-49ea-805f-5878bf8fe6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bdd541-280a-4749-a872-756191dbae10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0fe7be4-f502-4292-a202-ef3652d0ee13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Wet days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c0e67-9e3a-4dee-92d9-cb984acfd64f",
   "metadata": {},
   "source": [
    "### 5yr GMFD RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf7b907-ba27-4b59-b917-6fe1f87432de",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'wet'\n",
    "submetric = ['pr_rp5gmfd_count', 'pr_rp5gmfd_streak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8c9456e-4135-444c-85ac-d196740fbcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 6.51 s, total: 33.4 s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# Interannual variability\n",
    "################################\n",
    "delayed_res = make_delayed_list_iav(metric, submetric, False)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and average over ensemble + model (ensmod) and ssp\n",
    "ds_out = xr.concat(res, dim='ensmod').mean(dim=['ensmod', 'ssp'])\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_rp5gmfd_iav.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "646439de-b610-45fe-a036-82857a0fbbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 11.8 s, total: 1min 18s\n",
      "Wall time: 9min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on forced response\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2020, 2095):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09_forced)(nex_in, nex_models, \n",
    "                                           cil_in, cil_models, \n",
    "                                           isi_in, isi_models, \n",
    "                                           cbp_in, cbp_gard_precip_models, cbp_deep_models,\n",
    "                                           land_mask,\n",
    "                                           metric, submetric,\n",
    "                                           year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_rp5gmfd.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa8f6f-b1ef-44e0-a31d-0abb5721a631",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Hot days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c39e2-0f7a-4db3-8315-af9f89ce7e2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tasmax GMFD RP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a40955ae-268a-40ea-b712-de0c1c5e167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'hot'\n",
    "submetric = ['tasmax_rp5gmfd_count', 'tasmax_rp5gmfd_streak']\n",
    "submetric_var = 'tasmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30cd6e7f-731c-4ee7-b13f-c135d378c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 8.2 s, total: 34.7 s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# Interannual variability\n",
    "################################\n",
    "delayed_res = make_delayed_list_iav(metric, submetric, submetric_var)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and average over ensemble + model (ensmod) and ssp\n",
    "ds_out = xr.concat(res, dim='ensmod').mean(dim=['ensmod', 'ssp'])\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_' + submetric_var + '_rp5gmfd_iav.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53692b49-afbb-4ac7-a078-876d36607f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 7.31 s, total: 1min 45s\n",
      "Wall time: 10min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on forced response\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2020, 2095):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09_forced)(nex_in, [model + '_' + submetric_var for model in nex_models], \n",
    "                                           cil_in, cil_models, \n",
    "                                           isi_in, [model + '_' + submetric_var for model in isi_models], \n",
    "                                           cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                           land_mask,\n",
    "                                           metric, submetric,\n",
    "                                           year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_' + submetric_var + '_rp5gmfd.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21b027-ec55-4b33-8358-744f7b13d4f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tasmin GMFD RP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e748830-0ff9-4fb9-980d-8a016eb91245",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'hot'\n",
    "submetric = ['tasmin_rp5gmfd_count', 'tasmin_rp5gmfd_streak']\n",
    "submetric_var = 'tasmin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a783e0de-0091-4cdf-a735-959b35a20faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.2 s, sys: 8.01 s, total: 32.2 s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# Interannual variability\n",
    "################################\n",
    "delayed_res = make_delayed_list_iav(metric, submetric, submetric_var)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and average over ensemble + model (ensmod) and ssp\n",
    "ds_out = xr.concat(res, dim='ensmod').mean(dim=['ensmod', 'ssp'])\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_' + submetric_var + '_rp5gmfd_iav.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c1e03d4-973c-4b31-bf81-ce0a40bed74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 6.92 s, total: 1min 40s\n",
      "Wall time: 10min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "################################\n",
    "# UC on forced response\n",
    "################################\n",
    "delayed_res = []\n",
    "for year in range(2020, 2095):\n",
    "    # Read all ensembles and compute UC\n",
    "    tmp_res = dask.delayed(uc_hs09_forced)(nex_in, [model + '_' + submetric_var for model in nex_models], \n",
    "                                           cil_in, cil_models, \n",
    "                                           isi_in, [model + '_' + submetric_var for model in isi_models], \n",
    "                                           cbp_in, cbp_gard_models, cbp_deep_models,\n",
    "                                           land_mask,\n",
    "                                           metric, submetric,\n",
    "                                           year)\n",
    "    \n",
    "    # Append\n",
    "    delayed_res.append(tmp_res)\n",
    "    \n",
    "# Compute\n",
    "res = dask.compute(*delayed_res)\n",
    "\n",
    "# Merge and store\n",
    "ds_out = xr.concat(res, dim='time')\n",
    "ds_out.to_netcdf(out_path + 'hs09_iav/' + metric + '_' + submetric_var + '_rp5gmfd.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f719b-cf4a-43b0-8fbc-aa0c0aed25f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
