{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "010dc88c-5348-4f20-b016-f5de6aa3121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import xclim\n",
    "xclim.set_options(cf_compliance=\"log\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527e008-f356-43f0-bd69-e949bbc5afed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dccce93-c392-4a92-b317-d9a37641eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Set paths\n",
    "# UPDATE THIS FOR REPRODUCTION\n",
    "###############################\n",
    "in_path = '/gpfs/group/kaf26/default/dcl5300/ISIMIP3b_input_climate_data/files/'\n",
    "out_path = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/isimip3b/'\n",
    "quantile_path = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/quantiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88b6d653-0e6d-4d29-9d58-cf4e1f64334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Models\n",
    "###################\n",
    "from utils import isimip_ssp_dict\n",
    "\n",
    "models = list(isimip_ssp_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07a2aab6-e052-453d-9a4a-2716cf141928",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# File year layout\n",
    "####################\n",
    "start_years = [2015] + [yr for yr in range(2021,2101,10)]\n",
    "year_steps = [5] + [9 for yr in range(2021,2101,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13b1446d-4c58-433d-9472-033c67ee4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Model details\n",
    "###################\n",
    "model_info = {}\n",
    "for model in models:\n",
    "    tmp = glob(in_path + model.lower() + '*_w5e5_ssp126_pr_global_daily_2015_2020.nc')\n",
    "    tmp = tmp[0].replace(in_path + model.lower() + '_', '').replace('_w5e5_ssp126_pr_global_daily_2015_2020.nc', '')\n",
    "    model_info.update({model: tmp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f418bb08-2ee8-4156-89cb-4f459c5e9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-440d1e16-910c-11ed-91ba-34e6d79eac50</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">e8d389fb</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-0d9e63f1-c048-45ed-9c4b-91a081f77b78</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.102.201.236:42512\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.102.201.236:42512' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Dask\n",
    "############\n",
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster(cores=1, resource_spec='pmem=30GB', memory='30GB',\n",
    "                     worker_extra_args= ['#PBS -l feature=rhel7'],\n",
    "                     walltime = '01:30:00')\n",
    "\n",
    "cluster.scale(jobs=25)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3e158-fad8-4e8b-ac18-1a74aaa26fbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Simple metrics (no historical quantiles required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db6e33ae-f020-4437-8846-097544c43ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Calculate the metric for a \n",
    "# single model-year, including all SSPs and variables\n",
    "########################################################\n",
    "def model_year_metric(path, model, model_vers, ssps, var_ids, year, year_step, metric):\n",
    "    # Function for longest consecutive spell if needed\n",
    "    def n_longest_consecutive(ds, dim='time'):\n",
    "        ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "        return ds.max(dim=dim)\n",
    "\n",
    "    # Set up dictionary for all results\n",
    "    ds_all = {}\n",
    "    # Loop through SSPs\n",
    "    for ssp in ssps:\n",
    "        # Temporary list for each SSP\n",
    "        ds_list = []\n",
    "        # Loop through variables\n",
    "        for var in var_ids:\n",
    "            ## Temporary file for each variable\n",
    "            ds_tmp = xr.open_dataset(path + model + '_' + model_vers + '_w5e5_' + \n",
    "                                     ssp + '_' + var + '_global_daily_' + str(year) \n",
    "                                     + '_' + str(year + year_step) + '.nc')\n",
    "            \n",
    "            ## Convert units\n",
    "            # temperature: K -> C\n",
    "            if var == 'tas' and ds_tmp.tas.attrs['units'] == 'K':\n",
    "                ds_tmp['tas'] = ds_tmp['tas'] - 273.15\n",
    "            if var == 'tasmax' and ds_tmp.tasmax.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmax'] = ds_tmp['tasmax'] - 273.15\n",
    "            if var == 'tasmin' and ds_tmp.tasmin.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmin'] = ds_tmp['tasmin'] - 273.15\n",
    "\n",
    "            # precip: kg m-2 s-1 -> mm day-1\n",
    "            if var == 'pr' and ds_tmp.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "                ds_tmp['pr'] = ds_tmp['pr'] * 86400\n",
    "                ds_tmp.pr.attrs['units'] = 'mm/day'\n",
    "\n",
    "            # Calculate metric\n",
    "            if metric == 'avg':\n",
    "                ds_tmp = ds_tmp.resample(time='1Y').mean()\n",
    "            elif metric == 'max':\n",
    "                ds_tmp = ds_tmp.resample(time='1Y').max()\n",
    "            elif metric == 'dry':\n",
    "                # Number of dry days\n",
    "                ds_tmp_0 = (ds_tmp == 0.).resample(time='1Y').sum() # 0mm\n",
    "                ds_tmp_1 = (ds_tmp < 1.).resample(time='1Y').sum() # less than 1mm\n",
    "                # Longest sonsecutive dry day streak\n",
    "                ds_tmp_0c = (ds_tmp == 0.).resample(time='1Y').apply(n_longest_consecutive) # 0mm longest consecutive\n",
    "                ds_tmp_1c = (ds_tmp < 1.).resample(time='1Y').apply(n_longest_consecutive) # less than 1mm longest consecutive\n",
    "                # Merge\n",
    "                ds_tmp = xr.merge([ds_tmp_0.rename({'pr':'count_eq_0'}),\n",
    "                                   ds_tmp_0c.rename({'pr':'streak_eq_0'}),\n",
    "                                   ds_tmp_1.rename({'pr':'count_lt_1'}),\n",
    "                                   ds_tmp_1c.rename({'pr':'streak_lt_1'})])\n",
    "            elif metric == 'max5d':\n",
    "                ds_tmp = xclim.indicators.icclim.RX5day(ds=ds_tmp, freq='Y')\n",
    "                ds_tmp = xr.Dataset({'RX5day':ds_tmp})\n",
    "                \n",
    "            # Append to list\n",
    "            ds_list.append(ds_tmp)\n",
    "            \n",
    "        # Append to dict\n",
    "        ds_all.update({ssp: ds_list})\n",
    "\n",
    "    # Merge and concat along ssp dimension\n",
    "    for ssp in ssps:\n",
    "        ds_all[ssp] = xr.merge(ds_all[ssp])\n",
    "        ds_all[ssp] = ds_all[ssp].assign_coords(ssp = ssp)\n",
    "    \n",
    "    # Return\n",
    "    ds_out = xr.concat([ds_all[ssp] for ssp in ssps], dim='ssp')\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfc4e3-ba1c-43af-ab41-d25af40ea022",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c53d71ff-e774-4d80-a11f-98345d4cb5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "GFDL-ESM4 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR already done\n",
      "MRI-ESM2-0 already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~10 MINS PER MODEL WITH 9 DASK WORKERS\n",
    "metric = 'avg'\n",
    "\n",
    "# All variables\n",
    "var_ids = ['tas', 'tasmin', 'tasmax', 'pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + 'native_grid/' + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year, year_step in zip(start_years, year_steps):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model.lower(),\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = isimip_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  year_step = year_step,\n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.combine_by_coords(res)\n",
    "    df_final.to_netcdf(out_path + 'native_grid/' + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eecd2f0-6a74-46a1-a7cd-25a4afc7956d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be1f0705-5a03-43bd-a259-2100ad24e7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "GFDL-ESM4 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR already done\n",
      "MRI-ESM2-0 already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "metric = 'max'\n",
    "\n",
    "# All variables\n",
    "var_ids = ['tas', 'tasmin', 'tasmax', 'pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + 'native_grid/' + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year, year_step in zip(start_years, year_steps):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model.lower(),\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = isimip_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  year_step = year_step,\n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.combine_by_coords(res)\n",
    "    df_final.to_netcdf(out_path + 'native_grid/' + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a067544-08bb-4b7a-a653-758f62fc27de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 5-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55886640-ea3f-41c3-bfc5-a8e4ea23fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through models: RUNTIME IS ~10 MINS PER MODEL WITH 9 DASK WORKERS\n",
    "metric = 'max5d'\n",
    "\n",
    "# Precip only\n",
    "var_ids = ['pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + 'native_grid/' + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year, year_step in zip(start_years, year_steps):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model.lower(),\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = isimip_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  year_step = year_step,\n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + 'native_grid/' + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0258f00-0cc0-448a-acd7-88fed3347cb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21577022-9af1-46ca-a1eb-cb166b71a50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "GFDL-ESM4\n",
      "IPSL-CM6A-LR\n",
      "MIROC6\n",
      "MPI-ESM1-2-HR\n",
      "MRI-ESM2-0\n",
      "UKESM1-0-LL\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~10 MINS PER MODEL WITH 9 DASK WORKERS\n",
    "metric = 'dry'\n",
    "\n",
    "# Precip only\n",
    "var_ids = ['pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + 'native_grid/' + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year, year_step in zip(start_years, year_steps):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model.lower(),\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = isimip_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  year_step = year_step,\n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + 'native_grid/' + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212c2bd-d370-4832-b473-5e0e085e1056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70ae34bd-fb45-41c2-871e-2947b8d150ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Less simple metrics (historical quantiles required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea6a29a-d5a5-4f4b-b7af-3a08f6e6f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_year_ssp_metric(model_path, quantile_path, model, model_vers, ssp, var_id, year, year_step, obs):\n",
    "    \"\"\"\n",
    "    Reads ISIMIP model output for a given ssp-year and calculates the number of hot/wet days \n",
    "    and the longest consecutive hot/wet day streak. This function will be wrapped in dask \n",
    "    distributed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subfunction to calculate longest consecutive spell\n",
    "    def n_longest_consecutive(ds, dim='time'):\n",
    "        ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "        return ds.max(dim=dim)\n",
    "    \n",
    "    # Read historical quantiles\n",
    "    if var_id in ['tasmax', 'tasmin', 'tas']:\n",
    "        if 'gmfd' in obs:\n",
    "            ds_q_gmfd = xr.open_dataset(quantile_path + 'gmfd_temperature_quantiles_isimip.nc')\n",
    "        if 'era5' in obs:\n",
    "            ds_q_era5 = xr.open_dataset(quantile_path + 'era5_temperature_quantiles_isimip', engine='zarr')\n",
    "    elif var_id == 'pr':\n",
    "        if 'gmfd' in obs:\n",
    "            ds_q_gmfd = xr.open_dataset(quantile_path + 'gmfd_precip_quantiles_isimip.nc')\n",
    "        if 'era5' in obs:\n",
    "            ds_q_era5 = xr.open_dataset(quantile_path + 'era5_precip_quantiles_isimip', engine='zarr')\n",
    "    \n",
    "    # Read model file\n",
    "    ds_tmp = xr.open_dataset(model_path + model + '_' + model_vers + '_w5e5_' + \n",
    "                             ssp + '_' + var_id + '_global_daily_' + str(year) \n",
    "                             + '_' + str(year + year_step) + '.nc')\n",
    "\n",
    "    ds_tmp = ds_tmp.sel(lat=slice(90,-60)) # both obs extend only to 60S\n",
    "           \n",
    "    # Temperature: K -> C\n",
    "    if var_id == 'tas' and ds_tmp.tas.attrs['units'] == 'K':\n",
    "        ds_tmp['tas'] = ds_tmp['tas'] - 273.15\n",
    "    if var_id == 'tasmax' and ds_tmp.tasmax.attrs['units'] == 'K':\n",
    "        ds_tmp['tasmax'] = ds_tmp['tasmax'] - 273.15\n",
    "    if var_id == 'tasmin' and ds_tmp.tasmin.attrs['units'] == 'K':\n",
    "        ds_tmp['tasmin'] = ds_tmp['tasmin'] - 273.15\n",
    "\n",
    "    # Precip: kg m-2 s-1 -> mm day-1\n",
    "    if var_id == 'pr' and ds_tmp.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "        ds_tmp['pr'] = ds_tmp['pr'] * 86400\n",
    "\n",
    "    # Calculate metrics\n",
    "    ds_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        # GMFD\n",
    "        if 'gmfd' in obs:\n",
    "            # Above/below binary\n",
    "            ds_tmp_q_gmfd = ds_tmp[var_id] > ds_q_gmfd[var_id + '_' + rp]\n",
    "            # Count\n",
    "            ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "            # Streak\n",
    "            ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "            \n",
    "        # ERA5\n",
    "        if 'era5' in obs:\n",
    "            # Above/below binary\n",
    "            ds_tmp_q_era5 = ds_tmp[var_id] > ds_q_era5[var_id + '_' + rp]\n",
    "            # Count\n",
    "            ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "            # Streak\n",
    "            ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "    \n",
    "    # Merge and return\n",
    "    ds_out = xr.merge(ds_tmp_out)\n",
    "    ds_out = ds_out.assign_coords(ssp=ssp)\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92d74e-9a26-4ee2-bb31-d374c2c62468",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc5ea42-49d0-4b20-8ce1-751abe34e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "CNRM-CM6-1\n",
      "CNRM-ESM2-1\n",
      "EC-Earth3\n",
      "GFDL-ESM4\n",
      "IPSL-CM6A-LR\n",
      "MIROC6\n",
      "MPI-ESM1-2-HR\n",
      "MRI-ESM2-0\n",
      "UKESM1-0-LL\n",
      "CPU times: user 13min 11s, sys: 1min 24s, total: 14min 35s\n",
      "Wall time: 1h 12min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through models\n",
    "metric = 'wet'\n",
    "var_id = 'pr'\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + 'native_grid/' + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over ssp-years\n",
    "    delayed_res = []\n",
    "\n",
    "    for ssp in isimip_ssp_dict[model]:\n",
    "        for year, year_step in zip(start_years, year_steps):\n",
    "            tmp_res = dask.delayed(model_year_ssp_metric)(in_path,\n",
    "                                                          quantile_path,\n",
    "                                                          model.lower(),\n",
    "                                                          model_info[model],\n",
    "                                                          ssp,\n",
    "                                                          var_id,\n",
    "                                                          year,\n",
    "                                                          year_step,\n",
    "                                                          ['gmfd', 'era5'])\n",
    "            delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "    \n",
    "    # Combine in correct order along ssp, year\n",
    "    df_final = xr.concat([xr.concat([ds for ds in res if ds.ssp == ssp], dim='time') for ssp in isimip_ssp_dict[model]], dim='ssp')\n",
    "    del res\n",
    "\n",
    "    # Store\n",
    "    df_final.to_netcdf(out_path + 'native_grid/' + metric + '/' + model + '.nc')\n",
    "    del df_final \n",
    "    \n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17cdf3-80d7-4bf0-90f8-e52189a35ca9",
   "metadata": {},
   "source": [
    "### Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b1de63-cbc4-4ee3-a2f5-530ba2381df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5 tasmin\n",
      "CanESM5 tasmax\n",
      "CanESM5 tas\n",
      "CNRM-CM6-1 tasmin\n",
      "CNRM-CM6-1 tasmax\n",
      "CNRM-CM6-1 tas\n",
      "CNRM-ESM2-1 tasmin\n",
      "CNRM-ESM2-1 tasmax\n",
      "CNRM-ESM2-1 tas\n",
      "EC-Earth3 tasmin\n",
      "EC-Earth3 tasmax\n",
      "EC-Earth3 tas\n",
      "GFDL-ESM4 tasmin\n",
      "GFDL-ESM4 tasmax\n",
      "GFDL-ESM4 tas\n",
      "IPSL-CM6A-LR tasmin\n",
      "IPSL-CM6A-LR tasmax\n",
      "IPSL-CM6A-LR tas\n",
      "MIROC6 tasmin\n",
      "MIROC6 tasmax\n",
      "MIROC6 tas\n",
      "MPI-ESM1-2-HR tasmin\n",
      "MPI-ESM1-2-HR tasmax\n",
      "MPI-ESM1-2-HR tas\n",
      "MRI-ESM2-0 tasmin\n",
      "MRI-ESM2-0 tasmax\n",
      "MRI-ESM2-0 tas\n",
      "UKESM1-0-LL tasmin\n",
      "UKESM1-0-LL tasmax\n",
      "UKESM1-0-LL tas\n"
     ]
    }
   ],
   "source": [
    "# Loop through models (around 3.5 hours)\n",
    "metric = 'hot'\n",
    "\n",
    "for model in models:\n",
    "    for var_id in ['tasmin', 'tasmax', 'tas']:\n",
    "        # Check if already exists\n",
    "        if os.path.isfile(out_path + 'native_grid/' + metric + '/' + model + '_' + var_id + '.nc'):\n",
    "            print(model + ' ' + var_id + ' already done')\n",
    "            continue\n",
    "    \n",
    "        # Parallelize with dask over ssp-years\n",
    "        delayed_res = []\n",
    "\n",
    "        for ssp in isimip_ssp_dict[model]:\n",
    "            for year, year_step in zip(start_years, year_steps):\n",
    "                tmp_res = dask.delayed(model_year_ssp_metric)(in_path,\n",
    "                                                              quantile_path,\n",
    "                                                              model.lower(),\n",
    "                                                              model_info[model],\n",
    "                                                              ssp,\n",
    "                                                              var_id,\n",
    "                                                              year,\n",
    "                                                              year_step,\n",
    "                                                              ['gmfd', 'era5'])\n",
    "                delayed_res.append(tmp_res)\n",
    "            \n",
    "        # Compute\n",
    "        res = dask.compute(*delayed_res)\n",
    "    \n",
    "        # Combine in correct order along ssp, year\n",
    "        df_final = xr.concat([xr.concat([ds for ds in res if ds.ssp == ssp], dim='time') for ssp in isimip_ssp_dict[model]], dim='ssp')\n",
    "        del res\n",
    "\n",
    "        # Store\n",
    "        df_final.to_netcdf(out_path + 'native_grid/' + metric + '/' + model + '_' + var_id + '.nc')\n",
    "        print(model + ' ' + var_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c518a-ce13-4432-abcb-89230e7252bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multivariate metrics (historical quantiles required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b161e2-4bc8-4c3b-a6bf-ca7351d74669",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hot and dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f334212-24ce-41ea-bc87-8c63d6be2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_year_ssp_hotdry(model_path, quantile_path, model, model_vers, ssp, year, year_step, obs):\n",
    "    \"\"\"\n",
    "    Reads ISIMIP model output for a given ssp-year and calculates the number of hot+dry days \n",
    "    and the longest consecutive hot+dry day streak. This function will be wrapped in dask \n",
    "    distributed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subfunction to calculate longest consecutive spell\n",
    "    def n_longest_consecutive(ds, dim='time'):\n",
    "        ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "        return ds.max(dim=dim)\n",
    "    \n",
    "    # Read historical quantiles\n",
    "    if 'gmfd' in obs:\n",
    "        ds_q_gmfd = xr.open_dataset(quantile_path + 'gmfd_temperature_quantiles_isimip.nc')\n",
    "    if 'era5' in obs:\n",
    "        ds_q_era5 = xr.open_dataset(quantile_path + 'era5_temperature_quantiles_isimip', engine='zarr')\n",
    "    \n",
    "    # Read model file\n",
    "    ds_tasmax_tmp = xr.open_dataset(model_path + model + '_' + model_vers + '_w5e5_' + \n",
    "                             ssp + '_tasmax_global_daily_' + str(year) \n",
    "                             + '_' + str(year + year_step) + '.nc')\n",
    "\n",
    "    ds_tasmax_tmp = ds_tasmax_tmp.sel(lat=slice(90,-60)) # both obs extend only to 60S\n",
    "\n",
    "    ds_pr_tmp = xr.open_dataset(model_path + model + '_' + model_vers + '_w5e5_' + \n",
    "                             ssp + '_pr_global_daily_' + str(year) \n",
    "                             + '_' + str(year + year_step) + '.nc')\n",
    "\n",
    "    ds_pr_tmp = ds_pr_tmp.sel(lat=slice(90,-60)) # both obs extend only to 60S\n",
    "           \n",
    "    # Temperature: K -> C\n",
    "    if ds_tasmax_tmp.tasmax.attrs['units'] == 'K':\n",
    "        ds_tasmax_tmp['tasmax'] = ds_tasmax_tmp['tasmax'] - 273.15\n",
    "\n",
    "    # Precip: kg m-2 s-1 -> mm day-1\n",
    "    if ds_pr_tmp.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "        ds_pr_tmp['pr'] = ds_pr_tmp['pr'] * 86400\n",
    "\n",
    "    # Calculate metrics\n",
    "    ds_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        # GMFD\n",
    "        if 'gmfd' in obs:\n",
    "            # Above/below binary\n",
    "            ds_tmp_q_gmfd = (ds_tasmax_tmp['tasmax'] > ds_q_gmfd['tasmax_' + rp]) & (ds_pr_tmp['pr'] < 1.)\n",
    "            # Count\n",
    "            ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "            # Streak\n",
    "            ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "            \n",
    "        # ERA5\n",
    "        if 'era5' in obs:\n",
    "            # Above/below binary\n",
    "            ds_tmp_q_era5 = (ds_tasmax_tmp['tasmax'] > ds_q_era5['tasmax_' + rp]) & (ds_pr_tmp['pr'] < 1.)\n",
    "            # Count\n",
    "            ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "            # Streak\n",
    "            ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "    \n",
    "    # Merge and return\n",
    "    ds_out = xr.merge(ds_tmp_out)\n",
    "    ds_out = ds_out.assign_coords(ssp=ssp)\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af171ff1-1200-40c1-8c64-3881715afae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5 already done\n",
      "CNRM-CM6-1 already done\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through models: RUNTIME IS ~20 MINS PER MODEL WITH 25 DASK WORKERS\n",
    "metric = 'hotdry'\n",
    "\n",
    "for model in models[:5]:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + 'native_grid/' + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over ssp-years\n",
    "    delayed_res = []\n",
    "\n",
    "    for ssp in isimip_ssp_dict[model]:\n",
    "        for year, year_step in zip(start_years, year_steps):\n",
    "            tmp_res = dask.delayed(model_year_ssp_hotdry)(in_path,\n",
    "                                                          quantile_path,\n",
    "                                                          model.lower(),\n",
    "                                                          model_info[model],\n",
    "                                                          ssp,\n",
    "                                                          year,\n",
    "                                                          year_step,\n",
    "                                                          ['gmfd','era5'])\n",
    "            delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "    \n",
    "    # Combine in correct order along ssp, year\n",
    "    df_final = xr.concat([xr.concat([ds for ds in res if ds.ssp == ssp], dim='time') for ssp in isimip_ssp_dict[model]], dim='ssp')\n",
    "    del res\n",
    "\n",
    "    # Store\n",
    "    df_final.to_netcdf(out_path + 'native_grid/' + metric + '/' + model + '.nc')\n",
    "    del df_final \n",
    "    \n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ed725-4c95-41e5-9288-eac64f10bafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
