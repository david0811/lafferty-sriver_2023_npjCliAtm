{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010dc88c-5348-4f20-b016-f5de6aa3121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import xclim\n",
    "xclim.set_options(cf_compliance=\"log\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527e008-f356-43f0-bd69-e949bbc5afed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dccce93-c392-4a92-b317-d9a37641eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Set paths\n",
    "# UPDATE THIS FOR REPRODUCTION\n",
    "###############################\n",
    "in_path = '/gpfs/group/kaf26/default/public/NEX-GDDP-CMIP6/models/'\n",
    "out_path = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/nex-gddp/'\n",
    "quantile_path = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/quantiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b6d653-0e6d-4d29-9d58-cf4e1f64334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Models\n",
    "###################\n",
    "from utils import nex_ssp_dict\n",
    "\n",
    "models = list(nex_ssp_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b1446d-4c58-433d-9472-033c67ee4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Model details\n",
    "###################\n",
    "model_info = {}\n",
    "for model in models:\n",
    "    tmp = glob(in_path + model + '/ssp126/tasmax/*_2015.nc')\n",
    "    tmp = tmp[0].replace(in_path + model, '').replace('/ssp126/tasmax/tasmax_day_' + model + '_ssp126', '').replace('2015.nc', '')\n",
    "    model_info.update({model: tmp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f418bb08-2ee8-4156-89cb-4f459c5e9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-a55bc506-71d1-11ed-93fc-34e6d79eac43</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">7e0e9c85</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-c61c66ef-c945-4d85-a83b-a865f3870721</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.102.201.235:38223\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.102.201.235:38223' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Dask\n",
    "############\n",
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster(cores=1, resource_spec = 'pmem=30GB', memory='30GB',\n",
    "                     worker_extra_args= ['#PBS -l feature=rhel7'],\n",
    "                     walltime = '15:00:00')\n",
    "\n",
    "cluster.scale(jobs=55)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78ddaf-5cf0-4b86-8e49-c7d156f01721",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Simple metrics (no historical quantiles required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226eb6d-aa5d-44ee-b2b5-d2399ff66bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Calculate the metric for a \n",
    "# single model-year, including all SSPs and variables\n",
    "########################################################\n",
    "def model_year_metric(path, model, model_vers, ssps, var_ids, year, metric):\n",
    "    # Function for longest consecutive spell if needed\n",
    "    def n_longest_consecutive(ds, dim='time'):\n",
    "        ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "        return ds.max(dim=dim)\n",
    "\n",
    "    # Set up dictionary for all results\n",
    "    ds_all = {}\n",
    "    # Loop through SSPs\n",
    "    for ssp in ssps:\n",
    "        # Temporary list for each SSP\n",
    "        ds_list = []\n",
    "        # Loop through variables\n",
    "        for var in var_ids:\n",
    "            ## Temporary file for each variable\n",
    "            ds_tmp = xr.open_dataset(path + model + '/' + ssp + '/' +\n",
    "                                     var + '/' + var + '_day_' + model + \n",
    "                                     '_' + ssp + model_vers + str(year) + '.nc')\n",
    "            \n",
    "            ## Convert units\n",
    "            # temperature: K -> C\n",
    "            if var == 'tas' and ds_tmp.tas.attrs['units'] == 'K':\n",
    "                ds_tmp['tas'] = ds_tmp['tas'] - 273.15\n",
    "            if var == 'tasmax' and ds_tmp.tasmax.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmax'] = ds_tmp['tasmax'] - 273.15\n",
    "            if var == 'tasmin' and ds_tmp.tasmin.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmin'] = ds_tmp['tasmin'] - 273.15\n",
    "\n",
    "            # precip: kg m-2 s-1 -> mm day-1\n",
    "            if var == 'pr' and ds_tmp.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "                ds_tmp['pr'] = ds_tmp['pr'] * 86400\n",
    "                ds_tmp.pr.attrs['units'] = 'mm/day'\n",
    "                \n",
    "            # Calculate metric\n",
    "            if metric == 'avg':\n",
    "                ds_tmp = ds_tmp.resample(time='1Y').mean()\n",
    "            elif metric == 'max':\n",
    "                ds_tmp = ds_tmp.resample(time='1Y').max()\n",
    "            elif metric == 'dry':\n",
    "                # Number of dry days\n",
    "                ds_tmp_0 = (ds_tmp == 0.).resample(time='1Y').sum() # 0mm\n",
    "                ds_tmp_1 = (ds_tmp < 1.).resample(time='1Y').sum() # less than 1mm\n",
    "                # Longest sonsecutive dry day streak\n",
    "                ds_tmp_0c = (ds_tmp == 0.).resample(time='1Y').apply(n_longest_consecutive) # 0mm longest consecutive\n",
    "                ds_tmp_1c = (ds_tmp < 1.).resample(time='1Y').apply(n_longest_consecutive) # less than 1mm longest consecutive\n",
    "                # Merge\n",
    "                ds_tmp = xr.merge([ds_tmp_0.rename({'pr':'count_eq_0'}),\n",
    "                                   ds_tmp_0c.rename({'pr':'streak_eq_0'}),\n",
    "                                   ds_tmp_1.rename({'pr':'count_lt_1'}),\n",
    "                                   ds_tmp_1c.rename({'pr':'streak_lt_1'})])\n",
    "            elif metric == 'max5d':\n",
    "                ds_tmp = xclim.indicators.icclim.RX5day(ds=ds_tmp, freq='Y')\n",
    "                ds_tmp = xr.Dataset({'RX5day':ds_tmp})\n",
    "                \n",
    "            # Append to list\n",
    "            ds_list.append(ds_tmp)\n",
    "            \n",
    "        # Append to dict\n",
    "        ds_all.update({ssp: ds_list})\n",
    "\n",
    "    # Merge and concat along ssp dimension\n",
    "    for ssp in ssps:\n",
    "        ds_all[ssp] = xr.merge(ds_all[ssp])\n",
    "        ds_all[ssp] = ds_all[ssp].assign_coords(ssp = ssp)\n",
    "    \n",
    "    # Return\n",
    "    ds_out = xr.concat([ds_all[ssp] for ssp in ssps], dim='ssp')\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3e158-fad8-4e8b-ac18-1a74aaa26fbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14278fa3-3162-4bde-b617-893996a3eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 already done\n",
      "BCC-CSM2-MR already done\n",
      "CanESM5 already done\n",
      "CMCC-ESM2 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "EC-Earth3-Veg-LR already done\n",
      "GFDL-ESM4 already done\n",
      "HadGEM3-GC31-LL already done\n",
      "INM-CM4-8 already done\n",
      "INM-CM5-0 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC-ES2L already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR already done\n",
      "MRI-ESM2-0\n",
      "NESM3\n",
      "NorESM2-LM already done\n",
      "NorESM2-MM already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~15 MINS PER MODEL WITH 30 DASK WORKERS\n",
    "metric = 'avg'\n",
    "\n",
    "# All variables\n",
    "var_ids = ['tas', 'tasmin', 'tasmax', 'pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eecd2f0-6a74-46a1-a7cd-25a4afc7956d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0793d900-bea0-4afd-bd50-dfc6cc1ec933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 already done\n",
      "BCC-CSM2-MR already done\n",
      "CanESM5 already done\n",
      "CMCC-ESM2 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "EC-Earth3-Veg-LR already done\n",
      "GFDL-ESM4 already done\n",
      "HadGEM3-GC31-LL already done\n",
      "INM-CM4-8 already done\n",
      "INM-CM5-0 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC-ES2L already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR already done\n",
      "MRI-ESM2-0\n",
      "NESM3\n",
      "NorESM2-LM already done\n",
      "NorESM2-MM already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~10 MINS PER MODEL WITH 30 DASK WORKERS\n",
    "metric = 'max'\n",
    "\n",
    "# All variables\n",
    "var_ids = ['tas', 'tasmin', 'tasmax', 'pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc6e4d-bb58-4734-841c-8c5924f88b0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5-day max (pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e83f6951-5881-43d2-827c-9b09f9e2aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5\n",
      "BCC-CSM2-MR\n",
      "CanESM5\n",
      "CMCC-ESM2\n",
      "CNRM-CM6-1\n",
      "CNRM-ESM2-1\n",
      "EC-Earth3\n",
      "EC-Earth3-Veg-LR\n",
      "GFDL-ESM4\n",
      "HadGEM3-GC31-LL\n",
      "INM-CM4-8\n",
      "INM-CM5-0\n",
      "IPSL-CM6A-LR\n",
      "MIROC-ES2L\n",
      "MIROC6\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR\n",
      "MRI-ESM2-0\n",
      "NESM3\n",
      "NorESM2-LM\n",
      "NorESM2-MM\n",
      "UKESM1-0-LL\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~5 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "metric = 'max5d'\n",
    "\n",
    "# Precip only\n",
    "var_ids = ['pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014def66-53d0-4bfa-bbe8-df28be225f49",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af26328-ffa6-4e1a-88d2-1b095e5c37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 already done\n",
      "BCC-CSM2-MR already done\n",
      "CanESM5 already done\n",
      "CMCC-ESM2 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "EC-Earth3-Veg-LR already done\n",
      "GFDL-ESM4 already done\n",
      "HadGEM3-GC31-LL already done\n",
      "INM-CM4-8 already done\n",
      "INM-CM5-0 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC-ES2L already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR already done\n",
      "MPI-ESM1-2-LR already done\n",
      "MRI-ESM2-0 already done\n",
      "NESM3 already done\n",
      "NorESM2-LM already done\n",
      "NorESM2-MM already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~15 MINS PER MODEL WITH 30 DASK WORKERS\n",
    "metric = 'dry'\n",
    "\n",
    "# Precip only\n",
    "var_ids = ['pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850701a9-65d8-4b14-9cce-2ffe068a41f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Less simple metrics (historical quantiles required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31ee58f-560b-4891-a9a3-ff13806910b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_year_ssp_metric(model_path, quantile_path, model, model_vers, ssp, var_id, year, obs):\n",
    "    \"\"\"\n",
    "    Reads NEX-GDDP model output for a given ssp-year and calculates the number of hot/wet days \n",
    "    and the longest consecutive hot/wet day streak. This function will be wrapped in dask \n",
    "    distributed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subfunction to calculate longest consecutive spell\n",
    "    def n_longest_consecutive(ds, dim='time'):\n",
    "        ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "        return ds.max(dim=dim)\n",
    "    \n",
    "    # Read historical quantiles\n",
    "    if var_id in ['tasmax', 'tasmin', 'tas']:\n",
    "        if 'gmfd' in obs:\n",
    "            ds_q_gmfd = xr.open_dataset(quantile_path + 'gmfd_temperature_quantiles_nex-cil-deepsd.nc')\n",
    "        if 'era5' in obs:\n",
    "            ds_q_era5 = xr.open_dataset(quantile_path + 'era5_temperature_quantiles_nex-cil-deepsd', engine='zarr')\n",
    "    elif var_id == 'pr':\n",
    "        if 'gmfd' in obs:\n",
    "            ds_q_gmfd = xr.open_dataset(quantile_path + 'gmfd_precip_quantiles_nex-cil-deepsd.nc')\n",
    "        if 'era5' in obs:\n",
    "            ds_q_era5 = xr.open_dataset(quantile_path + 'era5_precip_quantiles_nex-cil-deepsd', engine='zarr')\n",
    "    \n",
    "    # Read model file\n",
    "    ds_tmp = xr.open_dataset(model_path + model + '/' + ssp + '/' +\n",
    "                             var_id + '/' + var_id + '_day_' + model + \n",
    "                             '_' + ssp + model_vers + str(year) + '.nc')\n",
    "           \n",
    "    # Temperature: K -> C\n",
    "    if var_id == 'tas' and ds_tmp.tas.attrs['units'] == 'K':\n",
    "        ds_tmp['tas'] = ds_tmp['tas'] - 273.15\n",
    "    if var_id == 'tasmax' and ds_tmp.tasmax.attrs['units'] == 'K':\n",
    "        ds_tmp['tasmax'] = ds_tmp['tasmax'] - 273.15\n",
    "    if var_id == 'tasmin' and ds_tmp.tasmin.attrs['units'] == 'K':\n",
    "        ds_tmp['tasmin'] = ds_tmp['tasmin'] - 273.15\n",
    "\n",
    "    # Precip: kg m-2 s-1 -> mm day-1\n",
    "    if var_id == 'pr' and ds_tmp.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "        ds_tmp['pr'] = ds_tmp['pr'] * 86400\n",
    "\n",
    "    # Calculate metrics\n",
    "    ds_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        # GMFD\n",
    "        if 'gmfd' in obs:\n",
    "            # Above/below binary\n",
    "            ds_tmp_q_gmfd = ds_tmp[var_id] > ds_q_gmfd[var_id + '_' + rp]\n",
    "            # Count\n",
    "            ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "            # Streak\n",
    "            ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "            \n",
    "        # ERA5\n",
    "        if 'era5' in obs:\n",
    "            # Above/below binary\n",
    "            ds_tmp_q_era5 = ds_tmp[var_id] > ds_q_era5[var_id + '_' + rp]\n",
    "            # Count\n",
    "            ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "            # Streak\n",
    "            ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "    \n",
    "    # Merge and return\n",
    "    ds_out = xr.merge(ds_tmp_out)\n",
    "    ds_out = ds_out.assign_coords(ssp=ssp)\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ec925-53bd-4bb5-8e77-3bc8c1087956",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4420df47-613b-42e5-8c6b-f90fcd563c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 pr already done\n",
      "BCC-CSM2-MR pr already done\n",
      "CanESM5\n",
      "CMCC-ESM2\n",
      "CNRM-CM6-1\n",
      "CNRM-ESM2-1\n",
      "EC-Earth3\n",
      "EC-Earth3-Veg-LR\n",
      "GFDL-ESM4\n",
      "HadGEM3-GC31-LL\n",
      "INM-CM4-8\n",
      "INM-CM5-0\n",
      "IPSL-CM6A-LR\n",
      "MIROC-ES2L\n",
      "MIROC6\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR\n",
      "MRI-ESM2-0\n",
      "NESM3\n",
      "NorESM2-LM\n",
      "NorESM2-MM\n",
      "UKESM1-0-LL\n",
      "CPU times: user 15min 32s, sys: 10min 25s, total: 25min 58s\n",
      "Wall time: 4h 32min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through models: RUNTIME IS ~16 MINS PER MODEL WITH 55 DASK WORKERS\n",
    "metric = 'wet'\n",
    "\n",
    "# Precip only\n",
    "var_id = 'pr'\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' ' + var_id + ' already done')\n",
    "        continue\n",
    "\n",
    "    # Parallelize with dask over ssp-years\n",
    "    delayed_res = []\n",
    "\n",
    "    for ssp in nex_ssp_dict[model]:\n",
    "        for year in range(2015, 2101):\n",
    "            tmp_res = dask.delayed(model_year_ssp_metric)(in_path,\n",
    "                                                          quantile_path,\n",
    "                                                          model,\n",
    "                                                          model_info[model],\n",
    "                                                          ssp,\n",
    "                                                          var_id,\n",
    "                                                          year,\n",
    "                                                          ['gmfd', 'era5'])\n",
    "            delayed_res.append(tmp_res)\n",
    "        \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Combine in correct order along ssp, year\n",
    "    df_final = xr.concat([xr.concat([ds for ds in res if ds.ssp == ssp], dim='time') for ssp in nex_ssp_dict[model]], dim='ssp')\n",
    "    del res\n",
    "    \n",
    "    # Store\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "    del df_final\n",
    "    \n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b29ae7-7241-486b-8668-95b5a744db49",
   "metadata": {},
   "source": [
    "### Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee39ef9b-ed57-48fa-a32b-85a69437b6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 tasmin already done\n",
      "ACCESS-ESM1-5 tasmax already done\n",
      "ACCESS-ESM1-5 tas already done\n",
      "BCC-CSM2-MR tasmin already done\n",
      "BCC-CSM2-MR tasmax already done\n",
      "BCC-CSM2-MR tas already done\n",
      "CanESM5 tasmin already done\n",
      "CanESM5 tasmax already done\n",
      "CanESM5 tas already done\n",
      "CMCC-ESM2 tasmin already done\n",
      "CMCC-ESM2 tasmax already done\n",
      "CMCC-ESM2 tas already done\n",
      "CNRM-CM6-1 tasmin already done\n",
      "CNRM-CM6-1 tasmax already done\n",
      "CNRM-CM6-1 tas already done\n",
      "CNRM-ESM2-1 tasmin already done\n",
      "CNRM-ESM2-1 tasmax already done\n",
      "CNRM-ESM2-1 tas already done\n",
      "EC-Earth3_tasmin\n",
      "EC-Earth3_tasmax\n",
      "EC-Earth3_tas\n",
      "EC-Earth3-Veg-LR_tasmin\n",
      "EC-Earth3-Veg-LR_tasmax\n",
      "EC-Earth3-Veg-LR_tas\n",
      "GFDL-ESM4_tasmin\n",
      "GFDL-ESM4_tasmax\n",
      "GFDL-ESM4_tas\n",
      "HadGEM3-GC31-LL_tasmin\n",
      "HadGEM3-GC31-LL_tasmax\n",
      "HadGEM3-GC31-LL_tas\n",
      "INM-CM4-8_tasmin\n",
      "INM-CM4-8_tasmax\n",
      "INM-CM4-8_tas\n",
      "INM-CM5-0_tasmin\n",
      "INM-CM5-0_tasmax\n",
      "INM-CM5-0_tas\n",
      "IPSL-CM6A-LR_tasmin\n",
      "IPSL-CM6A-LR_tasmax\n",
      "IPSL-CM6A-LR_tas\n",
      "MIROC-ES2L_tasmin\n",
      "MIROC-ES2L_tasmax\n",
      "MIROC-ES2L_tas\n",
      "MIROC6_tasmin\n",
      "MIROC6_tasmax\n",
      "MIROC6_tas\n",
      "MPI-ESM1-2-HR_tasmin\n",
      "MPI-ESM1-2-HR_tasmax\n",
      "MPI-ESM1-2-HR_tas\n",
      "MPI-ESM1-2-LR_tasmin\n",
      "MPI-ESM1-2-LR_tasmax\n",
      "MPI-ESM1-2-LR_tas\n",
      "MRI-ESM2-0_tasmin\n",
      "MRI-ESM2-0_tasmax\n",
      "MRI-ESM2-0_tas\n",
      "NESM3_tasmin\n",
      "NESM3_tasmax\n",
      "NESM3_tas\n",
      "NorESM2-LM_tasmin\n",
      "NorESM2-LM_tasmax\n",
      "NorESM2-LM_tas\n",
      "NorESM2-MM_tasmin\n",
      "NorESM2-MM_tasmax\n",
      "NorESM2-MM_tas\n",
      "UKESM1-0-LL_tasmin\n",
      "UKESM1-0-LL_tasmax\n",
      "UKESM1-0-LL_tas\n",
      "CPU times: user 46min 50s, sys: 20min 29s, total: 1h 7min 20s\n",
      "Wall time: 10h 31min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through models: RUNTIME IS ~16 MINS PER MODEL-VARIABLE WITH 55 DASK WORKERS\n",
    "metric = 'hot'\n",
    "\n",
    "for model in models:\n",
    "    for var_id in ['tasmin', 'tasmax', 'tas']:\n",
    "        # Check if already exists\n",
    "        if os.path.isfile(out_path + metric + '/' + model + '_' + var_id + '.nc'):\n",
    "            print(model + ' ' + var_id + ' already done')\n",
    "            continue\n",
    "    \n",
    "        # Parallelize with dask over ssp-years\n",
    "        delayed_res = []\n",
    "    \n",
    "        for ssp in nex_ssp_dict[model]:\n",
    "            for year in range(2015, 2101):\n",
    "                tmp_res = dask.delayed(model_year_ssp_metric)(in_path,\n",
    "                                                              quantile_path,\n",
    "                                                              model,\n",
    "                                                              model_info[model],\n",
    "                                                              ssp,\n",
    "                                                              var_id,\n",
    "                                                              year,\n",
    "                                                              ['gmfd', 'era5'])\n",
    "                delayed_res.append(tmp_res)\n",
    "            \n",
    "        # Compute\n",
    "        res = dask.compute(*delayed_res)\n",
    "    \n",
    "        # Combine in correct order along ssp, year\n",
    "        df_final = xr.concat([xr.concat([ds for ds in res if ds.ssp == ssp], dim='time') for ssp in nex_ssp_dict[model]], dim='ssp')\n",
    "        del res\n",
    "\n",
    "        # Store\n",
    "        df_final.to_netcdf(out_path + metric + '/' + model + '_' + var_id + '.nc')\n",
    "        del df_final \n",
    "        \n",
    "        print(model + '_' + var_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d469ac04-8562-4e51-934c-9fce730d24b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 05:14:03,141 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    }
   ],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31079d-ab2b-4b3f-822c-2aa8a386ce3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
