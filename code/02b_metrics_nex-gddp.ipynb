{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010dc88c-5348-4f20-b016-f5de6aa3121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527e008-f356-43f0-bd69-e949bbc5afed",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dccce93-c392-4a92-b317-d9a37641eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Set paths\n",
    "# UPDATE THIS FOR REPRODUCTION\n",
    "###############################\n",
    "in_path = '/gpfs/group/kaf26/default/public/NEX-GDDP-CMIP6/models/'\n",
    "out_path = '/gpfs/group/kaf26/default/dcl5300/lafferty-sriver_inprep_tbh_DATA/metrics/nex-gddp/'\n",
    "quantile_path = '/storage/home/dcl5300/work/lafferty-sriver_inprep_tbd/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b6d653-0e6d-4d29-9d58-cf4e1f64334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Models\n",
    "###################\n",
    "from utils import nex_ssp_dict\n",
    "\n",
    "models = list(nex_ssp_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b1446d-4c58-433d-9472-033c67ee4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Model details\n",
    "###################\n",
    "model_info = {}\n",
    "for model in models:\n",
    "    tmp = glob(in_path + model + '/ssp126/tasmax/*_2015.nc')\n",
    "    tmp = tmp[0].replace(in_path + model, '').replace('/ssp126/tasmax/tasmax_day_' + model + '_ssp126', '').replace('2015.nc', '')\n",
    "    model_info.update({model: tmp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f418bb08-2ee8-4156-89cb-4f459c5e9d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-1d8d3c5a-607e-11ed-8136-34e6d79eac6a</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.PBSCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">f6226add</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-d2220ded-6ca6-421f-85ea-6587a22167c3</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.102.201.238:38675\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.102.201.238:38675' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Dask\n",
    "############\n",
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster(cores=1, resource_spec = 'pmem=30GB', memory='30GB',\n",
    "                     worker_extra_args= ['#PBS -l feature=rhel7'],\n",
    "                     walltime = '08:00:00')\n",
    "\n",
    "cluster.scale(jobs=43)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78ddaf-5cf0-4b86-8e49-c7d156f01721",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Simple metrics (no historical quantiles required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2226eb6d-aa5d-44ee-b2b5-d2399ff66bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Calculate the metric for a \n",
    "# single model-year, including all SSPs and variables\n",
    "########################################################\n",
    "def model_year_metric(path, model, model_vers, ssps, var_ids, year, metric):\n",
    "    # Function for longest consecutive spell if needed\n",
    "    def n_longest_consecutive(ds, dim='time'):\n",
    "        ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "        return ds.max(dim=dim)\n",
    "\n",
    "    # Set up dictionary for all results\n",
    "    ds_all = {}\n",
    "    # Loop through SSPs\n",
    "    for ssp in ssps:\n",
    "        # Temporary list for each SSP\n",
    "        ds_list = []\n",
    "        # Loop through variables\n",
    "        for var in var_ids:\n",
    "            ## Temporary file for each variable\n",
    "            ds_tmp = xr.open_dataset(path + model + '/' + ssp + '/' +\n",
    "                                     var + '/' + var + '_day_' + model + \n",
    "                                     '_' + ssp + model_vers + str(year) + '.nc')\n",
    "            \n",
    "            ## Convert units\n",
    "            # temperature: K -> C\n",
    "            if var == 'tas' and ds_tmp.tas.attrs['units'] == 'K':\n",
    "                ds_tmp['tas'] = ds_tmp['tas'] - 273.15\n",
    "            if var == 'tasmax' and ds_tmp.tasmax.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmax'] = ds_tmp['tasmax'] - 273.15\n",
    "            if var == 'tasmin' and ds_tmp.tasmin.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmin'] = ds_tmp['tasmin'] - 273.15\n",
    "\n",
    "            # precip: kg m-2 s-1 -> mm day-1\n",
    "            if var == 'pr' and ds_tmp.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "                ds_tmp['pr'] = ds_tmp['pr'] * 86400\n",
    "\n",
    "            # Calculate metric\n",
    "            if metric == 'avg':\n",
    "                ds_tmp = ds_tmp.resample(time='1Y').mean()\n",
    "            elif metric == 'max':\n",
    "                ds_tmp = ds_tmp.resample(time='1Y').max()\n",
    "            elif metric == 'dry':\n",
    "                # Number of dry days\n",
    "                ds_tmp_0 = (ds_tmp == 0.).resample(time='1Y').sum() # 0mm\n",
    "                ds_tmp_1 = (ds_tmp < 1.).resample(time='1Y').sum() # less than 1mm\n",
    "                # Longest sonsecutive dry day streak\n",
    "                ds_tmp_0c = (ds_tmp == 0.).resample(time='1Y').apply(n_longest_consecutive) # 0mm longest consecutive\n",
    "                ds_tmp_1c = (ds_tmp < 1.).resample(time='1Y').apply(n_longest_consecutive) # less than 1mm longest consecutive\n",
    "                # Merge\n",
    "                ds_tmp = xr.merge([ds_tmp_0.rename({'pr':'count_eq_0'}),\n",
    "                                   ds_tmp_0c.rename({'pr':'streak_eq_0'}),\n",
    "                                   ds_tmp_1.rename({'pr':'count_lt_1'}),\n",
    "                                   ds_tmp_1c.rename({'pr':'streak_lt_1'})])\n",
    "                \n",
    "            # Append to list\n",
    "            ds_list.append(ds_tmp)\n",
    "            \n",
    "        # Append to dict\n",
    "        ds_all.update({ssp: ds_list})\n",
    "\n",
    "    # Merge and concat along ssp dimension\n",
    "    for ssp in ssps:\n",
    "        ds_all[ssp] = xr.merge(ds_all[ssp])\n",
    "        ds_all[ssp] = ds_all[ssp].assign_coords(ssp = ssp)\n",
    "    \n",
    "    # Return\n",
    "    ds_out = xr.concat([ds_all[ssp] for ssp in ssps], dim='ssp')\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3e158-fad8-4e8b-ac18-1a74aaa26fbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Annual averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14278fa3-3162-4bde-b617-893996a3eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 already done\n",
      "BCC-CSM2-MR already done\n",
      "CanESM5 already done\n",
      "CMCC-ESM2 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "EC-Earth3-Veg-LR already done\n",
      "GFDL-ESM4 already done\n",
      "HadGEM3-GC31-LL already done\n",
      "INM-CM4-8 already done\n",
      "INM-CM5-0 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC-ES2L already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR already done\n",
      "MRI-ESM2-0\n",
      "NESM3\n",
      "NorESM2-LM already done\n",
      "NorESM2-MM already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~15 MINS PER MODEL WITH 30 DASK WORKERS\n",
    "metric = 'avg'\n",
    "\n",
    "# All variables\n",
    "var_ids = ['tas', 'tasmin', 'tasmax', 'pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eecd2f0-6a74-46a1-a7cd-25a4afc7956d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Annual maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0793d900-bea0-4afd-bd50-dfc6cc1ec933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 already done\n",
      "BCC-CSM2-MR already done\n",
      "CanESM5 already done\n",
      "CMCC-ESM2 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "EC-Earth3-Veg-LR already done\n",
      "GFDL-ESM4 already done\n",
      "HadGEM3-GC31-LL already done\n",
      "INM-CM4-8 already done\n",
      "INM-CM5-0 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC-ES2L already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR\n",
      "MPI-ESM1-2-LR already done\n",
      "MRI-ESM2-0\n",
      "NESM3\n",
      "NorESM2-LM already done\n",
      "NorESM2-MM already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~10 MINS PER MODEL WITH 30 DASK WORKERS\n",
    "metric = 'max'\n",
    "\n",
    "# All variables\n",
    "var_ids = ['tas', 'tasmin', 'tasmax', 'pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014def66-53d0-4bfa-bbe8-df28be225f49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af26328-ffa6-4e1a-88d2-1b095e5c37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-ESM1-5 already done\n",
      "BCC-CSM2-MR already done\n",
      "CanESM5 already done\n",
      "CMCC-ESM2 already done\n",
      "CNRM-CM6-1 already done\n",
      "CNRM-ESM2-1 already done\n",
      "EC-Earth3 already done\n",
      "EC-Earth3-Veg-LR already done\n",
      "GFDL-ESM4 already done\n",
      "HadGEM3-GC31-LL already done\n",
      "INM-CM4-8 already done\n",
      "INM-CM5-0 already done\n",
      "IPSL-CM6A-LR already done\n",
      "MIROC-ES2L already done\n",
      "MIROC6 already done\n",
      "MPI-ESM1-2-HR already done\n",
      "MPI-ESM1-2-LR already done\n",
      "MRI-ESM2-0 already done\n",
      "NESM3 already done\n",
      "NorESM2-LM already done\n",
      "NorESM2-MM already done\n",
      "UKESM1-0-LL already done\n"
     ]
    }
   ],
   "source": [
    "# Loop through models: RUNTIME IS ~15 MINS PER MODEL WITH 30 DASK WORKERS\n",
    "metric = 'dry'\n",
    "\n",
    "# Precip only\n",
    "var_ids = ['pr']\n",
    "\n",
    "for model in models:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(path = in_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850701a9-65d8-4b14-9cce-2ffe068a41f2",
   "metadata": {},
   "source": [
    "## Less simple metrics (historical quantiles required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c5dd2e1-c8fc-4254-bf71-68e3a7ede76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# Calculate the metric for a single \n",
    "# model-year, including all SSPs and variables\n",
    "########################################################\n",
    "def model_year_metric(model_path, quantile_path, model, model_vers, ssps, var_ids, year, metric):\n",
    "    # Function for longest consecutive spell if needed\n",
    "    def n_longest_consecutive(ds, dim='time'):\n",
    "        ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "        return ds.max(dim=dim)\n",
    "    \n",
    "    # Read historical quantiles\n",
    "    if any(x in ['tasmax', 'tasmin', 'tas'] for x in var_ids):\n",
    "        ds_q_era5 = xr.open_dataset(quantile_path + 'era5_temperature_quantiles_nex-cil.nc')\n",
    "        ds_q_gmfd = xr.open_dataset(quantile_path + 'gmfd_temperature_quantiles_nex-cil.nc')\n",
    "    elif 'pr' in var_ids:\n",
    "        ds_q_era5 = xr.open_dataset(quantile_path + 'era5_precip_quantiles_nex-cil.nc')\n",
    "        ds_q_gmfd = xr.open_dataset(quantile_path + 'gmfd_precip_quantiles_nex-cil.nc')\n",
    "\n",
    "    # Set up dictionary for all results\n",
    "    ds_all = {}\n",
    "    # Loop through SSPs\n",
    "    for ssp in ssps:\n",
    "        # Temporary list for each SSP\n",
    "        ds_list = []\n",
    "        # Loop through variables\n",
    "        for var_id in var_ids:\n",
    "            ## Temporary file for each variable\n",
    "            ds_tmp = xr.open_dataset(model_path + model + '/' + ssp + '/' +\n",
    "                                     var_id + '/' + var_id + '_day_' + model + \n",
    "                                     '_' + ssp + model_vers + str(year) + '.nc')\n",
    "           \n",
    "            ## Convert units\n",
    "            # temperature: K -> C\n",
    "            if var_id == 'tas' and ds_tmp.tas.attrs['units'] == 'K':\n",
    "                ds_tmp['tas'] = ds_tmp['tas'] - 273.15\n",
    "            if var_id == 'tasmax' and ds_tmp.tasmax.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmax'] = ds_tmp['tasmax'] - 273.15\n",
    "            if var_id == 'tasmin' and ds_tmp.tasmin.attrs['units'] == 'K':\n",
    "                ds_tmp['tasmin'] = ds_tmp['tasmin'] - 273.15\n",
    "\n",
    "            # precip: kg m-2 s-1 -> mm day-1\n",
    "            if var_id == 'pr' and ds_tmp.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "                ds_tmp['pr'] = ds_tmp['pr'] * 86400\n",
    "\n",
    "            ## Calculate metrics\n",
    "            ds_tmp_out = []\n",
    "            for rp in ['rp5', 'rp10', 'rp20']:\n",
    "                # Get above/below binary\n",
    "                ds_tmp_q_era5 = ds_tmp > ds_q_era5[var_id + '_' + rp]\n",
    "                ds_tmp_q_gmfd = ds_tmp > ds_q_gmfd[var_id + '_' + rp]\n",
    "                \n",
    "                # Count of hot/wet days\n",
    "                ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "                ds_tmp_out.append(ds_tmp_q_era5_count.rename({var_id : var_id + '_' + rp + 'era5_count'}))\n",
    "                ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "                ds_tmp_out.append(ds_tmp_q_gmfd_count.rename({var_id : var_id + '_' + rp + 'gmfd_count'}))\n",
    "                \n",
    "                # Longest consecutive hot/wet day streak\n",
    "                ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "                ds_tmp_out.append(ds_tmp_q_era5_streak.rename({var_id : var_id + '_' + rp + 'era5_streak'}))\n",
    "                ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "                ds_tmp_out.append(ds_tmp_q_gmfd_streak.rename({var_id : var_id + '_' + rp + 'gmfd_streak'}))\n",
    "                \n",
    "            # Merge metrics and append\n",
    "            ds_tmp = xr.merge(ds_tmp_out)\n",
    "            ds_list.append(ds_tmp)\n",
    "            \n",
    "        # Append to SSP dict\n",
    "        ds_all.update({ssp: ds_list})\n",
    "\n",
    "    # Merge and concat along ssp dimension\n",
    "    for ssp in ssps:\n",
    "        ds_all[ssp] = xr.merge(ds_all[ssp])\n",
    "        ds_all[ssp] = ds_all[ssp].assign_coords(ssp = ssp)\n",
    "    \n",
    "    # Return\n",
    "    ds_out = xr.concat([ds_all[ssp] for ssp in ssps], dim='ssp')\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ec925-53bd-4bb5-8e77-3bc8c1087956",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9262307-fe6e-4419-bd87-773dcb7232e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop through models: RUNTIME IS ~15 MINS PER MODEL WITH 43 DASK WORKERS\n",
    "metric = 'wet'\n",
    "\n",
    "# Precip only\n",
    "var_ids = ['pr']\n",
    "\n",
    "for model in models[:1]:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(model_path = in_path,\n",
    "                                                  quantile_path = quantile_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b29ae7-7241-486b-8668-95b5a744db49",
   "metadata": {},
   "source": [
    "### Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39ef9b-ed57-48fa-a32b-85a69437b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop through models: RUNTIME IS ~15 MINS PER MODEL WITH 43 DASK WORKERS\n",
    "metric = 'hot'\n",
    "\n",
    "# Precip only\n",
    "var_ids = ['tas', 'tasmax', 'tasmin']\n",
    "\n",
    "for model in models[:1]:\n",
    "    # Check if already exists\n",
    "    if os.path.isfile(out_path + metric + '/' + model + '.nc'):\n",
    "        print(model + ' already done')\n",
    "        continue\n",
    "    \n",
    "    # Parallelize with dask over years\n",
    "    delayed_res = []\n",
    "\n",
    "    for year in range(2015, 2101):\n",
    "        tmp_res = dask.delayed(model_year_metric)(model_path = in_path,\n",
    "                                                  quantile_path = quantile_path,\n",
    "                                                  model = model,\n",
    "                                                  model_vers = model_info[model],\n",
    "                                                  ssps = nex_ssp_dict[model],\n",
    "                                                  var_ids = var_ids,\n",
    "                                                  year = year, \n",
    "                                                  metric = metric)\n",
    "        delayed_res.append(tmp_res)\n",
    "            \n",
    "    # Compute\n",
    "    res = dask.compute(*delayed_res)\n",
    "\n",
    "    # Store\n",
    "    df_final = xr.concat(res, dim='time')\n",
    "    df_final.to_netcdf(out_path + metric + '/' + model + '.nc')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c1de7-9e8d-4dc3-9eec-e21a66843921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
