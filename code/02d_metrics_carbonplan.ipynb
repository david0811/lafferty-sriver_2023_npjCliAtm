{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e081161-797d-493d-b414-f69c77115096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: may need to run the following command in terminal to install regionmask:\n",
    "# mamba install -c conda-forge regionmask cartopy pygeos\n",
    "# mamba install -c anaconda cryptography==38.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd1c55d-e48a-4013-97b2-824b364d5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import regionmask\n",
    "import xarray as xr\n",
    "import io\n",
    "import os\n",
    "import intake\n",
    "\n",
    "import getpass\n",
    "import azure.storage.blob\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff5d25-e6cb-4d3c-a820-9a5e3530a0fd",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8981a24f-9864-465b-a576-1b5dd9ca26cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Azure blob storage\n",
    "######################\n",
    "# connection string (from azure web login, select your storage account, then \"Access keys\")\n",
    "connection_string = getpass.getpass()\n",
    "\n",
    "    \n",
    "# format storage\n",
    "container_client = azure.storage.blob.ContainerClient.from_connection_string(\n",
    "    connection_string, container_name=\"mpctransfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312b096e-ca75-4c12-9e9d-a3cc1f00b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Models\n",
    "###################\n",
    "from utils import gardsv_ssp_dict, gardsv_var_dict, deepsdbc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e625df91-f1f4-4a6e-ab24-7d80d529cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Data access\n",
    "#################\n",
    "\n",
    "# Complete catalog\n",
    "cat = intake.open_esm_datastore(\n",
    "    \"https://cpdataeuwest.blob.core.windows.net/cp-cmip/version1/catalogs/global-downscaled-cmip6.json\"\n",
    ")\n",
    "\n",
    "# function to grab all variables and SSPs for singe model/method\n",
    "def grab_model(method, model, scenarios):\n",
    "    # Search catalogue for method, model, all SSPs, all vars\n",
    "    dsets = cat.search(\n",
    "        method=method,\n",
    "        source_id=model,\n",
    "        experiment_id=scenarios,\n",
    "        timescale='day'\n",
    "    ).to_dataset_dict()\n",
    "    \n",
    "    # Concat along SSP dimension and return\n",
    "    ds_ssp = []\n",
    "    for key in list(dsets.keys()):\n",
    "        # Get single ssp file\n",
    "        ds_tmp = dsets[key]\n",
    "        \n",
    "        # Add ssp dimension\n",
    "        if 'experiment_id' in ds_tmp.attrs:\n",
    "            ds_tmp = ds_tmp.assign_coords(ssp = ds_tmp.attrs['experiment_id'])\n",
    "        else:\n",
    "            ds_tmp = ds_tmp.assign_coords(ssp = ds_tmp.attrs['intake_esm_attrs:experiment_id'])\n",
    "        \n",
    "        # For some models/methods we are missing precip\n",
    "        # so need to fill with NaNs\n",
    "        if 'pr' not in ds_tmp.data_vars:\n",
    "            ds_tmp['pr'] = xr.full_like(ds_tmp['tasmax'], np.NaN)\n",
    "            ds_tmp['pr'].attrs = {'units':'NaN'}\n",
    "        \n",
    "        # Append\n",
    "        ds_ssp.append(ds_tmp)\n",
    "    \n",
    "    # Rechunk for faster compuations\n",
    "    ds_out = xr.concat(ds_ssp, dim='ssp')\n",
    "    ds_out = ds_out.chunk({'ssp':1, 'lat':360, 'lon':360,\n",
    "                               'time':tuple(ds_out.time.groupby(ds_out.time.dt.year).count().to_numpy())})\n",
    "    return ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b51c7f5-b947-4e15-81f6-895fc29238ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for longest consecutive spell if needed\n",
    "def n_longest_consecutive(ds, dim='time'):\n",
    "    ds = ds.cumsum(dim=dim) - ds.cumsum(dim=dim).where(ds == 0).ffill(dim=dim).fillna(0)\n",
    "    return ds.max(dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43646670-0b36-4867-befa-938c5d78fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Convert units\n",
    "##################\n",
    "def convert_units(ds):\n",
    "    if 'tasmax' in ds.data_vars and ds.tasmax.attrs['units'] == 'K':\n",
    "        ds['tasmax'] = ds['tasmax'] - 273.15\n",
    "    if 'tasmin' in ds.data_vars and ds.tasmin.attrs['units'] == 'K':\n",
    "        ds['tasmin'] = ds['tasmin'] - 273.15\n",
    "    if 'pr' in ds.data_vars and ds.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "        ds['pr'] = ds['pr'] * 86400\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e777b0-df70-4ca4-9164-a9e3d7c53533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.090757d24ea24fae965d7db5a677b2e4/status\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# Dask\n",
    "#########\n",
    "import dask_gateway\n",
    "gateway = dask_gateway.Gateway()\n",
    "\n",
    "# cluster options\n",
    "cluster_options = gateway.cluster_options()\n",
    "cluster_options[\"worker_memory\"] = 24\n",
    "cluster_options[\"worker_cores\"] = 1\n",
    "\n",
    "# start cluster\n",
    "cluster = gateway.new_cluster(cluster_options)\n",
    "client = cluster.get_client()\n",
    "cluster.scale(45)\n",
    "\n",
    "# dashboard link\n",
    "print(cluster.dashboard_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f473d5-0691-4884-b884-5dabc666dd8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GARD-SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35083b41-15a4-4873-9f8c-d365d6c830c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "method = 'GARD-SV'\n",
    "models = list(gardsv_ssp_dict.keys())\n",
    "\n",
    "assert models == list(gardsv_var_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158586d-5246-49ce-a0ff-54d3fa1b5b00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e4fc9-12b5-440d-927a-ce6188475c0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Annual avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1aabe2fa-96f3-4739-a173-e960ae82235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:10&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:16&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR\n"
     ]
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 5 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "    \n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmin'] + ds['tasmax']) / 2.\n",
    "    \n",
    "    # Annual averages\n",
    "    ds_final = ds.resample(time='1Y').mean()\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/avg/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76a35d-9791-450b-8c09-c02dfba9a8ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa81bb75-b6ec-4582-ad5d-ba4cb940a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR\n"
     ]
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "\n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmin'] + ds['tasmax']) / 2.\n",
    "    \n",
    "    # Annual maxs\n",
    "    ds_final = ds.resample(time='1Y').max()\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/max/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e714471-2467-4aa1-a5d6-249642f89804",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12d14c5-22ad-4afa-8868-b7c725091ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xclim\n",
    "xclim.set_options(cf_compliance=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28f264d3-b632-4640-919a-6df0791a5367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MIROC6', 'MPI-ESM1-2-HR']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f29ad93-07f2-4a77-a17e-175ebeaf41c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MIROC6'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77defb2-bdee-4e28-b818-17d34e8dc491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "('store-map-a9ba9cf6fc8fd729e12ce8ac82ed1ec5', 0, 2, 0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m store \u001b[38;5;241m=\u001b[39m zarr\u001b[38;5;241m.\u001b[39mABSStore(client\u001b[38;5;241m=\u001b[39mcontainer_client, prefix\u001b[38;5;241m=\u001b[39mazure_prefix)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# store\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mds_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/core/dataset.py:2060\u001b[0m, in \u001b[0;36mDataset.to_zarr\u001b[0;34m(self, store, chunk_store, mode, synchronizer, group, encoding, compute, consolidated, append_dim, region, safe_chunks, storage_options)\u001b[0m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;124;03m\"\"\"Write dataset contents to a zarr group.\u001b[39;00m\n\u001b[1;32m   1951\u001b[0m \n\u001b[1;32m   1952\u001b[0m \u001b[38;5;124;03mZarr chunks are determined in the following way:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;124;03m    The I/O user guide, with more details and examples.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_zarr\n\u001b[0;32m-> 2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafe_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_chunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/backends/api.py:1638\u001b[0m, in \u001b[0;36mto_zarr\u001b[0;34m(dataset, store, chunk_store, mode, synchronizer, group, encoding, compute, consolidated, append_dim, region, safe_chunks, storage_options)\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to properly handle unlimited_dims\u001b[39;00m\n\u001b[1;32m   1637\u001b[0m dump_to_store(dataset, zstore, writer, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m-> 1638\u001b[0m writes \u001b[38;5;241m=\u001b[39m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[1;32m   1641\u001b[0m     _finalize_store(writes, zstore)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/xarray/backends/common.py:168\u001b[0m, in \u001b[0;36mArrayWriter.sync\u001b[0;34m(self, compute)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mda\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# TODO: consider wrapping targets with dask.delayed, if this makes\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# for any discernible difference in perforance, e.g.,\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# targets = [dask.delayed(t) for t in self.targets]\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m delayed_store \u001b[38;5;241m=\u001b[39m \u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msources \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/dask/array/core.py:1230\u001b[0m, in \u001b[0;36mstore\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compute:\n\u001b[1;32m   1229\u001b[0m     store_dsk \u001b[38;5;241m=\u001b[39m HighLevelGraph(layers, dependencies)\n\u001b[0;32m-> 1230\u001b[0m     \u001b[43mcompute_as_if_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_dsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mcompute_as_if_collection\u001b[0;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m schedule \u001b[38;5;241m=\u001b[39m get_scheduler(scheduler\u001b[38;5;241m=\u001b[39mscheduler, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, get\u001b[38;5;241m=\u001b[39mget)\n\u001b[1;32m    341\u001b[0m dsk2 \u001b[38;5;241m=\u001b[39m optimization_function(\u001b[38;5;28mcls\u001b[39m)(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/client.py:3036\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m         should_rejoin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3036\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3038\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/client.py:2210\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2209\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/utils.py:338\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/utils.py:405\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    404\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/utils.py:378\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    376\u001b[0m         future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[1;32m    377\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     error \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/gen.py:762\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/distributed/client.py:2074\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2072\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2073\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m-> 2074\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2076\u001b[0m     bad_keys\u001b[38;5;241m.\u001b[39madd(key)\n",
      "\u001b[0;31mCancelledError\u001b[0m: ('store-map-a9ba9cf6fc8fd729e12ce8ac82ed1ec5', 0, 2, 0, 0)"
     ]
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models[2:]:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmin'] + ds['tasmax']) / 2.\n",
    "    ds['pr'].attrs['units'] = 'mm/day'\n",
    "    \n",
    "    # Compute\n",
    "    ds_RX5day = xclim.indicators.icclim.RX5day(ds=ds[['pr']], freq='Y')\n",
    "    \n",
    "    ds_temp5day = ds[['tas','tasmin','tasmax']].rolling(time=5).mean().resample(time='1Y').max()\n",
    "    ds_temp5day -= 273.15 # K -> C\n",
    "        \n",
    "    # Storage options\n",
    "    ds_final = xr.merge([ds_temp5day, ds_RX5day])\n",
    "    ds_final = ds_final.isel(member_id=0).drop('member_id')\n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/max5d/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f24e29-3cd6-4bd0-b762-81e09746bb69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc3160e-5aa8-4c03-8d0f-c87d4bea996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for longest consecutive spell if needed\n",
    "def n_longest_consecutive(ds):\n",
    "    ds_out = ds.cumsum(dim='time') - ds.cumsum(dim='time').where(ds == 0).ffill(dim='time').fillna(0)\n",
    "    return ds_out.max(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c774f6e-bfe3-4292-a516-c2fdd82ba508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR contains no precip\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6 contains no precip\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR\n"
     ]
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "    ds = convert_units(ds)\n",
    "    \n",
    "    if ds['pr'].attrs['units'] == 'NaN':\n",
    "        print(model + ' contains no precip')\n",
    "        continue\n",
    "    \n",
    "    # Select only precip\n",
    "    ds = ds.drop(['tasmin', 'tasmax'])\n",
    "    \n",
    "    # Compute\n",
    "    # Number of dry days\n",
    "    ds_tmp_0 = (ds == 0.).resample(time='1Y').sum() # 0mm\n",
    "    ds_tmp_1 = (ds < 1.).resample(time='1Y').sum() # less than 1mm\n",
    "    # Longest sonsecutive dry day streak\n",
    "    ds_tmp_0c = (ds == 0.).resample(time='1Y').apply(n_longest_consecutive) # 0mm longest consecutive\n",
    "    ds_tmp_1c = (ds < 1.).resample(time='1Y').apply(n_longest_consecutive) # less than 1mm longest consecutive\n",
    "    # Merge\n",
    "    ds_final = xr.merge([ds_tmp_0.rename({'pr':'count_eq_0'}),\n",
    "                         ds_tmp_0c.rename({'pr':'streak_eq_0'}),\n",
    "                         ds_tmp_1.rename({'pr':'count_lt_1'}),\n",
    "                         ds_tmp_1c.rename({'pr':'streak_lt_1'})])\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/dry/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b840a-c328-4a8d-8dff-1def920fab62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Less simple metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7f088-76f2-4f38-b1a7-be111daa03f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b38269c5-5e78-4195-9740-5d29a5ae4987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:08&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR contains no precip\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:06&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6 contains no precip\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR\n",
      "CPU times: user 4min 24s, sys: 2.49 s, total: 4min 27s\n",
      "Wall time: 29min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_precip_quantiles_gardsv.nc')\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_precip_quantiles_gardsv.nc')\n",
    "    \n",
    "# loop through models: RUNTIME IS AROUND 20 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "    ds = convert_units(ds)\n",
    "    \n",
    "    if ds['pr'].attrs['units'] == 'NaN':\n",
    "        print(model + ' contains no precip')\n",
    "        continue\n",
    "        \n",
    "    # Select only precip\n",
    "    ds = ds.drop(['tasmin', 'tasmax'])\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    var_id = 'pr'\n",
    "    ds_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        # Get above/below binary\n",
    "        ds_tmp_q_era5 = ds[var_id] > ds_q_era5[var_id + '_' + rp]\n",
    "        ds_tmp_q_gmfd = ds[var_id] > ds_q_gmfd[var_id + '_' + rp]\n",
    "        \n",
    "        # Count of hot days\n",
    "        ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "        ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "        \n",
    "        # Longest consecutive hot day streak\n",
    "        ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "        ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "        \n",
    "    # Merge metrics and append\n",
    "    ds_final = xr.merge(ds_tmp_out)\n",
    "        \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':20, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/wet/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3ce23-f6d6-4a4e-bd33-f9ebb3d0b156",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3929d100-0317-4f0e-b03e-6ccb4a684973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR\n",
      "CPU times: user 42min 53s, sys: 12.1 s, total: 43min 6s\n",
      "Wall time: 3h 14min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_temperature_quantiles_gardsv.nc')\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_temperature_quantiles_gardsv.nc')\n",
    "    \n",
    "# loop through models: RUNTIME IS AROUND 10 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmax'] + ds['tasmin']) / 2.\n",
    "    \n",
    "    # Drop precip\n",
    "    ds = ds.drop(['pr'])\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    ds_tmp_final = []\n",
    "    for var_id in ['tasmin','tasmax','tas']:\n",
    "        ds_tmp_out = []\n",
    "        for rp in ['q99', 'rp10']:\n",
    "            # Get above/below binary\n",
    "            ds_tmp_q_era5 = ds[var_id] > ds_q_era5[var_id + '_' + rp]\n",
    "            ds_tmp_q_gmfd = ds[var_id] > ds_q_gmfd[var_id + '_' + rp]\n",
    "        \n",
    "            # Count of hot days\n",
    "            ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "            ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "        \n",
    "            # Longest consecutive hot day streak\n",
    "            ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "            ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "        \n",
    "        # Merge RPs and append\n",
    "        ds_out = xr.merge(ds_tmp_out)\n",
    "        ds_tmp_final.append(ds_out)\n",
    "    \n",
    "    # Merge variables\n",
    "    ds_final = xr.merge(ds_tmp_final)\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':20, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/hot/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ead9b-69df-4e59-b937-93466e0b448e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multivariate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4853c-7af5-48aa-ad01-ab3969de8c7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hot and dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e5c3271-4384-4931-8b6d-b96e12b2f1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR contains no precip\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:06&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6 contains no precip\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR\n",
      "CPU times: user 3min 53s, sys: 4.83 s, total: 3min 58s\n",
      "Wall time: 1h 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_temperature_quantiles_gardsv.nc')\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_temperature_quantiles_gardsv.nc')\n",
    "    \n",
    "# loop through models: RUNTIME IS AROUND 10 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "    ds = convert_units(ds)\n",
    "    \n",
    "    if ds['pr'].attrs['units'] == 'NaN':\n",
    "        print(model + ' contains no precip')\n",
    "        continue\n",
    "    \n",
    "    # Drop tasmin\n",
    "    ds = ds.drop(['tasmin'])\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    ds_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        # Get above/below binary\n",
    "        ds_tmp_q_gmfd = (ds['tasmax'] > ds_q_gmfd['tasmax_' + rp]) & (ds['pr'] < 1.)\n",
    "        ds_tmp_q_era5 = (ds['tasmax'] > ds_q_era5['tasmax_' + rp]) & (ds['pr'] < 1.)\n",
    "        \n",
    "        # Count of hot+dry days\n",
    "        ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "        ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "        \n",
    "        # Longest consecutive hot+dry day streak\n",
    "        ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "        ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "        \n",
    "    # Merge metrics and append\n",
    "    ds_final = xr.merge(ds_tmp_out)\n",
    "        \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':10, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/hotdry/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00affc22-5cb3-4527-9f78-5a88caea0330",
   "metadata": {},
   "source": [
    "## Spatially compounding metrics (historical quantiles required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e667a1c8-c795-4cda-bb7e-a1863cc80850",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3e331be6-8a52-4585-9933-8bd509807101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:04&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR\n",
      "CPU times: user 44min 10s, sys: 58.9 s, total: 45min 9s\n",
      "Wall time: 2h 24min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "area_frac = 0.5\n",
    "var_id = 'tasmax'\n",
    "\n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_temperature_quantiles_gardsv.nc')\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_temperature_quantiles_gardsv.nc')\n",
    "    \n",
    "# loop through models: RUNTIME IS AROUND 20 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, gardsv_ssp_dict[model])\n",
    "    ds = convert_units(ds)\n",
    "    # ds['tas'] = (ds['tasmax'] + ds['tasmin']) / 2.\n",
    "        \n",
    "    # Drop precip and tasmin\n",
    "    ds = ds.drop(['pr', 'tasmin'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    gmfd_tmp_out = []\n",
    "    era5_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        ## GMFD\n",
    "        # Above/below binary\n",
    "        ds_tmp_q_gmfd = (ds[var_id] > ds_q_gmfd[var_id + '_' + rp]).persist()\n",
    "        # Mask\n",
    "        mask = regionmask.defined_regions.ar6.land.mask(ds_tmp_q_gmfd)\n",
    "        # Loop through regions\n",
    "        for region in regionmask.defined_regions.ar6.land.abbrevs:\n",
    "            region_index = regionmask.defined_regions.ar6.land.map_keys(region)\n",
    "            \n",
    "            ds_tmp_q_masked = ds_tmp_q_gmfd.where(mask == region_index, drop=True)\n",
    "            ds_tmp_region_q_masked = ds_tmp_q_masked.mean(dim=['lat','lon'], skipna=True)\n",
    "            \n",
    "            # Count\n",
    "            out_name = var_id + '_' + rp + 'gmfd_count'\n",
    "            tmp_q_count = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').sum()\n",
    "            \n",
    "            tmp_q_count = pd.wide_to_long(tmp_q_count.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_count = tmp_q_count.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_count['year'] = tmp_q_count['year'].dt.year\n",
    "            tmp_q_count['ssp'] = tmp_q_count['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Streak\n",
    "            out_name = var_id + '_' + rp + 'gmfd_streak'\n",
    "            tmp_q_streak = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').apply(n_longest_consecutive)\n",
    "            \n",
    "            tmp_q_streak = pd.wide_to_long(tmp_q_streak.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_streak = tmp_q_streak.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_streak['year'] = tmp_q_streak['year'].dt.year\n",
    "            tmp_q_streak['ssp'] = tmp_q_streak['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Merge\n",
    "            tmp_q_out = pd.merge(tmp_q_count, tmp_q_streak, on=['year', 'ssp'])\n",
    "            tmp_q_out['region'] = region\n",
    "            gmfd_tmp_out.append(tmp_q_out)\n",
    "            \n",
    "        ## ERA5\n",
    "        # Above/below binary\n",
    "        ds_tmp_q_era5 = (ds[var_id] > ds_q_era5[var_id + '_' + rp]).persist()\n",
    "        # Mask\n",
    "        mask = regionmask.defined_regions.ar6.land.mask(ds_tmp_q_era5)\n",
    "        # Loop through regions\n",
    "        for region in regionmask.defined_regions.ar6.land.abbrevs:\n",
    "            region_index = regionmask.defined_regions.ar6.land.map_keys(region)\n",
    "            \n",
    "            ds_tmp_q_masked = ds_tmp_q_era5.where(mask == region_index, drop=True)\n",
    "            ds_tmp_region_q_masked = ds_tmp_q_masked.mean(dim=['lat','lon'], skipna=True)\n",
    "            \n",
    "            # Count\n",
    "            out_name = var_id + '_' + rp + 'era5_count'\n",
    "            tmp_q_count = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').sum()\n",
    "            \n",
    "            tmp_q_count = pd.wide_to_long(tmp_q_count.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_count = tmp_q_count.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_count['year'] = tmp_q_count['year'].dt.year\n",
    "            tmp_q_count['ssp'] = tmp_q_count['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Streak\n",
    "            out_name = var_id + '_' + rp + 'era5_streak'\n",
    "            tmp_q_streak = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').apply(n_longest_consecutive)\n",
    "            \n",
    "            tmp_q_streak = pd.wide_to_long(tmp_q_streak.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_streak = tmp_q_streak.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_streak['year'] = tmp_q_streak['year'].dt.year\n",
    "            tmp_q_streak['ssp'] = tmp_q_streak['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Merge\n",
    "            tmp_q_out = pd.merge(tmp_q_count, tmp_q_streak, on=['year', 'ssp'])\n",
    "            tmp_q_out['region'] = region\n",
    "            era5_tmp_out.append(tmp_q_out)\n",
    "    \n",
    "    # Merge and remove NaNs\n",
    "    df_out = pd.merge(pd.concat(gmfd_tmp_out), pd.concat(era5_tmp_out), on=['region', 'ssp', 'year'])\n",
    "    df_out = df_out.groupby(['region', 'ssp', 'year']).max()\n",
    "    \n",
    "    # Upload to azure\n",
    "    with io.BytesIO() as buffer:\n",
    "        df_out.to_csv(buffer)\n",
    "        buffer.seek(0)\n",
    "        blob_client = container_client.get_blob_client('carbonplan/' + method + '/hot_spatial/' + model + '_' + var_id + '.csv')\n",
    "        blob_client.upload_blob(buffer, overwrite=True)\n",
    "    \n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a4828-3fb3-4a67-8bef-72d24dae0aab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DeepSD-BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28cbfb70-2e69-4413-abee-03d9ceac986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "method = 'DeepSD-BC'\n",
    "models = list(deepsdbc_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f3f94-037d-477d-a5d1-9b7e6d964932",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96baba8f-c34f-4268-b691-346d5571ed34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Annual avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0e6f62-9867-4bd5-8aa6-741098842226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0\n"
     ]
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 20 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models[1:]:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model,\n",
    "                   [ssp for ssp in list(deepsdbc_dict[model].keys())])\n",
    "    \n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmin'] + ds['tasmax']) / 2.\n",
    "    \n",
    "    # Annual averages\n",
    "    ds_final = ds.resample(time='1Y').mean()\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/avg/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60430cab-88f5-4714-8b0f-0b5732f6417c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b9bf089-6428-4e21-a030-b7adf315b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0\n"
     ]
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model,\n",
    "                   [ssp for ssp in list(deepsdbc_dict[model].keys())])\n",
    "\n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmin'] + ds['tasmax']) / 2.\n",
    "    \n",
    "    # Annual maxs\n",
    "    ds_final = ds.resample(time='1Y').max()\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/max/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd85a5-f89d-439b-9de2-48359d96b59c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5-day max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be02070b-1859-4e43-95f3-7e6b5b86d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xclim\n",
    "xclim.set_options(cf_compliance=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286c41f-4eff-4ea4-8f57-090a4318af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model,\n",
    "                    [ssp for ssp in list(deepsdbc_dict[model].keys())])\n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmin'] + ds['tasmax']) / 2.\n",
    "    ds['pr'].attrs['units'] = 'mm/day'\n",
    "    \n",
    "    # Compute\n",
    "    ds_RX5day = xclim.indicators.icclim.RX5day(ds=ds[['pr']], freq='Y')\n",
    "    \n",
    "    ds_temp5day = ds[['tas','tasmin','tasmax']].rolling(time=5).mean().resample(time='1Y').max()\n",
    "    ds_temp5day -= 273.15 # K -> C\n",
    "        \n",
    "    # Storage options\n",
    "    ds_final = xr.merge([ds_temp5day, ds_RX5day])\n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/max5d/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6601c-1a7c-4c80-bf42-3dadebb63b15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ab53dd-8535-42fd-9fe1-7440ad180df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for longest consecutive spell if needed\n",
    "def n_longest_consecutive(ds):\n",
    "    ds_out = ds.cumsum(dim='time') - ds.cumsum(dim='time').where(ds == 0).ffill(dim='time').fillna(0)\n",
    "    return ds_out.max(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1896a99-f885-49ec-aabc-98b0caaa6e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2/2 00:07&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0\n"
     ]
    }
   ],
   "source": [
    "# loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model,\n",
    "                    [ssp for ssp in list(deepsdbc_dict[model].keys()) if 'pr' in deepsdbc_dict[model][ssp]])\n",
    "    ds = convert_units(ds)\n",
    "    \n",
    "    # Select only precip\n",
    "    ds = ds.drop(['tasmin', 'tasmax'])\n",
    "    \n",
    "    # Compute\n",
    "    # Number of dry days\n",
    "    ds_tmp_0 = (ds == 0.).resample(time='1Y').sum() # 0mm\n",
    "    ds_tmp_1 = (ds < 1.).resample(time='1Y').sum() # less than 1mm\n",
    "    # Longest sonsecutive dry day streak\n",
    "    ds_tmp_0c = (ds == 0.).resample(time='1Y').apply(n_longest_consecutive) # 0mm longest consecutive\n",
    "    ds_tmp_1c = (ds < 1.).resample(time='1Y').apply(n_longest_consecutive) # less than 1mm longest consecutive\n",
    "    # Merge\n",
    "    ds_final = xr.merge([ds_tmp_0.rename({'pr':'count_eq_0'}),\n",
    "                         ds_tmp_0c.rename({'pr':'streak_eq_0'}),\n",
    "                         ds_tmp_1.rename({'pr':'count_lt_1'}),\n",
    "                         ds_tmp_1c.rename({'pr':'streak_lt_1'})])\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':30, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/dry/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3951742-756c-4635-81d4-9cc9029ce930",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Less simple metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293b4d8-bb38-4efb-b3ba-9532ac5f98a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "216f8126-eefe-42e7-8fdd-f9459921e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2/2 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0\n",
      "CPU times: user 1min 53s, sys: 921 ms, total: 1min 54s\n",
      "Wall time: 19min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_precip_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_era5['lon'] = np.where(ds_q_era5['lon'] > 180, ds_q_era5['lon'] - 360, ds_q_era5['lon'])\n",
    "ds_q_era5 = ds_q_era5.sortby('lon')\n",
    "\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_precip_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_gmfd['lon'] = np.where(ds_q_gmfd['lon'] > 180, ds_q_gmfd['lon'] - 360, ds_q_gmfd['lon'])\n",
    "ds_q_gmfd = ds_q_gmfd.sortby('lon')\n",
    "    \n",
    "# Loop through models: RUNTIME IS AROUND 15 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model,\n",
    "                    [ssp for ssp in list(deepsdbc_dict[model].keys()) if 'pr' in deepsdbc_dict[model][ssp]])\n",
    "    ds = convert_units(ds)\n",
    "    \n",
    "    if ds['pr'].attrs['units'] == 'NaN':\n",
    "        print(model + ' contains no precip')\n",
    "        continue\n",
    "    \n",
    "    # Select only precip\n",
    "    ds = ds.drop(['tasmin', 'tasmax'])\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    var_id = 'pr'\n",
    "    ds_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        # Get above/below binary\n",
    "        ds_tmp_q_era5 = ds[var_id] > ds_q_era5[var_id + '_' + rp]\n",
    "        ds_tmp_q_gmfd = ds[var_id] > ds_q_gmfd[var_id + '_' + rp]\n",
    "        \n",
    "        # Count of hot days\n",
    "        ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "        ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "        \n",
    "        # Longest consecutive hot day streak\n",
    "        ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "        ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "        \n",
    "    # Merge metrics and append\n",
    "    ds_final = xr.merge(ds_tmp_out)\n",
    "        \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':20, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/wet/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634ce31-09b9-4974-87b2-cb4afdfcdc8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5b9fc-a96a-4bc3-82cc-0039f2533a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_temperature_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_era5['lon'] = np.where(ds_q_era5['lon'] > 180, ds_q_era5['lon'] - 360, ds_q_era5['lon'])\n",
    "ds_q_era5 = ds_q_era5.sortby('lon')\n",
    "\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_temperature_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_gmfd['lon'] = np.where(ds_q_gmfd['lon'] > 180, ds_q_gmfd['lon'] - 360, ds_q_gmfd['lon'])\n",
    "ds_q_gmfd = ds_q_gmfd.sortby('lon')\n",
    "    \n",
    "# Loop through models: RUNTIME IS AROUND 10 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, list(deepsdbc_dict[model].keys()))\n",
    "    ds = convert_units(ds)\n",
    "    ds['tas'] = (ds['tasmax'] + ds['tasmin']) / 2.\n",
    "    \n",
    "    # Drop precip\n",
    "    ds = ds.drop(['pr'])\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    ds_tmp_final = []\n",
    "    for var_id in ['tasmin', 'tasmax', 'tas']:\n",
    "        ds_tmp_out = []\n",
    "        for rp in ['q99', 'rp10']:\n",
    "            # Get above/below binary\n",
    "            ds_tmp_q_era5 = ds[var_id] > ds_q_era5[var_id + '_' + rp]\n",
    "            ds_tmp_q_gmfd = ds[var_id] > ds_q_gmfd[var_id + '_' + rp]\n",
    "        \n",
    "            # Count of hot days\n",
    "            ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "            ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "        \n",
    "            # Longest consecutive hot day streak\n",
    "            ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "            ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "            ds_tmp_out.append(xr.Dataset({var_id + '_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "            \n",
    "        # Merge RPs and append\n",
    "        ds_out = xr.merge(ds_tmp_out)\n",
    "        ds_tmp_final.append(ds_out)\n",
    "    \n",
    "    # Merge variables\n",
    "    ds_final = xr.merge(ds_tmp_final)\n",
    "    \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':20, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/hot/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03bede8-d31f-42c9-aa97-7e98695f1a0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Multivariate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bed181-8f59-4abb-9842-7317c9314b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hot and dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e54e46a8-8779-4800-9cea-0c127e235295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2/2 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0\n",
      "CPU times: user 2min 15s, sys: 2.12 s, total: 2min 17s\n",
      "Wall time: 43min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_temperature_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_era5['lon'] = np.where(ds_q_era5['lon'] > 180, ds_q_era5['lon'] - 360, ds_q_era5['lon'])\n",
    "ds_q_era5 = ds_q_era5.sortby('lon')\n",
    "\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_temperature_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_gmfd['lon'] = np.where(ds_q_gmfd['lon'] > 180, ds_q_gmfd['lon'] - 360, ds_q_gmfd['lon'])\n",
    "ds_q_gmfd = ds_q_gmfd.sortby('lon')\n",
    "    \n",
    "# loop through models: RUNTIME IS AROUND 10 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model,\n",
    "                    [ssp for ssp in list(deepsdbc_dict[model].keys()) if 'pr' in deepsdbc_dict[model][ssp]])\n",
    "    ds = convert_units(ds)\n",
    "    \n",
    "    # Drop tasmin\n",
    "    ds = ds.drop(['tasmin'])\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    ds_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        # Get above/below binary\n",
    "        ds_tmp_q_gmfd = (ds['tasmax'] > ds_q_gmfd['tasmax_' + rp]) & (ds['pr'] < 1.)\n",
    "        ds_tmp_q_era5 = (ds['tasmax'] > ds_q_era5['tasmax_' + rp]) & (ds['pr'] < 1.)\n",
    "        \n",
    "        # Count of hot+dry days\n",
    "        ds_tmp_q_era5_count = ds_tmp_q_era5.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'era5_count': ds_tmp_q_era5_count}))\n",
    "        ds_tmp_q_gmfd_count = ds_tmp_q_gmfd.resample(time='1Y').sum()\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'gmfd_count': ds_tmp_q_gmfd_count}))\n",
    "        \n",
    "        # Longest consecutive hot+dry day streak\n",
    "        ds_tmp_q_era5_streak = ds_tmp_q_era5.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'era5_streak': ds_tmp_q_era5_streak}))\n",
    "        ds_tmp_q_gmfd_streak = ds_tmp_q_gmfd.resample(time='1Y').apply(n_longest_consecutive)\n",
    "        ds_tmp_out.append(xr.Dataset({'hotdry_' + rp + 'gmfd_streak': ds_tmp_q_gmfd_streak}))\n",
    "        \n",
    "    # Merge metrics and append\n",
    "    ds_final = xr.merge(ds_tmp_out)\n",
    "        \n",
    "    # storage options    \n",
    "    ds_final = ds_final.chunk({'ssp':1, 'time':20, 'lat':720, 'lon':1440})\n",
    "    \n",
    "    compressor = zarr.Blosc(cname='zstd', clevel=3)\n",
    "    encoding = {vname: {'compressor': compressor} for vname in ds_final.data_vars}\n",
    "    \n",
    "    azure_prefix = 'carbonplan/' + method + '/hotdry/' + model\n",
    "    store = zarr.ABSStore(client=container_client, prefix=azure_prefix)\n",
    "\n",
    "    # store\n",
    "    ds_final.to_zarr(store=store, encoding=encoding, consolidated=True, mode='w')\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b21a0d-fe94-4378-8cfb-e57edf719eaa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Spatially compounding metrics (historical quantiles required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6e348-cf1d-4e8a-90d3-a99b5ccb7d3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Hot days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63dd78df-8e69-46dd-8858-31f98874e589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CanESM5\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.timescale.method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3/3 00:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI-ESM2-0\n",
      "CPU times: user 21min 16s, sys: 28.1 s, total: 21min 44s\n",
      "Wall time: 1h 5min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "area_frac = 0.5\n",
    "var_id = 'tasmax'\n",
    "\n",
    "# Load quantiles\n",
    "ds_q_era5 = xr.open_dataset('../data/quantiles/era5_temperature_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_era5['lon'] = np.where(ds_q_era5['lon'] > 180, ds_q_era5['lon'] - 360, ds_q_era5['lon'])\n",
    "ds_q_era5 = ds_q_era5.sortby('lon')\n",
    "\n",
    "ds_q_gmfd = xr.open_dataset('../data/quantiles/gmfd_temperature_quantiles_nex-cil-deepsd.nc')\n",
    "ds_q_gmfd['lon'] = np.where(ds_q_gmfd['lon'] > 180, ds_q_gmfd['lon'] - 360, ds_q_gmfd['lon'])\n",
    "ds_q_gmfd = ds_q_gmfd.sortby('lon')\n",
    "    \n",
    "# loop through models: RUNTIME IS AROUND 20 MINS PER MODEL WITH 40 DASK WORKERS\n",
    "for model in models:\n",
    "    # Grab model\n",
    "    ds = grab_model(method, model, list(deepsdbc_dict[model].keys()))\n",
    "    ds = convert_units(ds)\n",
    "    # ds['tas'] = (ds['tasmax'] + ds['tasmin']) / 2.\n",
    "        \n",
    "    # Drop precip and tasmin\n",
    "    ds = ds.drop(['pr', 'tasmin'])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    gmfd_tmp_out = []\n",
    "    era5_tmp_out = []\n",
    "    for rp in ['q99', 'rp10']:\n",
    "        ## GMFD\n",
    "        # Above/below binary\n",
    "        ds_tmp_q_gmfd = (ds[var_id] > ds_q_gmfd[var_id + '_' + rp]).persist()\n",
    "        # Mask\n",
    "        mask = regionmask.defined_regions.ar6.land.mask(ds_tmp_q_gmfd)\n",
    "        # Loop through regions\n",
    "        for region in regionmask.defined_regions.ar6.land.abbrevs:\n",
    "            region_index = regionmask.defined_regions.ar6.land.map_keys(region)\n",
    "            \n",
    "            ds_tmp_q_masked = ds_tmp_q_gmfd.where(mask == region_index, drop=True)\n",
    "            ds_tmp_region_q_masked = ds_tmp_q_masked.mean(dim=['lat','lon'], skipna=True)\n",
    "            \n",
    "            # Count\n",
    "            out_name = var_id + '_' + rp + 'gmfd_count'\n",
    "            tmp_q_count = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').sum()\n",
    "            \n",
    "            tmp_q_count = pd.wide_to_long(tmp_q_count.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_count = tmp_q_count.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_count['year'] = tmp_q_count['year'].dt.year\n",
    "            tmp_q_count['ssp'] = tmp_q_count['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Streak\n",
    "            out_name = var_id + '_' + rp + 'gmfd_streak'\n",
    "            tmp_q_streak = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').apply(n_longest_consecutive)\n",
    "            \n",
    "            tmp_q_streak = pd.wide_to_long(tmp_q_streak.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_streak = tmp_q_streak.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_streak['year'] = tmp_q_streak['year'].dt.year\n",
    "            tmp_q_streak['ssp'] = tmp_q_streak['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Merge\n",
    "            tmp_q_out = pd.merge(tmp_q_count, tmp_q_streak, on=['year', 'ssp'])\n",
    "            tmp_q_out['region'] = region\n",
    "            gmfd_tmp_out.append(tmp_q_out)\n",
    "            \n",
    "        ## ERA5\n",
    "        # Above/below binary\n",
    "        ds_tmp_q_era5 = (ds[var_id] > ds_q_era5[var_id + '_' + rp]).persist()\n",
    "        # Mask\n",
    "        mask = regionmask.defined_regions.ar6.land.mask(ds_tmp_q_era5)\n",
    "        # Loop through regions\n",
    "        for region in regionmask.defined_regions.ar6.land.abbrevs:\n",
    "            region_index = regionmask.defined_regions.ar6.land.map_keys(region)\n",
    "            \n",
    "            ds_tmp_q_masked = ds_tmp_q_era5.where(mask == region_index, drop=True)\n",
    "            ds_tmp_region_q_masked = ds_tmp_q_masked.mean(dim=['lat','lon'], skipna=True)\n",
    "            \n",
    "            # Count\n",
    "            out_name = var_id + '_' + rp + 'era5_count'\n",
    "            tmp_q_count = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').sum()\n",
    "            \n",
    "            tmp_q_count = pd.wide_to_long(tmp_q_count.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_count = tmp_q_count.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_count['year'] = tmp_q_count['year'].dt.year\n",
    "            tmp_q_count['ssp'] = tmp_q_count['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Streak\n",
    "            out_name = var_id + '_' + rp + 'era5_streak'\n",
    "            tmp_q_streak = (ds_tmp_region_q_masked > area_frac).resample(time='1Y').apply(n_longest_consecutive)\n",
    "            \n",
    "            tmp_q_streak = pd.wide_to_long(tmp_q_streak.isel(member_id=0).to_pandas().T.reset_index(),\n",
    "                                          stubnames='ssp', i='time', j=out_name).reset_index()\n",
    "            tmp_q_streak = tmp_q_streak.rename(columns={out_name:'ssp', 'ssp':out_name, 'time':'year'})\n",
    "            tmp_q_streak['year'] = tmp_q_streak['year'].dt.year\n",
    "            tmp_q_streak['ssp'] = tmp_q_streak['ssp'].apply(lambda x: 'ssp' + str(x))\n",
    "            \n",
    "            # Merge\n",
    "            tmp_q_out = pd.merge(tmp_q_count, tmp_q_streak, on=['year', 'ssp'])\n",
    "            tmp_q_out['region'] = region\n",
    "            era5_tmp_out.append(tmp_q_out)\n",
    "      \n",
    "    # Merge and remove NaNs\n",
    "    df_out = pd.merge(pd.concat(gmfd_tmp_out), pd.concat(era5_tmp_out), on=['region', 'ssp', 'year'])\n",
    "    df_out = df_out.groupby(['region', 'ssp', 'year']).max()\n",
    "    \n",
    "    # Upload to azure\n",
    "    with io.BytesIO() as buffer:\n",
    "        df_out.to_csv(buffer)\n",
    "        buffer.seek(0)\n",
    "        blob_client = container_client.get_blob_client('carbonplan/' + method + '/hot_spatial/' + model + '_' + var_id + '.csv')\n",
    "        blob_client.upload_blob(buffer, overwrite=True)\n",
    "    \n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420784b4-9968-47f0-8452-e2844c98c048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
